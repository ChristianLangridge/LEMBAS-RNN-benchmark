{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478ef771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3187, 16101)\n",
      "<class 'numpy.ndarray'> (3187, 16101)\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate/Fig_config_utilities.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95cbb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing noticeable heavy tails qualities within distribution of model prediction residuals \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "# from tail_analysis_clean import HeavyTailAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc8abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN ANALYSIS CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class HeavyTailAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes heavy-tailed residuals in gene expression predictions.\n",
    "    \n",
    "    Tests the hypothesis: \"Most predictions are good, but a few genes have \n",
    "    catastrophically wrong predictions, creating heavy tails in the residual \n",
    "    distribution.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, residuals, gene_ids, expression_matrix, model_name=\"Model\"):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with residuals and gene information.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        residuals : array-like, shape (n_predictions,)\n",
    "            Pre-calculated residuals: y_true - y_pred, flattened to 1D\n",
    "            \n",
    "        gene_ids : array-like, shape (n_predictions,)\n",
    "            Gene identifier for each prediction (same length as residuals)\n",
    "            Example: ['GENE1', 'GENE1', 'GENE1', 'GENE2', 'GENE2', ...]\n",
    "            \n",
    "        expression_matrix : pd.DataFrame, shape (n_genes, n_samples)\n",
    "            Expression values with genes as rows and samples as columns\n",
    "            Used to calculate gene-level statistics (mean, variance, CV)\n",
    "            \n",
    "        model_name : str\n",
    "            Name of the model being analyzed (for reporting)\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> residuals = y_true.ravel() - y_pred.ravel()\n",
    "        >>> gene_ids = np.repeat(gene_names, n_samples)\n",
    "        >>> analyzer = HeavyTailAnalyzer(residuals, gene_ids, expr_matrix, \"KG-RNN\")\n",
    "        \"\"\"\n",
    "        self.residuals = np.array(residuals).ravel()\n",
    "        self.gene_ids = np.array(gene_ids).ravel()\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Validate inputs\n",
    "        if len(self.residuals) != len(self.gene_ids):\n",
    "            raise ValueError(\n",
    "                f\"Residuals ({len(self.residuals)}) and gene_ids ({len(self.gene_ids)}) \"\n",
    "                \"must have the same length\"\n",
    "            )\n",
    "        \n",
    "        # Store basic info\n",
    "        self.n_predictions = len(self.residuals)\n",
    "        self.n_unique_genes = len(np.unique(self.gene_ids))\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"INITIALIZING ANALYZER: {self.model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Total predictions: {self.n_predictions:,}\")\n",
    "        print(f\"Unique genes: {self.n_unique_genes:,}\")\n",
    "        print(f\"Mean residual: {np.mean(self.residuals):.6f}\")\n",
    "        print(f\"Std residual: {np.std(self.residuals):.4f}\")\n",
    "        print(f\"Kurtosis: {stats.kurtosis(self.residuals):.2f} \"\n",
    "              f\"({'heavy tails' if stats.kurtosis(self.residuals) > 3 else 'normal'})\")\n",
    "        \n",
    "        # Create the main dataframe\n",
    "        self._build_dataframe(expression_matrix)\n",
    "    \n",
    "    \n",
    "    def _build_dataframe(self, expression_matrix):\n",
    "        \"\"\"Build the internal dataframe with residuals and gene properties.\"\"\"\n",
    "        # Start with residuals\n",
    "        self.data = pd.DataFrame({\n",
    "            'gene_id': self.gene_ids,\n",
    "            'residual': self.residuals,\n",
    "            'abs_residual': np.abs(self.residuals)\n",
    "        })\n",
    "        \n",
    "        # Add gene-level statistics from expression matrix\n",
    "        gene_stats = self._calculate_gene_statistics(expression_matrix)\n",
    "        self.data = self.data.merge(gene_stats, on='gene_id', how='left')\n",
    "        \n",
    "        # Create gene-level aggregates\n",
    "        self.gene_summary = self._aggregate_by_gene()\n",
    "    \n",
    "    \n",
    "    def _calculate_gene_statistics(self, expression_matrix):\n",
    "        \"\"\"\n",
    "        Calculate mean, variance, and coefficient of variation for each gene.\n",
    "        \n",
    "        Returns DataFrame with columns: gene_id, mean_expr, variance, cv\n",
    "        \"\"\"\n",
    "        print(f\"\\nCalculating gene-level statistics...\")\n",
    "        \n",
    "        gene_stats = pd.DataFrame({\n",
    "            'gene_id': expression_matrix.index,\n",
    "            'mean_expr': expression_matrix.mean(axis=1),\n",
    "            'variance': expression_matrix.var(axis=1),\n",
    "            'cv': expression_matrix.std(axis=1) / (expression_matrix.mean(axis=1) + 1e-10)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Mean expression range: [{gene_stats['mean_expr'].min():.2f}, \"\n",
    "              f\"{gene_stats['mean_expr'].max():.2f}]\")\n",
    "        print(f\"  Variance range: [{gene_stats['variance'].min():.2f}, \"\n",
    "              f\"{gene_stats['variance'].max():.2f}]\")\n",
    "        \n",
    "        return gene_stats\n",
    "    \n",
    "    \n",
    "    def _aggregate_by_gene(self):\n",
    "        \"\"\"Aggregate residuals at the gene level.\"\"\"\n",
    "        gene_agg = self.data.groupby('gene_id').agg({\n",
    "            'residual': ['mean', 'std'],\n",
    "            'abs_residual': 'mean',\n",
    "            'mean_expr': 'first',\n",
    "            'variance': 'first',\n",
    "            'cv': 'first'\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        gene_agg.columns = ['_'.join(col).strip('_') for col in gene_agg.columns]\n",
    "        gene_agg = gene_agg.reset_index()\n",
    "        \n",
    "        # Count predictions per gene\n",
    "        counts = self.data.groupby('gene_id').size().reset_index(name='n_predictions')\n",
    "        gene_agg = gene_agg.merge(counts, on='gene_id')\n",
    "        \n",
    "        return gene_agg\n",
    "    \n",
    "    \n",
    "    # =========================================================================\n",
    "    # TAIL IDENTIFICATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def identify_heavy_tails(self, threshold_sigma=2.5):\n",
    "        \"\"\"\n",
    "        Identify residuals in the heavy tails of the distribution.\n",
    "        \n",
    "        Definition: Tail residuals are those beyond ±threshold_sigma standard \n",
    "        deviations from the mean.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        threshold_sigma : float, default=2.5\n",
    "            Number of standard deviations to define tail boundary\n",
    "            Common values: 2.0 (95%), 2.5 (98.8%), 3.0 (99.7%)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Subset of predictions in the tails, sorted by absolute residual\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"IDENTIFYING HEAVY TAILS (±{threshold_sigma}σ)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Calculate tail boundaries\n",
    "        mean_residual = np.mean(self.residuals)\n",
    "        std_residual = np.std(self.residuals)\n",
    "        lower_bound = mean_residual - threshold_sigma * std_residual\n",
    "        upper_bound = mean_residual + threshold_sigma * std_residual\n",
    "        \n",
    "        print(f\"Mean residual: {mean_residual:.6f}\")\n",
    "        print(f\"Std residual: {std_residual:.4f}\")\n",
    "        print(f\"Lower tail boundary: {lower_bound:.4f}\")\n",
    "        print(f\"Upper tail boundary: {upper_bound:.4f}\")\n",
    "        \n",
    "        # Flag tail residuals\n",
    "        self.data['is_tail'] = (\n",
    "            (self.data['residual'] < lower_bound) | \n",
    "            (self.data['residual'] > upper_bound)\n",
    "        )\n",
    "        \n",
    "        # Extract tail data\n",
    "        tail_data = self.data[self.data['is_tail']].copy()\n",
    "        tail_data = tail_data.sort_values('abs_residual', ascending=False)\n",
    "        \n",
    "        # Report statistics\n",
    "        n_tail = len(tail_data)\n",
    "        pct_tail = 100 * n_tail / self.n_predictions\n",
    "        n_genes_in_tail = tail_data['gene_id'].nunique()\n",
    "        \n",
    "        print(f\"\\nRESULTS:\")\n",
    "        print(f\"  Tail predictions: {n_tail:,} ({pct_tail:.2f}% of total)\")\n",
    "        print(f\"  Body predictions: {self.n_predictions - n_tail:,} \"\n",
    "              f\"({100 - pct_tail:.2f}% of total)\")\n",
    "        print(f\"  Unique genes affected: {n_genes_in_tail} \"\n",
    "              f\"({100*n_genes_in_tail/self.n_unique_genes:.1f}% of genes)\")\n",
    "        \n",
    "        # Show worst predictions\n",
    "        print(f\"\\n  Top 10 worst predictions:\")\n",
    "        worst_10 = tail_data.nlargest(10, 'abs_residual')\n",
    "        for idx, row in worst_10.iterrows():\n",
    "            print(f\"    {row['gene_id']}: residual = {row['residual']:.4f}, \"\n",
    "                  f\"variance = {row['variance']:.2f}\")\n",
    "        \n",
    "        self.tail_data = tail_data\n",
    "        self.threshold_sigma = threshold_sigma\n",
    "        \n",
    "        return tail_data\n",
    "    \n",
    "    \n",
    "    def compare_tail_vs_body(self):\n",
    "        \"\"\"\n",
    "        Compare gene properties between tail and body residuals.\n",
    "        \n",
    "        Tests whether genes with catastrophic predictions (tails) have \n",
    "        different characteristics than genes with good predictions (body).\n",
    "        \n",
    "        Uses Mann-Whitney U test (non-parametric) to compare:\n",
    "        - Mean expression level\n",
    "        - Expression variance\n",
    "        - Coefficient of variation\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with test results and summary statistics\n",
    "        \"\"\"\n",
    "        if 'is_tail' not in self.data.columns:\n",
    "            raise ValueError(\"Must run identify_heavy_tails() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"COMPARING TAIL vs BODY PROPERTIES\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Split data\n",
    "        tail = self.data[self.data['is_tail']]\n",
    "        body = self.data[~self.data['is_tail']]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # --- Compare residual magnitudes ---\n",
    "        print(f\"\\n1. RESIDUAL MAGNITUDES\")\n",
    "        print(f\"   {'Tail':8s} | {'Body':8s} | Difference\")\n",
    "        print(f\"   {'-'*8} | {'-'*8} | {'-'*10}\")\n",
    "        \n",
    "        tail_mean_abs = tail['abs_residual'].mean()\n",
    "        body_mean_abs = body['abs_residual'].mean()\n",
    "        print(f\"   {tail_mean_abs:8.4f} | {body_mean_abs:8.4f} | \"\n",
    "              f\"{tail_mean_abs/body_mean_abs:.2f}x larger\")\n",
    "        \n",
    "        results['abs_residual_tail'] = tail_mean_abs\n",
    "        results['abs_residual_body'] = body_mean_abs\n",
    "        \n",
    "        # --- Compare gene properties ---\n",
    "        properties = [\n",
    "            ('mean_expr', 'Mean Expression'),\n",
    "            ('variance', 'Variance'),\n",
    "            ('cv', 'Coefficient of Variation')\n",
    "        ]\n",
    "        \n",
    "        for col, label in properties:\n",
    "            print(f\"\\n2. {label.upper()}\")\n",
    "            print(f\"   {'Metric':20s} | {'Tail':10s} | {'Body':10s}\")\n",
    "            print(f\"   {'-'*20} | {'-'*10} | {'-'*10}\")\n",
    "            \n",
    "            # Summary statistics\n",
    "            tail_mean = tail[col].mean()\n",
    "            tail_median = tail[col].median()\n",
    "            body_mean = body[col].mean()\n",
    "            body_median = body[col].median()\n",
    "            \n",
    "            print(f\"   {'Mean':20s} | {tail_mean:10.4f} | {body_mean:10.4f}\")\n",
    "            print(f\"   {'Median':20s} | {tail_median:10.4f} | {body_median:10.4f}\")\n",
    "            \n",
    "            # Statistical test\n",
    "            tail_values = tail[col].dropna()\n",
    "            body_values = body[col].dropna()\n",
    "            \n",
    "            if len(tail_values) > 0 and len(body_values) > 0:\n",
    "                statistic, p_value = stats.mannwhitneyu(\n",
    "                    tail_values, body_values, alternative='two-sided'\n",
    "                )\n",
    "                \n",
    "                # Interpret p-value\n",
    "                if p_value < 0.001:\n",
    "                    sig = \"***\"\n",
    "                    interp = \"HIGHLY SIGNIFICANT\"\n",
    "                elif p_value < 0.01:\n",
    "                    sig = \"**\"\n",
    "                    interp = \"SIGNIFICANT\"\n",
    "                elif p_value < 0.05:\n",
    "                    sig = \"*\"\n",
    "                    interp = \"SIGNIFICANT\"\n",
    "                else:\n",
    "                    sig = \"ns\"\n",
    "                    interp = \"NOT SIGNIFICANT\"\n",
    "                \n",
    "                print(f\"   {'Mann-Whitney U':20s} | p = {p_value:.4e} {sig}\")\n",
    "                print(f\"   {'Interpretation':20s} | {interp}\")\n",
    "                \n",
    "                results[f'{col}_p_value'] = p_value\n",
    "                results[f'{col}_significant'] = p_value < 0.05\n",
    "            else:\n",
    "                print(f\"   Insufficient data for statistical test\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    \n",
    "    # =========================================================================\n",
    "    # PERFORMANCE STRATIFICATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def stratify_performance(self, y_true_by_gene, y_pred_by_gene, \n",
    "                            property='variance', n_bins=5):\n",
    "        \"\"\"\n",
    "        Stratify model performance by gene property.\n",
    "        \n",
    "        This tests whether prediction accuracy correlates with gene characteristics.\n",
    "        For example: \"Do high-variance genes have worse R² scores?\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true_by_gene : dict\n",
    "            Dictionary mapping gene_id -> array of true values\n",
    "            Example: {'GENE1': array([5.2, 6.1, ...]), 'GENE2': array([...])}\n",
    "            \n",
    "        y_pred_by_gene : dict\n",
    "            Dictionary mapping gene_id -> array of predicted values\n",
    "            Same structure as y_true_by_gene\n",
    "            \n",
    "        property : str, default='variance'\n",
    "            Gene property to bin by: 'variance', 'mean_expr', or 'cv'\n",
    "            \n",
    "        n_bins : int, default=5\n",
    "            Number of quantile bins (e.g., 5 = quintiles)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Performance metrics for each bin\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"STRATIFYING PERFORMANCE BY GENE {property.upper()}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Validate property\n",
    "        valid_properties = ['variance', 'mean_expr', 'cv']\n",
    "        if property not in valid_properties:\n",
    "            raise ValueError(f\"property must be one of {valid_properties}\")\n",
    "        \n",
    "        # Calculate per-gene R² and metrics\n",
    "        print(f\"\\nCalculating per-gene metrics...\")\n",
    "        gene_metrics = self._calculate_gene_metrics(y_true_by_gene, y_pred_by_gene)\n",
    "        \n",
    "        # Merge with gene summary\n",
    "        analysis_df = self.gene_summary.merge(gene_metrics, on='gene_id', how='inner')\n",
    "        \n",
    "        # Create bins\n",
    "        print(f\"Creating {n_bins} quantile bins based on {property}...\")\n",
    "        try:\n",
    "            analysis_df['bin'] = pd.qcut(\n",
    "                analysis_df[property], \n",
    "                q=n_bins,\n",
    "                labels=[f'Q{i+1}' for i in range(n_bins)],\n",
    "                duplicates='drop'\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"  Warning: Could not create {n_bins} unique bins. Using fewer bins.\")\n",
    "            analysis_df['bin'] = pd.qcut(\n",
    "                analysis_df[property], \n",
    "                q=n_bins,\n",
    "                duplicates='drop'\n",
    "            )\n",
    "        \n",
    "        # Aggregate by bin\n",
    "        bin_summary = self._summarize_bins(analysis_df, property)\n",
    "        \n",
    "        # Test correlation\n",
    "        self._test_correlation(analysis_df, property)\n",
    "        \n",
    "        # Store results\n",
    "        self.stratification_results = {\n",
    "            'property': property,\n",
    "            'n_bins': n_bins,\n",
    "            'bin_summary': bin_summary,\n",
    "            'full_data': analysis_df\n",
    "        }\n",
    "        \n",
    "        return bin_summary\n",
    "    \n",
    "    \n",
    "    def _calculate_gene_metrics(self, y_true_by_gene, y_pred_by_gene):\n",
    "        \"\"\"Calculate R², MSE, and MAE for each gene.\"\"\"\n",
    "        metrics_list = []\n",
    "        \n",
    "        for gene_id in self.gene_summary['gene_id']:\n",
    "            if gene_id not in y_true_by_gene or gene_id not in y_pred_by_gene:\n",
    "                continue\n",
    "            \n",
    "            y_true = np.array(y_true_by_gene[gene_id])\n",
    "            y_pred = np.array(y_pred_by_gene[gene_id])\n",
    "            \n",
    "            # Need at least 2 samples for R²\n",
    "            if len(y_true) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Calculate metrics\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            \n",
    "            metrics_list.append({\n",
    "                'gene_id': gene_id,\n",
    "                'r2': r2,\n",
    "                'mse': mse,\n",
    "                'mae': mae\n",
    "            })\n",
    "        \n",
    "        print(f\"  Calculated metrics for {len(metrics_list)} genes\")\n",
    "        return pd.DataFrame(metrics_list)\n",
    "    \n",
    "    \n",
    "    def _summarize_bins(self, df, property):\n",
    "        \"\"\"Summarize performance metrics by bin.\"\"\"\n",
    "        summary = df.groupby('bin').agg({\n",
    "            'r2': ['mean', 'std', 'median', 'min', 'max'],\n",
    "            'mse': ['mean', 'median'],\n",
    "            'mae': ['mean', 'median'],\n",
    "            property: ['mean', 'min', 'max'],\n",
    "            'gene_id': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten column names\n",
    "        summary.columns = ['_'.join(col).strip('_') for col in summary.columns]\n",
    "        summary.rename(columns={'gene_id_count': 'n_genes'}, inplace=True)\n",
    "        \n",
    "        # Print formatted table\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PERFORMANCE BY {property.upper()} QUANTILE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        print(f\"{'Bin':6s} | {'N Genes':8s} | {property:12s} | \"\n",
    "              f\"{'R² Mean':8s} | {'R² Median':10s}\")\n",
    "        print(f\"{'-'*6} | {'-'*8} | {'-'*12} | {'-'*8} | {'-'*10}\")\n",
    "        \n",
    "        for _, row in summary.iterrows():\n",
    "            bin_name = row['bin']\n",
    "            n_genes = int(row['n_genes'])\n",
    "            prop_mean = row[f'{property}_mean']\n",
    "            r2_mean = row['r2_mean']\n",
    "            r2_median = row['r2_median']\n",
    "            \n",
    "            print(f\"{bin_name:6s} | {n_genes:8,d} | {prop_mean:12.4f} | \"\n",
    "                  f\"{r2_mean:8.4f} | {r2_median:10.4f}\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    \n",
    "    def _test_correlation(self, df, property):\n",
    "        \"\"\"Test correlation between gene property and R².\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CORRELATION: {property.upper()} vs R²\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_df = df.dropna(subset=[property, 'r2'])\n",
    "        \n",
    "        if len(valid_df) < 3:\n",
    "            print(\"Insufficient data for correlation test\")\n",
    "            return\n",
    "        \n",
    "        # Spearman (rank-based, robust to outliers)\n",
    "        spearman_r, spearman_p = spearmanr(valid_df[property], valid_df['r2'])\n",
    "        \n",
    "        # Pearson (linear correlation)\n",
    "        pearson_r, pearson_p = pearsonr(valid_df[property], valid_df['r2'])\n",
    "        \n",
    "        print(f\"\\nSpearman Correlation (rank-based):\")\n",
    "        print(f\"  ρ = {spearman_r:.4f}\")\n",
    "        print(f\"  p-value = {spearman_p:.4e}\")\n",
    "        print(f\"  Interpretation: {self._interpret_correlation(spearman_r, spearman_p)}\")\n",
    "        \n",
    "        print(f\"\\nPearson Correlation (linear):\")\n",
    "        print(f\"  r = {pearson_r:.4f}\")\n",
    "        print(f\"  p-value = {pearson_p:.4e}\")\n",
    "        print(f\"  Interpretation: {self._interpret_correlation(pearson_r, pearson_p)}\")\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _interpret_correlation(r, p):\n",
    "        \"\"\"Interpret correlation coefficient and p-value.\"\"\"\n",
    "        # Significance\n",
    "        if p < 0.001:\n",
    "            sig = \"highly significant\"\n",
    "        elif p < 0.01:\n",
    "            sig = \"significant\"\n",
    "        elif p < 0.05:\n",
    "            sig = \"marginally significant\"\n",
    "        else:\n",
    "            sig = \"not significant\"\n",
    "        \n",
    "        # Strength and direction\n",
    "        abs_r = abs(r)\n",
    "        if abs_r > 0.7:\n",
    "            strength = \"strong\"\n",
    "        elif abs_r > 0.4:\n",
    "            strength = \"moderate\"\n",
    "        elif abs_r > 0.2:\n",
    "            strength = \"weak\"\n",
    "        else:\n",
    "            strength = \"very weak\"\n",
    "        \n",
    "        direction = \"positive\" if r > 0 else \"negative\"\n",
    "        \n",
    "        return f\"{strength} {direction} correlation, {sig}\"\n",
    "    \n",
    "    \n",
    "    # =========================================================================\n",
    "    # EXPORT & REPORTING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def export_results(self, output_dir='.', prefix='analysis'):\n",
    "        \"\"\"\n",
    "        Export analysis results to CSV files.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        output_dir : str, default='.'\n",
    "            Directory to save files\n",
    "        prefix : str, default='analysis'\n",
    "            Prefix for output filenames\n",
    "        \n",
    "        Creates Files\n",
    "        -------------\n",
    "        {prefix}_{model}_samples.csv : All predictions with tail flags\n",
    "        {prefix}_{model}_genes.csv : Gene-level summary statistics\n",
    "        {prefix}_{model}_worst50.csv : Top 50 worst predictions\n",
    "        \"\"\"\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        model_safe = self.model_name.replace(' ', '_').replace('/', '-')\n",
    "        \n",
    "        # 1. Sample-level data\n",
    "        sample_file = os.path.join(output_dir, f'{prefix}_{model_safe}_samples.csv')\n",
    "        self.data.to_csv(sample_file, index=False)\n",
    "        print(f\"\\n✓ Saved: {sample_file}\")\n",
    "        print(f\"  ({len(self.data):,} predictions)\")\n",
    "        \n",
    "        # 2. Gene-level summary\n",
    "        gene_file = os.path.join(output_dir, f'{prefix}_{model_safe}_genes.csv')\n",
    "        self.gene_summary.to_csv(gene_file, index=False)\n",
    "        print(f\"✓ Saved: {gene_file}\")\n",
    "        print(f\"  ({len(self.gene_summary):,} genes)\")\n",
    "        \n",
    "        # 3. Worst predictions\n",
    "        worst_file = os.path.join(output_dir, f'{prefix}_{model_safe}_worst50.csv')\n",
    "        worst_50 = self.data.nlargest(50, 'abs_residual')\n",
    "        worst_50.to_csv(worst_file, index=False)\n",
    "        print(f\"✓ Saved: {worst_file}\")\n",
    "        print(f\"  (Top 50 catastrophic predictions)\")\n",
    "        \n",
    "        print(f\"\\nAll results exported to: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880c44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting function inputs together \n",
    "\n",
    "# data loading and flattening for each model \n",
    "\n",
    "mlr_y_pred_unflattened = mlr_y_pred\n",
    "xgbrf_y_pred_unflattened = xgbrf_y_pred\n",
    "\n",
    "y_true = y_test_centered.ravel()\n",
    "mlr_y_pred = mlr_y_pred.ravel()\n",
    "xgbrf_y_pred = xgbrf_y_pred.ravel()\n",
    "\n",
    "# generating prediction residuals for each model\n",
    "mlr_residuals = y_true - mlr_y_pred\n",
    "xgbrf_residuals = y_true - xgbrf_y_pred\n",
    "\n",
    "# generating a dataframe from centered y_train with the gene ID names for better indexing \n",
    "train_expr_df = pd.DataFrame(\n",
    "    y_train_centered.T,  # transpose: (n_genes, n_train_samples)\n",
    "    index=y_train_gene_names  # gene names as row index\n",
    ")\n",
    "\n",
    "# generating gene_ids array by repeating gene names for each sample\n",
    "# using np.tile because your data is (samples × genes)\n",
    "n_test_samples = y_test_centered.shape[0]\n",
    "n_genes = y_test_centered.shape[1]\n",
    "gene_ids_test = np.tile(y_train_gene_names, n_test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5968127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING ANALYZER: MLR\n",
      "======================================================================\n",
      "Total predictions: 51,313,887\n",
      "Unique genes: 16,101\n",
      "Mean residual: -0.000276\n",
      "Std residual: 0.1769\n",
      "Kurtosis: 32.44 (heavy tails)\n",
      "\n",
      "Calculating gene-level statistics...\n",
      "  Mean expression range: [-0.00, 0.00]\n",
      "  Variance range: [0.00, 2.84]\n",
      "\n",
      "======================================================================\n",
      "INITIALIZING ANALYZER: XGBRF\n",
      "======================================================================\n",
      "Total predictions: 51,313,887\n",
      "Unique genes: 16,101\n",
      "Mean residual: 0.001872\n",
      "Std residual: 0.3973\n",
      "Kurtosis: 3.56 (heavy tails)\n",
      "\n",
      "Calculating gene-level statistics...\n",
      "  Mean expression range: [-0.00, 0.00]\n",
      "  Variance range: [0.00, 2.84]\n"
     ]
    }
   ],
   "source": [
    "# initial analysis of model predictions (both body and tails)\n",
    "\n",
    "mlr_analyzer = HeavyTailAnalyzer(\n",
    "        residuals=mlr_residuals,\n",
    "        gene_ids=gene_ids_test, # gene IDs used in y training run (np.tiled to ensure they match 1D formatting of the residuals)\n",
    "        expression_matrix=train_expr_df, # transposed y training set (centered) ONLY to prevent leakage \n",
    "        model_name=\"MLR\" # mlr for this first analysis\n",
    "    )\n",
    "\n",
    "xgbrf_analyzer = HeavyTailAnalyzer(\n",
    "        residuals=xgbrf_y_pred,\n",
    "        gene_ids=gene_ids_test, # gene IDs used in y training run (np.tiled to ensure they match 1D formatting of the residuals)\n",
    "        expression_matrix=train_expr_df, # transposed y training set (centered)\n",
    "        model_name=\"XGBRF\" # xgbrf for this second analysis\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e354bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "IDENTIFYING HEAVY TAILS (±2.5σ)\n",
      "======================================================================\n",
      "Mean residual: -0.000276\n",
      "Std residual: 0.1769\n",
      "Lower tail boundary: -0.4424\n",
      "Upper tail boundary: 0.4419\n",
      "\n",
      "RESULTS:\n",
      "  Tail predictions: 1,422,580 (2.77% of total)\n",
      "  Body predictions: 49,891,307 (97.23% of total)\n",
      "  Unique genes affected: 14979 (93.0% of genes)\n",
      "\n",
      "  Top 10 worst predictions:\n",
      "    RPS4Y1: residual = -7.6462, variance = 1.06\n",
      "    IGKC: residual = 6.1538, variance = 1.78\n",
      "    MT1A: residual = 6.0703, variance = 0.70\n",
      "    MT1G: residual = 5.7812, variance = 1.83\n",
      "    RPS4Y1: residual = 5.7408, variance = 1.06\n",
      "    HCST: residual = 5.7049, variance = 0.51\n",
      "    S100A9: residual = 5.6819, variance = 0.95\n",
      "    APOA1: residual = -5.6707, variance = 2.40\n",
      "    PLA2G2A: residual = -5.4945, variance = 1.12\n",
      "    IGKC: residual = 5.4040, variance = 1.78\n"
     ]
    }
   ],
   "source": [
    "# higher resolution inspection of tails for each model (how many there, which genes involved, worst cases)\n",
    "mlr_tail_data = mlr_analyzer.identify_heavy_tails(threshold_sigma=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "IDENTIFYING HEAVY TAILS (±2.5σ)\n",
      "======================================================================\n",
      "Mean residual: 0.001872\n",
      "Std residual: 0.3973\n",
      "Lower tail boundary: -0.9913\n",
      "Upper tail boundary: 0.9950\n",
      "\n",
      "RESULTS:\n",
      "  Tail predictions: 1,574,022 (3.07% of total)\n",
      "  Body predictions: 49,739,865 (96.93% of total)\n",
      "  Unique genes affected: 14603 (90.7% of genes)\n",
      "\n",
      "  Top 10 worst predictions:\n",
      "    CSH1: residual = 5.2218, variance = 0.44\n",
      "    CSH1: residual = 5.2218, variance = 0.44\n",
      "    CSH1: residual = 5.2218, variance = 0.44\n",
      "    CSN2: residual = 5.2117, variance = 0.03\n",
      "    CSH1: residual = 5.1999, variance = 0.44\n",
      "    CSH1: residual = 5.1782, variance = 0.44\n",
      "    CSH1: residual = 5.1782, variance = 0.44\n",
      "    CSH1: residual = 5.1782, variance = 0.44\n",
      "    CSH1: residual = 5.1782, variance = 0.44\n",
      "    CSH1: residual = 5.1645, variance = 0.44\n"
     ]
    }
   ],
   "source": [
    "# same for xgbrf\n",
    "# interesting that CSH1 and CSH2 come back, CSH1 needs to be looked at for biological significance while CSH2 might just have outliers or be functionally related to CSH1 \n",
    "# differences in architecture means I have to approach this analysis differently, I need to look for 10-worst genes across ALL models not just \n",
    "xgbrf_tail_data = xgbrf_analyzer.identify_heavy_tails(threshold_sigma=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENES WITH MOST TAIL PREDICTIONS (SYSTEMATIC FAILURES)\n",
      "======================================================================\n",
      "\n",
      "Gene            | Tail Count   | % of Gene Predictions\n",
      "--------------- | ------------ | --------------------\n",
      "APCS            |        2,693 |               84.50%\n",
      "ALDOB           |        2,405 |               75.46%\n",
      "GC              |        2,372 |               74.43%\n",
      "C9              |        2,365 |               74.21%\n",
      "CYP2C8          |        2,190 |               68.72%\n",
      "LBP             |        2,171 |               68.12%\n",
      "F9              |        2,164 |               67.90%\n",
      "CYP3A4          |        2,156 |               67.65%\n",
      "CYP2E1          |        2,121 |               66.55%\n",
      "FGA             |        2,096 |               65.77%\n",
      "SAA1            |        2,092 |               65.64%\n",
      "SERPINC1        |        2,087 |               65.48%\n",
      "PLG             |        2,052 |               64.39%\n",
      "HP              |        2,050 |               64.32%\n",
      "ALB             |        2,031 |               63.73%\n",
      "KNG1            |        2,025 |               63.54%\n",
      "APOC3           |        2,017 |               63.29%\n",
      "APOH            |        1,999 |               62.72%\n",
      "ADH1B           |        1,987 |               62.35%\n",
      "UGT2B4          |        1,958 |               61.44%\n",
      "\n",
      "======================================================================\n",
      "INTERPRETATION:\n",
      "======================================================================\n",
      "High % = That gene's dedicated XGBRF model is systematically failing\n",
      "Low % = Random outliers, gene model is generally okay\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Problematic genes (>5% failure rate): 3265\n",
      "Consider: retraining with different hyperparameters or removing from model\n"
     ]
    }
   ],
   "source": [
    "# further analysis of tails across all XGBRF models - which genes show up consistently? \n",
    "# roughly 20% of genes are coming back with catastrophic failure which is masked by agg R^2\n",
    "# some genes with significanly poorer performan than others (ex: APCS has 84.5% of its instances in heavy tails)\n",
    "\n",
    "\n",
    "# Count how many times each gene appears in tails\n",
    "gene_tail_counts = xgbrf_tail_data['gene_id'].value_counts()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENES WITH MOST TAIL PREDICTIONS (SYSTEMATIC FAILURES)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"{'Gene':15s} | {'Tail Count':12s} | {'% of Gene Predictions':20s}\")\n",
    "print(f\"{'-'*15} | {'-'*12} | {'-'*20}\")\n",
    "\n",
    "n_test_samples = y_test_centered.shape[0]\n",
    "\n",
    "for gene_id, count in gene_tail_counts.head(20).items():\n",
    "    pct_of_gene = 100 * count / n_test_samples\n",
    "    print(f\"{gene_id:15s} | {count:12,d} | {pct_of_gene:19.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"INTERPRETATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"High % = That gene's dedicated XGBRF model is systematically failing\")\n",
    "print(\"Low % = Random outliers, gene model is generally okay\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Identify genes to potentially retrain or remove\n",
    "problematic_genes = gene_tail_counts[gene_tail_counts > 0.05 * n_test_samples]  # >5% failure rate\n",
    "print(f\"\\nProblematic genes (>5% failure rate): {len(problematic_genes)}\")\n",
    "print(f\"Consider: retraining with different hyperparameters or removing from model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARING TAIL vs BODY PROPERTIES\n",
      "======================================================================\n",
      "\n",
      "1. RESIDUAL MAGNITUDES\n",
      "   Tail     | Body     | Difference\n",
      "   -------- | -------- | ----------\n",
      "     0.7354 |   0.0798 | 9.22x larger\n",
      "\n",
      "2. MEAN EXPRESSION\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 |     0.0000 |     0.0000\n",
      "   Median               |     0.0000 |    -0.0000\n",
      "   Mann-Whitney U       | p = 2.0858e-05 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n",
      "\n",
      "2. VARIANCE\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 |     0.3073 |     0.2028\n",
      "   Median               |     0.2269 |     0.1745\n",
      "   Mann-Whitney U       | p = 0.0000e+00 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n",
      "\n",
      "2. COEFFICIENT OF VARIATION\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 | 5123021413.1973 | 4221569489.0299\n",
      "   Median               | 4763235254.1106 | 4177507970.4766\n",
      "   Mann-Whitney U       | p = 0.0000e+00 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n"
     ]
    }
   ],
   "source": [
    "# comparing properties between body and tails\n",
    "# variance is the super interesting metric in this case - the tails are of higher variance than the body (model is predicting worse on high-variance genes)\n",
    "mlr_comparison = mlr_analyzer.compare_tail_vs_body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d167f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARING TAIL vs BODY PROPERTIES\n",
      "======================================================================\n",
      "\n",
      "1. RESIDUAL MAGNITUDES\n",
      "   Tail     | Body     | Difference\n",
      "   -------- | -------- | ----------\n",
      "     1.2906 |   0.2455 | 5.26x larger\n",
      "\n",
      "2. MEAN EXPRESSION\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 |     0.0000 |     0.0000\n",
      "   Median               |     0.0000 |    -0.0000\n",
      "   Mann-Whitney U       | p = 1.8827e-61 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n",
      "\n",
      "2. VARIANCE\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 |     0.4772 |     0.1971\n",
      "   Median               |     0.3125 |     0.1729\n",
      "   Mann-Whitney U       | p = 0.0000e+00 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n",
      "\n",
      "2. COEFFICIENT OF VARIATION\n",
      "   Metric               | Tail       | Body      \n",
      "   -------------------- | ---------- | ----------\n",
      "   Mean                 | 6359722968.5542 | 4179689336.4025\n",
      "   Median               | 5590164057.9545 | 4158409924.5177\n",
      "   Mann-Whitney U       | p = 0.0000e+00 ***\n",
      "   Interpretation       | HIGHLY SIGNIFICANT\n"
     ]
    }
   ],
   "source": [
    "# same for xgbrf\n",
    "\n",
    "# comparing both models here:\n",
    "# MLR does worse at predicting genes with a higher expression variance (non-linear realtionships)\n",
    "# MLR has larger absolute error compared to XGBRF (highly variance-dependent)\n",
    "# Differences in tail structure present MLR as having a more gradual decline in performance vs XGBRF that either works well or doesn't (bimodality)\n",
    "\n",
    "# VERY IMPORTANT -> data is full of non-linear relatioships based on the complexly regulated gene expression patterns\n",
    "# MLR acts as an initial blanket solution, weak at capturing genes with high-variance expression (more complexity)\n",
    "# XGBRF comes in explaining more of this non-linearity and works better on said high-variance expression genes\n",
    "# (ex: if TF1 is above threshold but TF2 is below then...) but still fails for 20% of genes\n",
    "# Introduces the need for a robust means of tackling non-linear data that can reduce variance effect, reduce net total problematic genes and \n",
    "# have different failure modes (rare expression patterns, long-range dependent expression, etc.)\n",
    "\n",
    "xgbrf_comparison = xgbrf_analyzer.compare_tail_vs_body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2beb422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STRATIFYING PERFORMANCE BY GENE VARIANCE\n",
      "======================================================================\n",
      "\n",
      "Calculating per-gene metrics...\n",
      "  Calculated metrics for 0 genes\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gene_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_477578/1706293834.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# binning genes on variance for each model- do higher-variance genes have a worse R^2\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m mlr_bin_summary = mlr_analyzer.stratify_performance(\n\u001b[32m     16\u001b[39m     y_true_by_gene=y_test_centered,\n\u001b[32m     17\u001b[39m     y_pred_by_gene=mlr_y_pred_unflattened,\n\u001b[32m     18\u001b[39m     property=\u001b[33m'variance'\u001b[39m,  \u001b[38;5;66;03m# does variance in training set explain R^2 in test set\u001b[39;00m\n",
      "\u001b[32m/tmp/ipykernel_477578/3674859294.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, y_true_by_gene, y_pred_by_gene, property, n_bins)\u001b[39m\n\u001b[32m    343\u001b[39m         print(f\"\\nCalculating per-gene metrics...\")\n\u001b[32m    344\u001b[39m         gene_metrics = self._calculate_gene_metrics(y_true_by_gene, y_pred_by_gene)\n\u001b[32m    345\u001b[39m \n\u001b[32m    346\u001b[39m         \u001b[38;5;66;03m# Merge with gene summary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         analysis_df = self.gene_summary.merge(gene_metrics, on=\u001b[33m'gene_id'\u001b[39m, how=\u001b[33m'inner'\u001b[39m)\n\u001b[32m    348\u001b[39m \n\u001b[32m    349\u001b[39m         \u001b[38;5;66;03m# Create bins\u001b[39;00m\n\u001b[32m    350\u001b[39m         print(f\"Creating {n_bins} quantile bins based on {property}...\")\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10855\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m     ) -> DataFrame:\n\u001b[32m  10857\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10858\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m         return merge(\n\u001b[32m  10860\u001b[39m             self,\n\u001b[32m  10861\u001b[39m             right,\n\u001b[32m  10862\u001b[39m             how=how,\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'gene_id'"
     ]
    }
   ],
   "source": [
    "# stratifying genes based on variance \n",
    "# creating per-gene dictionaries containing model predictions were analyzing  \n",
    "y_true_by_gene = {}\n",
    "mlr_y_pred_by_gene = {}\n",
    "xgbrf_y_pred_by_gene = {}\n",
    "\n",
    "for i, gene in enumerate(y_train_gene_names):\n",
    "    y_true_by_gene[gene] = y_test_centered[:, i]  # test samples for this gene\n",
    "    mlr_y_pred_by_gene[gene] = mlr_y_pred_unflattened[:, i]\n",
    "    xgbrf_y_pred_by_gene[gene] = xgbrf_y_pred_unflattened[:, i]\n",
    "\n",
    "\n",
    "# binning genes on variance for each model- do higher-variance genes have a worse R^2 \n",
    "\n",
    "mlr_bin_summary = mlr_analyzer.stratify_performance(\n",
    "    y_true_by_gene=y_test_centered,\n",
    "    y_pred_by_gene=mlr_y_pred_unflattened,\n",
    "    property='variance',  # does variance in training set explain R^2 in test set\n",
    "    n_bins=5\n",
    "    )\n",
    "\n",
    "xgbrf_bin_summary = xgbrf_analyzer.stratify_performance(\n",
    "    y_true_by_gene=y_true_by_gene,\n",
    "    y_pred_by_gene=xgbrf_y_pred_unflattened,\n",
    "    property='variance',  \n",
    "    n_bins=5\n",
    "    )\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
