{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87f225c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'../benchmarking/data preprocessing/model_boilerplate_remote.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/IPython/core/magics/execution.py:728\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    727\u001b[39m     fpath = arg_lst[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m     filename = \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/IPython/utils/path.py:90\u001b[39m, in \u001b[36mget_py_filename\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m` not found.\u001b[39m\u001b[33m\"\u001b[39m % name)\n",
      "\u001b[31mOSError\u001b[39m: File `'../benchmarking/data preprocessing/model_boilerplate_remote.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../benchmarking/data preprocessing/model_boilerplate_remote.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2504\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2502\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2504\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2508\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/IPython/core/magics/execution.py:739\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re.match(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m$\u001b[39m\u001b[33m\"\u001b[39m,fpath):\n\u001b[32m    738\u001b[39m         warn(\u001b[33m'\u001b[39m\u001b[33mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33mun \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmyfile.py\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys.meta_path:\n",
      "\u001b[31mException\u001b[39m: File `'../benchmarking/data preprocessing/model_boilerplate_remote.py'` not found."
     ]
    }
   ],
   "source": [
    "%run '../benchmarking/data preprocessing/model_boilerplate_remote.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272a3f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12748, 1197)\n",
      "(12748, 16100)\n",
      "(3187, 1197)\n",
      "(3187, 16100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e3f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box r2 score LinearRegression:\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "# difference of 0.12 between train and test is understandable given the high-dimensionality and noise in gene expression data\n",
    "\n",
    "# after applying the centering boilerplate (only difference between MLR v1 and v2 is column-wise centering)\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "\n",
    "# after working with final, uncentered data preprocessing that included a network check to ensure that nodes matched input expression data columns \n",
    "# train score:  0.9041830139739396\n",
    "# test score:  0.7986089431408789\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_test = LinearRegression(\n",
    "                    n_jobs=-1,\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd61c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9041830139739396\n",
      "Score:  0.7986089431408789\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', reg_test.score(x_train, y_train))\n",
    "print('Score: ', reg_test.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeed774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0, Train set: 11473,     Test set:1275\n",
      "Fold:1, Train set: 11473,     Test set:1275\n",
      "Fold:2, Train set: 11473,     Test set:1275\n",
      "Fold:3, Train set: 11473,     Test set:1275\n",
      "Fold:4, Train set: 11473,     Test set:1275\n",
      "Fold:5, Train set: 11473,     Test set:1275\n",
      "Fold:6, Train set: 11473,     Test set:1275\n",
      "Fold:7, Train set: 11473,     Test set:1275\n",
      "Fold:8, Train set: 11474,     Test set:1274\n",
      "Fold:9, Train set: 11474,     Test set:1274\n"
     ]
    }
   ],
   "source": [
    "# conducting a k-fold validation to check for overfitting\n",
    "# splitting training set into 10-folds\n",
    "# train sets: ~11473 targets\n",
    "# test sets: ~1274 targets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cnt = 0\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=888) # changed from 42 to 888 to match training seed for RNN 13/01/26\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, \\\n",
    "    Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MLR model cross validation ------\n"
     ]
    }
   ],
   "source": [
    "# running the 10-fold validation \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773 -> similar to the holdout training run\n",
    "#StandardDeviation: 0.009341412328795035 -> very consistent between folds\n",
    "\n",
    "# unlikely that MLR is overfitting based on these results -> good sanity check for reference\n",
    "\n",
    "# redid same analysis with column-wise centered data and got the exact same results \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773\n",
    "#StandardDeviation: 0.00934141232879502\n",
    "\n",
    "# redid same analysis once again, with uncentered data like the first run, but set random seed to 888\n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.79322189 0.79384094 0.80615516 0.77715731 0.78278073 0.78325776\n",
    "# 0.79921787 0.77486414 0.75888273 0.7807757 ]\n",
    "#Mean: 0.7850154223167911\n",
    "#StandardDeviation: 0.01291359135998445\n",
    "\n",
    "\n",
    "# same as before but used index_col=0 and removed 'TF' which was a junk filler column 15/01/26\n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.79306553 0.79355143 0.80595273 0.77689887 0.78254468 0.78294832\n",
    "# 0.79897946 0.77465899 0.75861371 0.78061954]\n",
    "#Mean: 0.7847833249078063\n",
    "#StandardDeviation: 0.012924317642343348\n",
    "\n",
    "\n",
    "def cross_validation(reg_model, training_set, training_target, cv):\n",
    "    scores = cross_val_score(\n",
    "      reg_model, training_set,\n",
    "      training_target,\n",
    "      scoring=\"r2\", cv=cv)\n",
    "    r2_scores = scores\n",
    "    print(\"Scores:\", r2_scores)\n",
    "    print(\"Mean:\", r2_scores.mean())\n",
    "    print(\"StandardDeviation:\", r2_scores.std())\n",
    "\n",
    "print(\"----- MLR model cross validation ------\")\n",
    "lin_reg = LinearRegression()\n",
    "cross_validation(lin_reg, x_train, y_train, kf)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779c71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# saving model + metadata\n",
    "\n",
    "metadata = {\n",
    "    'sklearn_version': '1.7.2',\n",
    "    'model_type': 'LinearRegression',\n",
    "    'n_features': reg_test.n_features_in_,\n",
    "    'coef_shape': reg_test.coef_.shape,\n",
    "    'intercept_shape': reg_test.intercept_.shape,\n",
    "}\n",
    "\n",
    "joblib.dump(reg_test, \"/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/MLR_model_v4(uncentered[FINAL]).joblib\")\n",
    "with open(\"/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/model_metadata_uncentered[FINAL].json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
