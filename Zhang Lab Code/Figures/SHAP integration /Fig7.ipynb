{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3aafad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3187, 16101)\n",
      "<class 'numpy.ndarray'> (3187, 16101)\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/Fig_config_utilities.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62ee10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/SHAP_storage.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13acafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap_model_comparison import SHAPModelComparator\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# output directory\n",
    "os.makedirs('/home/christianl/Zhang-Lab/Zhang Lab Data/Saved SHAP values', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0c9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading testing set \n",
    "x_test_centered_df = pd.DataFrame(x_test_centered) \n",
    "subsetted_x_test_centered = x_test_centered_df.sample(n=1000, random_state=42)\n",
    "feature_names = subsetted_x_test_centered.columns.tolist()\n",
    "\n",
    "# loading feature names\n",
    "feature_names = subsetted_x_test_centered.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b536552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing compatibility issue between version 2.0+ XGBoost class and SHAP package\n",
    "# likely non impactful given I'm using KernelExplainer on select values instead of using TreeExplainer on XGBRF\n",
    "\n",
    "def fix_xgboost_for_shap(model):\n",
    "    try:\n",
    "        booster = model.get_booster() if hasattr(model, 'get_booster') else model\n",
    "        config = json.loads(booster.save_config())\n",
    "        base_score = config['learner']['learner_model_param']['base_score']\n",
    "        if base_score.startswith('[') and base_score.endswith(']'):\n",
    "            base_score_float = float(base_score.strip('[]'))\n",
    "            config['learner']['learner_model_param']['base_score'] = str(base_score_float)\n",
    "            booster.load_config(json.dumps(config))\n",
    "            print(\"✓ Fixed XGBoost model for SHAP compatibility\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: XGBoost fix not needed or failed: {e}\")\n",
    "    return model\n",
    "\n",
    "xgbrf_loaded = fix_xgboost_for_shap(xgbrf_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898b161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained models\n",
    "models = {\n",
    "    'MLR': mlr_loaded,\n",
    "    'XGBRF': xgbrf_loaded\n",
    "}  # add when RNN retrained 'LEMBAS-RNN': rnn 06/01/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8665bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for when RNN is retrained and needs to be included \n",
    "\n",
    "import torch\n",
    "\n",
    "class PyTorchRNNWrapper:\n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        \n",
    "        if len(X_tensor.shape) == 2:\n",
    "            X_tensor = X_tensor.unsqueeze(1)  # Add sequence dimension\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(X_tensor)\n",
    "        \n",
    "        return output.cpu().numpy().flatten()\n",
    "\n",
    "# Load and wrap\n",
    "rnn_base_model = torch.load('models/lembas_rnn.pth')\n",
    "rnn_model = PyTorchRNNWrapper(rnn_base_model)\n",
    "\n",
    "# Test\n",
    "test_pred = rnn_model.predict(subsetted_x_test_centered[:5])\n",
    "print(f\"✓ RNN loaded and wrapped. Test predictions: {test_pred[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8334d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Initializing SHAP Comparator\n",
      "================================================================================\n",
      "✓ Comparator initialized with 2 models\n",
      "✓ Data: 1000 samples, 1198 features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Initializing SHAP Comparator\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparator = SHAPModelComparator(\n",
    "    models_dict=models,\n",
    "    X_data=subsetted_x_test_centered, \n",
    "    feature_names=feature_names,\n",
    "    background_samples=100  # make lower if SHAP is slow \n",
    ")\n",
    "\n",
    "print(f\"✓ Comparator initialized with {len(models)} models\")\n",
    "print(f\"✓ Data: {subsetted_x_test_centered.shape[0]} samples, {subsetted_x_test_centered.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d27676b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Computing MLR SHAP Values (this may take a few minutes...)\n",
      "================================================================================\n",
      "\n",
      "Computing SHAP values for MLR...\n",
      "✓ SHAP values computed for MLR\n",
      "\n",
      "✓ SHAP computation complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Computing MLR SHAP Values (this may take a few minutes...)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# computing for MLR\n",
    "mlr_shap_values = comparator.compute_shap_values('MLR','linear')\n",
    "mlr_shap_values = comparator.shap_values['MLR']\n",
    "\n",
    "print(\"\\n✓ SHAP computation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f049abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.87678878e-02,  1.16853361e-02, -1.73930026e-04, ...,\n",
       "          5.04794743e-04, -2.36792920e-04,  2.96545570e-05],\n",
       "        [ 3.51957870e-16, -5.45876105e-02, -7.87519517e-03, ...,\n",
       "         -2.20250815e-04, -1.08223485e-02,  2.51890571e-02],\n",
       "        [-2.29723285e-16,  4.72547504e-03, -9.06017948e-03, ...,\n",
       "         -1.63843300e-02,  1.18156938e-02,  1.72146683e-03],\n",
       "        ...,\n",
       "        [ 1.50122343e-16,  1.32639846e-02, -8.22179118e-03, ...,\n",
       "         -9.60091120e-03, -9.32970297e-03, -4.50851713e-03],\n",
       "        [-9.00103362e-18,  2.44495014e-03, -2.26547228e-02, ...,\n",
       "         -2.23530065e-02,  9.91671970e-03, -2.05070646e-03],\n",
       "        [ 7.93876158e-17, -2.65408994e-02,  2.35601143e-02, ...,\n",
       "         -7.12959403e-04,  1.93468187e-02, -5.17547521e-03]],\n",
       "\n",
       "       [[ 5.70471356e-01,  9.69369536e-02, -1.44285510e-03, ...,\n",
       "          4.18757869e-03, -1.96434095e-03,  2.46002544e-04],\n",
       "        [-7.23997047e-18,  1.12289771e-03,  1.61997174e-04, ...,\n",
       "          4.53068260e-06,  2.22621768e-04, -5.18153009e-04],\n",
       "        [-7.95406698e-17,  1.63617480e-03, -3.13704701e-03, ...,\n",
       "         -5.67300169e-03,  4.09113163e-03,  5.96050262e-04],\n",
       "        ...,\n",
       "        [-6.37118094e-17, -5.62922507e-03,  3.48932199e-03, ...,\n",
       "          4.07461950e-03,  3.95951892e-03,  1.91341128e-03],\n",
       "        [ 7.32613699e-19, -1.98999808e-04,  1.84391716e-03, ...,\n",
       "          1.81935981e-03, -8.07143381e-04,  1.66911458e-04],\n",
       "        [-1.33834235e-17,  4.47435149e-03, -3.97184101e-03, ...,\n",
       "          1.20193024e-04, -3.26154988e-03,  8.72498511e-04]],\n",
       "\n",
       "       [[ 5.67530127e-01,  9.64371674e-02, -1.43541605e-03, ...,\n",
       "          4.16598843e-03, -1.95421323e-03,  2.44734207e-04],\n",
       "        [-5.67018914e-17,  8.79429337e-03,  1.26872702e-03, ...,\n",
       "          3.54833316e-05,  1.74352580e-03, -4.05806292e-03],\n",
       "        [ 8.17930559e-17, -1.68250703e-03,  3.22588006e-03, ...,\n",
       "          5.83364642e-03, -4.20698190e-03, -6.12928863e-04],\n",
       "        ...,\n",
       "        [-9.32290901e-17, -8.23720965e-03,  5.10590293e-03, ...,\n",
       "          5.96236509e-03,  5.79393914e-03,  2.79988270e-03],\n",
       "        [ 1.69879656e-18, -4.61443991e-04,  4.27570508e-03, ...,\n",
       "          4.21876111e-03, -1.87161720e-03,  3.87037003e-04],\n",
       "        [-1.00102132e-17,  3.34661847e-03, -2.97076269e-03, ...,\n",
       "          8.98991051e-05, -2.43949611e-03,  6.52590579e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.98298177e-01,  8.46729756e-02, -1.26031230e-03, ...,\n",
       "          3.65778720e-03, -1.71582237e-03,  2.14879534e-04],\n",
       "        [-6.67613004e-17,  1.03544775e-02,  1.49381024e-03, ...,\n",
       "          4.17783834e-05,  2.05284245e-03, -4.77799860e-03],\n",
       "        [ 4.58012599e-18, -9.42145285e-05,  1.80638038e-04, ...,\n",
       "          3.26663863e-04, -2.35576320e-04, -3.43218796e-05],\n",
       "        ...,\n",
       "        [-1.06756606e-16, -9.43242660e-03,  5.84676810e-03, ...,\n",
       "          6.82750269e-03,  6.63463819e-03,  3.20614494e-03],\n",
       "        [ 7.50909592e-19, -2.03969520e-04,  1.88996613e-03, ...,\n",
       "          1.86479550e-03, -8.27300536e-04,  1.71079813e-04],\n",
       "        [-3.48673144e-18,  1.16568545e-03, -1.03476834e-03, ...,\n",
       "          3.13134226e-05, -8.49718946e-04,  2.27308655e-04]],\n",
       "\n",
       "       [[ 8.94136926e-02,  1.51935603e-02, -2.26148082e-04, ...,\n",
       "          6.56346493e-04, -3.07883957e-04,  3.85575816e-05],\n",
       "        [ 5.08184636e-17, -7.88179134e-03, -1.13708302e-03, ...,\n",
       "         -3.18015563e-05, -1.56261635e-03,  3.63699547e-03],\n",
       "        [-5.64922372e-17,  1.16206181e-03, -2.22802755e-03, ...,\n",
       "         -4.02914078e-03,  2.90564788e-03,  4.23333281e-04],\n",
       "        ...,\n",
       "        [ 2.57087443e-17,  2.27148325e-03, -1.40799779e-03, ...,\n",
       "         -1.64417479e-03, -1.59772985e-03, -7.72092361e-04],\n",
       "        [-3.40948937e-18,  9.26119359e-04, -8.58135187e-03, ...,\n",
       "         -8.46706515e-03,  3.75634086e-03, -7.76784331e-04],\n",
       "        [-1.76280573e-17,  5.89341916e-03, -5.23153444e-03, ...,\n",
       "          1.58312970e-04, -4.29597018e-03,  1.14921670e-03]],\n",
       "\n",
       "       [[ 1.58857938e-01,  2.69938262e-02, -4.01788775e-04, ...,\n",
       "          1.16610608e-03, -5.47005824e-04,  6.85038022e-05],\n",
       "        [ 2.37715498e-16, -3.68689611e-02, -5.31897736e-03, ...,\n",
       "         -1.48759374e-04, -7.30951110e-03,  1.70129148e-02],\n",
       "        [-2.57568814e-16,  5.29826570e-03, -1.01583942e-02, ...,\n",
       "         -1.83703296e-02,  1.32479136e-02,  1.93013159e-03],\n",
       "        ...,\n",
       "        [ 1.64395833e-16,  1.45251116e-02, -9.00351130e-03, ...,\n",
       "         -1.05137568e-02, -1.02167623e-02, -4.93718268e-03],\n",
       "        [-5.57520709e-18,  1.51439311e-03, -1.40322519e-02, ...,\n",
       "         -1.38453700e-02,  6.14237968e-03, -1.27020003e-03],\n",
       "        [ 2.59439019e-17, -8.67357564e-03,  7.69945400e-03, ...,\n",
       "         -2.32995394e-04,  6.32254745e-03, -1.69134719e-03]]],\n",
       "      shape=(1000, 1198, 16101))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0095382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = SHAPValueStorage(base_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved SHAP values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41894446",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.save_as_memmap(\n",
    "    shap_values=mlr_shap_values,\n",
    "    model_name='MLR',\n",
    "    metadata={\n",
    "        'date_created': '2026-01-13',\n",
    "        'test_samples': 1000,\n",
    "        'model_version': 'v2',\n",
    "        'description': 'SHAP values for Multiple Linear Regression model'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Computing XGBRF SHAP Values (this may take a few minutes...)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# computing for XGBRF automatically\n",
    "xgbrf_shap_values = comparator.compute_shap_values('XGBRF','kernel')\n",
    "\n",
    "print(\"\\n✓ SHAP computation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
