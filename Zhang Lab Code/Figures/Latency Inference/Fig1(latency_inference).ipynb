{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630a06aa",
   "metadata": {},
   "source": [
    "**This script contains the figure generating functions for Fig 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76a2526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed predictions...\n",
      "✓ Loaded predictions for 3 models\n",
      "  Training samples: 12748, Genes: 16100\n",
      "  Test samples: 3187, Genes: 16100\n",
      "  Val samples: 262, Genes: 16100\n",
      "\n",
      "✓ All functions loaded. Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "############### LOADING DATA ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e198841",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING LATENCY INFERENCE FUNCTIONS ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5253c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_benchmarks' from 'model_latency_inference' (/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      7\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel_latency_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_benchmarks\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Validate prerequisites\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'run_benchmarks' from 'model_latency_inference' (/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py)"
     ]
    }
   ],
   "source": [
    "############### LOADING IN DATA AND MODELS ###############\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/')\n",
    "from model_latency_inference import run_benchmarks\n",
    "\n",
    "# ============================================================================\n",
    "# Validate prerequisites\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    _ = y_validation, predictions_validation\n",
    "    print(\"✓ model_load.py data detected\")\n",
    "except NameError:\n",
    "    raise SystemExit(\n",
    "        \"\\nERROR: Please run model_load.py first!\\n\"\n",
    "        \"Usage:\\n\"\n",
    "        \"  %run model_load.py\\n\"\n",
    "        \"  %run benchmark_latency.py\\n\"\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# Build x_validation (TF features) from external data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nPreparing validation inputs...\")\n",
    "\n",
    "# Load external validation data\n",
    "validation_dataset = pd.read_csv(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/Liver_bulk_external.tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Load network and TF reference\n",
    "net = pd.read_csv(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "    sep='\\t'\n",
    ")\n",
    "tf_expression = pd.read_csv(\n",
    "    '~/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Determine features\n",
    "network_nodes = set(net['TF'].unique()) | set(net['Gene'].unique())\n",
    "usable_features = [tf for tf in tf_expression.columns if tf in network_nodes]\n",
    "\n",
    "# Build x_validation with zero-filling for missing features\n",
    "x_validation = pd.DataFrame(0, index=validation_dataset.index, columns=usable_features)\n",
    "present_features = [f for f in usable_features if f in validation_dataset.columns]\n",
    "x_validation[present_features] = validation_dataset[present_features]\n",
    "\n",
    "print(f\"  x_validation: {x_validation.shape}\")\n",
    "print(f\"  y_validation: {y_validation.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nLoading models...\")\n",
    "\n",
    "sys.path.append('/home/christianl/Zhang-Lab/Zhang Lab Code/Tuning/uncentered_RNN_tuning')\n",
    "from RNN_reconstructor import load_model_from_checkpoint\n",
    "\n",
    "# MLR\n",
    "mlr_loaded = joblib.load(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/MLR_model_v4(uncentered[FINAL]).joblib'\n",
    ")\n",
    "\n",
    "# XGBRF\n",
    "xgbrf_loaded = joblib.load(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/XGBRF/XGBRF_v5/all_models_batch_XGBRF[uncentered_REALFINAL].joblib'\n",
    ")\n",
    "\n",
    "# RNN\n",
    "RNN_val = load_model_from_checkpoint(\n",
    "    checkpoint_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt',\n",
    "    net_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "    X_in_df=x_validation,\n",
    "    y_out_df=y_validation,\n",
    "    device='cpu',\n",
    "    use_exact_training_params=True\n",
    ")\n",
    "\n",
    "print(\"✓ All models loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
