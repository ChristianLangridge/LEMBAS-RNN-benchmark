{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c380398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate/Fig_config_utilities.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected and enhanced Bland-Altman plot script\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def bland_altman_plot(data1, data2, ax, model1_name, model2_name, confidence_interval=1.96):\n",
    "    \"\"\"\n",
    "    Helper function to create a single Bland-Altman plot on given axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1, data2 : array-like\n",
    "        Predictions from two models (should be same shape)\n",
    "    ax : matplotlib axis\n",
    "        Axis to plot on\n",
    "    model1_name, model2_name : str\n",
    "        Names of models being compared\n",
    "    confidence_interval : float\n",
    "        Z-score for confidence interval (default 1.96 for 95% CI)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Statistics including mean difference, SD, and limits\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays and flatten\n",
    "    data1 = np.asarray(data1).ravel()\n",
    "    data2 = np.asarray(data2).ravel()\n",
    "    \n",
    "    # Check shapes match\n",
    "    if data1.shape != data2.shape:\n",
    "        raise ValueError(f\"Data shapes don't match: {data1.shape} vs {data2.shape}\")\n",
    "    \n",
    "    # Calculate mean and difference\n",
    "    mean = (data1 + data2) / 2  # This is correct!\n",
    "    diff = data1 - data2\n",
    "    \n",
    "    # Statistics\n",
    "    md = np.mean(diff)  # Mean difference\n",
    "    sd = np.std(diff, ddof=1)  # Standard deviation (use ddof=1 for sample SD)\n",
    "    \n",
    "    # Limits of agreement (typically ±1.96 SD for 95% CI)\n",
    "    ci_low = md - confidence_interval * sd\n",
    "    ci_high = md + confidence_interval * sd\n",
    "    \n",
    "    # Scatter plot (subsample if too many points)\n",
    "    n_points = len(mean)\n",
    "    if n_points > 50000:\n",
    "        # Subsample for plotting performance\n",
    "        sample_size = 50000\n",
    "        indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        mean_plot = mean[indices]\n",
    "        diff_plot = diff[indices]\n",
    "        alpha = 0.3\n",
    "    else:\n",
    "        mean_plot = mean\n",
    "        diff_plot = diff\n",
    "        alpha = 0.5\n",
    "    \n",
    "    ax.scatter(mean_plot, diff_plot, alpha=alpha, s=20, \n",
    "               color='steelblue', edgecolors='none')\n",
    "    \n",
    "    # Mean difference line\n",
    "    ax.axhline(md, color='red', linestyle='-', lw=2.5, \n",
    "               label=f'Mean diff: {md:.4f}')\n",
    "    \n",
    "    # Zero line (perfect agreement)\n",
    "    ax.axhline(0, color='black', linestyle='--', lw=1.5, alpha=0.5,\n",
    "               label='Perfect agreement')\n",
    "    \n",
    "    # Limits of agreement (confidence interval lines)\n",
    "    ax.axhline(ci_high, color='gray', linestyle='--', lw=2, alpha=0.7,\n",
    "               label=f'±{confidence_interval}σ limits')\n",
    "    ax.axhline(ci_low, color='gray', linestyle='--', lw=2, alpha=0.7)\n",
    "    \n",
    "    # Calculate percentage of points within limits\n",
    "    within_limits = np.sum((diff >= ci_low) & (diff <= ci_high))\n",
    "    pct_within = 100 * within_limits / len(diff)\n",
    "    \n",
    "    # Add text annotations for limits\n",
    "    x_pos = mean.max() * 0.98\n",
    "    ax.text(x_pos, ci_high, f'+{confidence_interval}σ: {ci_high:.4f}',\n",
    "           fontsize=9, verticalalignment='bottom', horizontalalignment='right',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    ax.text(x_pos, ci_low, f'-{confidence_interval}σ: {ci_low:.4f}',\n",
    "           fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Statistics box\n",
    "    textstr = (f'Mean diff: {md:.4f}\\n'\n",
    "               f'SD: {sd:.4f}\\n'\n",
    "               f'Within limits: {pct_within:.1f}%')\n",
    "    ax.text(0.02, 0.98, textstr, transform=ax.transAxes,\n",
    "           fontsize=9, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # Check for proportional bias (correlation between mean and difference)\n",
    "    corr, p_value = pearsonr(mean, diff)\n",
    "    if abs(corr) > 0.1 and p_value < 0.05:\n",
    "        # Add trend line to show proportional bias\n",
    "        z = np.polyfit(mean, diff, 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_trend = np.linspace(mean.min(), mean.max(), 100)\n",
    "        y_trend = p(x_trend)\n",
    "        ax.plot(x_trend, y_trend, 'r--', lw=1.5, alpha=0.5,\n",
    "               label=f'Trend (r={corr:.3f})')\n",
    "        \n",
    "        # Add warning about proportional bias\n",
    "        if abs(corr) > 0.3:\n",
    "            ax.text(0.98, 0.02, '⚠ Proportional bias detected', \n",
    "                   transform=ax.transAxes,\n",
    "                   fontsize=9, verticalalignment='bottom', \n",
    "                   horizontalalignment='right',\n",
    "                   bbox=dict(boxstyle='round', facecolor='orange', alpha=0.8))\n",
    "    \n",
    "    # Labels and formatting\n",
    "    ax.set_xlabel(f'Mean of {model1_name} & {model2_name}', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel(f'Difference ({model1_name} - {model2_name})', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{model1_name} vs {model2_name}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Return statistics\n",
    "    return {\n",
    "        'mean_diff': md,\n",
    "        'sd': sd,\n",
    "        'ci_low': ci_low,\n",
    "        'ci_high': ci_high,\n",
    "        'pct_within_limits': pct_within,\n",
    "        'proportional_bias_r': corr,\n",
    "        'proportional_bias_p': p_value\n",
    "    }\n",
    "\n",
    "\n",
    "def figure_3_bland_altman(predictions_dict, \n",
    "                         output_path='/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/figure_3_bland_altman.png'):\n",
    "    \"\"\"\n",
    "    Generate Bland-Altman plots for pairwise model comparisons.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions_dict : dict\n",
    "        Dictionary of predictions by model\n",
    "        Example: {'MLR': pred_mlr, 'XGBRFRegressor': pred_xgbrf, 'RNN': pred_rnn}\n",
    "    output_path : str\n",
    "        Path to save figure\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Statistics for each comparison\n",
    "    \"\"\"\n",
    "    set_publication_style()\n",
    "    model_names = list(predictions_dict.keys())\n",
    "    n_models = len(model_names)\n",
    "    \n",
    "    if n_models < 2:\n",
    "        raise ValueError(\"Need at least 2 models for comparison\")\n",
    "    \n",
    "    # all pairwise comparisons\n",
    "    from itertools import combinations\n",
    "    comparisons = list(combinations(model_names, 2))\n",
    "    n_comparisons = len(comparisons)\n",
    "    \n",
    "    print(f\"\\nGenerating {n_comparisons} Bland-Altman plots for pairwise comparisons...\")\n",
    "    \n",
    "    # subplot layout\n",
    "    if n_comparisons == 1:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=FIGSIZE_SINGLE)\n",
    "        axes = [axes]\n",
    "    elif n_comparisons == 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    elif n_comparisons == 3:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "    elif n_comparisons == 4:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.ravel()\n",
    "    elif n_comparisons <= 6:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.ravel()\n",
    "    else:\n",
    "        # For more than 6 comparisons, create a grid\n",
    "        n_cols = 3\n",
    "        n_rows = (n_comparisons + n_cols - 1) // n_cols\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5*n_rows))\n",
    "        axes = axes.ravel()\n",
    "    \n",
    "    # generate plots\n",
    "    statistics = {}\n",
    "    \n",
    "    for idx, (model1, model2) in enumerate(comparisons):\n",
    "        ax = axes[idx]\n",
    "        print(f\"  Comparing {model1} vs {model2}...\")\n",
    "        \n",
    "        stats = bland_altman_plot(\n",
    "            predictions_dict[model1],\n",
    "            predictions_dict[model2],\n",
    "            ax, model1, model2\n",
    "        )\n",
    "        \n",
    "        statistics[f'{model1}_vs_{model2}'] = stats\n",
    "    \n",
    "    # hide unused subplots\n",
    "    for idx in range(n_comparisons, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"\\nFigure 3 saved to {output_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # summary stats\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BLAND-ALTMAN COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for comparison, stats in statistics.items():\n",
    "        print(f\"\\n{comparison}:\")\n",
    "        print(f\"  Mean difference: {stats['mean_diff']:8.4f}\")\n",
    "        print(f\"  SD of difference: {stats['sd']:7.4f}\")\n",
    "        print(f\"  95% limits: [{stats['ci_low']:7.4f}, {stats['ci_high']:7.4f}]\")\n",
    "        print(f\"  Within limits: {stats['pct_within_limits']:5.1f}%\")\n",
    "        \n",
    "        if abs(stats['proportional_bias_r']) > 0.1 and stats['proportional_bias_p'] < 0.05:\n",
    "            print(f\"  ⚠ Proportional bias: r={stats['proportional_bias_r']:.3f}, p={stats['proportional_bias_p']:.2e}\")\n",
    "        \n",
    "        # interpretation\n",
    "        if abs(stats['mean_diff']) < 0.01:\n",
    "            print(\"  → Models show excellent agreement (negligible bias)\")\n",
    "        elif abs(stats['mean_diff']) < 0.1:\n",
    "            print(\"  → Models show good agreement (minor bias)\")\n",
    "        else:\n",
    "            print(\"  → Models show systematic difference\")\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ffe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting figure dimensions slightly bigger for more breathing room between subplots \n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR vs. XGBRF\n",
    "bland_altman_plot(mlr_y_pred, xgbrf_y_pred, axes[0], 'MLR', 'XGBRF', confidence_interval=1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR vs. RNN\n",
    "bland_altman_plot(mlr_y_pred, rnn_y_pred, axes[1], 'MLR', 'RNN', confidence_interval=1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRF vs. RNN\n",
    "bland_altman_plot(xgbrf_y_pred, rnn_y_pred, axes[2], 'XGBRF', 'RNN', confidence_interval=1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
