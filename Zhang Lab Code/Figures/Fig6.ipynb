{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ca9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3187, 16101)\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate/Fig_config_utilities.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b556274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# wrapping models in pipelines as to avoid issues of data leakage from data centering through cross-validation analysis\n",
    "mlr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "xgbrf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', MultiOutputRegressor(\n",
    "        xgb.XGBRFRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators=3,\n",
    "            n_jobs=-1,     \n",
    "            verbosity=0,\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Dictionary for cross-validation\n",
    "model_dict_cv = {\n",
    "    'MLR': mlr_pipeline,\n",
    "    'XGBRFRegressor': xgbrf_pipeline\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c770d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross-validation helper function (5-fold)\n",
    "def run_cross_validation(models_dict, x, y, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Helper function to run cross-validation for multiple models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models_dict : dict\n",
    "        Dictionary of models to evaluate\n",
    "        Example: {'MLR': reg_model, 'XGBRFRegressor': xgbrf_model}\n",
    "    x : np.ndarray\n",
    "        Features\n",
    "    y : np.ndarray\n",
    "        Targets\n",
    "    n_folds : int\n",
    "        Number of CV folds\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cv_results : dict\n",
    "        Cross-validation results for each model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RUNNING {n_folds}-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cv_results = {}\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Run cross-validation\n",
    "        scores = cross_val_score(model, x, y, cv=kfold, \n",
    "                                scoring='r2', n_jobs=-1)\n",
    "        \n",
    "        cv_results[model_name] = scores\n",
    "        \n",
    "        print(f\"  R² scores: {scores}\")\n",
    "        print(f\"  Mean: {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5139b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Evaluating MLR...\n"
     ]
    }
   ],
   "source": [
    "cv_results_models = run_cross_validation(model_dict,x_train_centered,y_train_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation stability plot \n",
    "def figure_6_cv_stability(cv_results_dict, \n",
    "                         output_path='/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/'):\n",
    "    \"\"\"\n",
    "    Generate boxplots of model performance across CV folds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results_dict : dict\n",
    "        Dictionary where keys are model names and values are arrays of \n",
    "        cross-validation fold scores.\n",
    "        \n",
    "        Simple format (single metric):\n",
    "        {\n",
    "            'MLR': [0.75, 0.76, 0.74, 0.75, 0.76],\n",
    "            'XGBRFRegressor': [0.72, 0.73, 0.71, 0.72, 0.73]\n",
    "        }\n",
    "        \n",
    "        Or multi-metric format:\n",
    "        {\n",
    "            'MLR': {\n",
    "                'r2': [0.75, 0.76, 0.74, 0.75, 0.76],\n",
    "                'rmse': [0.42, 0.41, 0.43, 0.42, 0.41]\n",
    "            },\n",
    "            'XGBRFRegressor': {\n",
    "                'r2': [0.72, 0.73, 0.71, 0.72, 0.73],\n",
    "                'rmse': [0.45, 0.44, 0.46, 0.45, 0.44]\n",
    "            }\n",
    "        }\n",
    "    output_path : str\n",
    "        Path to save figure\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    summary_df : pd.DataFrame\n",
    "        Summary statistics for each model\n",
    "    \"\"\"\n",
    "    set_publication_style()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CROSS-VALIDATION STABILITY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_names = list(cv_results_dict.keys())\n",
    "    \n",
    "    # Detect data structure\n",
    "    first_value = list(cv_results_dict.values())[0]\n",
    "    is_multi_metric = isinstance(first_value, dict)\n",
    "    \n",
    "    if is_multi_metric:\n",
    "        print(\"\\nDetected multi-metric CV results\")\n",
    "        # Extract metrics\n",
    "        available_metrics = list(first_value.keys())\n",
    "        print(f\"Available metrics: {available_metrics}\")\n",
    "        \n",
    "        # Use r2 as primary metric\n",
    "        if 'r2' in available_metrics:\n",
    "            primary_metric = 'r2'\n",
    "            metric_label = 'R²'\n",
    "        else:\n",
    "            primary_metric = available_metrics[0]\n",
    "            metric_label = primary_metric.upper()\n",
    "    else:\n",
    "        print(\"\\nDetected single-metric CV results\")\n",
    "        is_multi_metric = False\n",
    "        primary_metric = None\n",
    "        metric_label = 'R²'\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    cv_data = []\n",
    "    summary_stats = []\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        if is_multi_metric:\n",
    "            scores = cv_results_dict[model_name][primary_metric]\n",
    "        else:\n",
    "            scores = cv_results_dict[model_name]\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Store for dataframe\n",
    "        for fold_idx, score in enumerate(scores):\n",
    "            cv_data.append({\n",
    "                'Model': model_name, \n",
    "                'Fold': fold_idx, \n",
    "                'Score': score\n",
    "            })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores, ddof=1)  # Sample std\n",
    "        min_score = np.min(scores)\n",
    "        max_score = np.max(scores)\n",
    "        cv_coef = std_score / mean_score if mean_score != 0 else np.nan  # Coefficient of variation\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'Model': model_name,\n",
    "            'Mean': mean_score,\n",
    "            'Std': std_score,\n",
    "            'Min': min_score,\n",
    "            'Max': max_score,\n",
    "            'CV': cv_coef,\n",
    "            'Range': max_score - min_score\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Mean {metric_label}: {mean_score:.4f}\")\n",
    "        print(f\"  Std Dev:  {std_score:.4f}\")\n",
    "        print(f\"  Range:    [{min_score:.4f}, {max_score:.4f}]\")\n",
    "        print(f\"  CV (Std/Mean): {cv_coef:.4f}\")\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data)\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    \n",
    "    # LEFT PLOT: Box plot with individual points\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Box plot\n",
    "    bp = ax1.boxplot([cv_results_dict[m] if not is_multi_metric \n",
    "                       else cv_results_dict[m][primary_metric] \n",
    "                       for m in model_names],\n",
    "                      labels=model_names,\n",
    "                      patch_artist=True,\n",
    "                      widths=0.6,\n",
    "                      showmeans=True,\n",
    "                      meanprops=dict(marker='D', markerfacecolor='red', \n",
    "                                   markeredgecolor='red', markersize=8))\n",
    "    \n",
    "    # Color boxes\n",
    "    for patch, model_name in zip(bp['boxes'], model_names):\n",
    "        patch.set_facecolor(MODEL_COLORS.get(model_name, '#1f77b4'))\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    # Overlay individual points\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        if is_multi_metric:\n",
    "            scores = cv_results_dict[model_name][primary_metric]\n",
    "        else:\n",
    "            scores = cv_results_dict[model_name]\n",
    "        \n",
    "        # Add jitter to x-coordinates\n",
    "        x = np.random.normal(i + 1, 0.04, size=len(scores))\n",
    "        ax1.scatter(x, scores, alpha=0.6, color='black', s=50, zorder=3)\n",
    "    \n",
    "    ax1.set_ylabel(f'{metric_label} Score', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title(f'Cross-Validation Performance ({metric_label})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # summary stats\n",
    "    summary_text = \"CV Summary:\\n\"\n",
    "    for _, row in summary_df.iterrows():\n",
    "        summary_text += f\"{row['Model']:15s}: {row['Mean']:.4f} ± {row['Std']:.4f}\\n\"\n",
    "    \n",
    "    ax1.text(0.02, 0.98, summary_text, transform=ax1.transAxes,\n",
    "            fontsize=9, verticalalignment='top', horizontalalignment='left',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.9),\n",
    "            family='monospace')\n",
    "    \n",
    "    # RIGHT PLOT: Stability comparison (Coefficient of Variation)\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # sorted CV for better visualization\n",
    "    summary_df_sorted = summary_df.sort_values('CV')\n",
    "    \n",
    "    bars = ax2.barh(summary_df_sorted['Model'], summary_df_sorted['CV'],\n",
    "                    color=[MODEL_COLORS.get(m, '#1f77b4') for m in summary_df_sorted['Model']],\n",
    "                    alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # value labels\n",
    "    for i, (idx, row) in enumerate(summary_df_sorted.iterrows()):\n",
    "        ax2.text(row['CV'], i, f\"  {row['CV']:.4f}\", \n",
    "                va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    #reference line for \"good\" stability (CV < 0.05 = <5% variation)\n",
    "    ax2.axvline(x=0.05, color='green', linestyle='--', linewidth=2, \n",
    "                alpha=0.7, label='Good stability (CV < 0.05)')\n",
    "    \n",
    "    ax2.set_xlabel('Coefficient of Variation (Std/Mean)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Model Stability Across CV Folds\\n(Lower = More Stable)', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    ax2.legend(loc='lower right', fontsize=9)\n",
    "    ax2.invert_yaxis()  # best at top\n",
    "    \n",
    "    # interpretation\n",
    "    max_cv = summary_df['CV'].max()\n",
    "    if max_cv < 0.03:\n",
    "        stability_text = \"✓ All models very stable\"\n",
    "        color = 'lightgreen'\n",
    "    elif max_cv < 0.05:\n",
    "        stability_text = \"✓ All models stable\"\n",
    "        color = 'lightgreen'\n",
    "    elif max_cv < 0.10:\n",
    "        stability_text = \"~ Some instability\"\n",
    "        color = 'lightyellow'\n",
    "    else:\n",
    "        stability_text = \"⚠ High variability\"\n",
    "        color = 'lightsalmon'\n",
    "    \n",
    "    ax2.text(0.98, 0.02, stability_text, transform=ax2.transAxes,\n",
    "            fontsize=11, verticalalignment='bottom', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.9),\n",
    "            fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"\\nFigure 6 saved to {output_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_6_cv_stability(cv_results_models,'figure6_v1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
