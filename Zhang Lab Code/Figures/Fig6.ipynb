{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate/Fig_config_utilities.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation stability analysis \n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def figure_6_cv_stability(cv_results_dict, \n",
    "                         output_path='/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/figure_6_cv_stability.png'):\n",
    "    \"\"\"\n",
    "    Generate boxplots of model performance across CV folds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results_dict : dict\n",
    "        Dictionary where keys are model names and values are arrays of \n",
    "        cross-validation fold scores.\n",
    "        \n",
    "        Simple format (single metric):\n",
    "        {\n",
    "            'MLR': [0.75, 0.76, 0.74, 0.75, 0.76],\n",
    "            'XGBRFRegressor': [0.72, 0.73, 0.71, 0.72, 0.73]\n",
    "        }\n",
    "        \n",
    "        Or multi-metric format:\n",
    "        {\n",
    "            'MLR': {\n",
    "                'r2': [0.75, 0.76, 0.74, 0.75, 0.76],\n",
    "                'rmse': [0.42, 0.41, 0.43, 0.42, 0.41]\n",
    "            },\n",
    "            'XGBRFRegressor': {\n",
    "                'r2': [0.72, 0.73, 0.71, 0.72, 0.73],\n",
    "                'rmse': [0.45, 0.44, 0.46, 0.45, 0.44]\n",
    "            }\n",
    "        }\n",
    "    output_path : str\n",
    "        Path to save figure\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    summary_df : pd.DataFrame\n",
    "        Summary statistics for each model\n",
    "    \"\"\"\n",
    "    set_publication_style()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CROSS-VALIDATION STABILITY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_names = list(cv_results_dict.keys())\n",
    "    \n",
    "    # Detect data structure\n",
    "    first_value = list(cv_results_dict.values())[0]\n",
    "    is_multi_metric = isinstance(first_value, dict)\n",
    "    \n",
    "    if is_multi_metric:\n",
    "        print(\"\\nDetected multi-metric CV results\")\n",
    "        # Extract metrics\n",
    "        available_metrics = list(first_value.keys())\n",
    "        print(f\"Available metrics: {available_metrics}\")\n",
    "        \n",
    "        # Use r2 as primary metric\n",
    "        if 'r2' in available_metrics:\n",
    "            primary_metric = 'r2'\n",
    "            metric_label = 'R²'\n",
    "        else:\n",
    "            primary_metric = available_metrics[0]\n",
    "            metric_label = primary_metric.upper()\n",
    "    else:\n",
    "        print(\"\\nDetected single-metric CV results\")\n",
    "        is_multi_metric = False\n",
    "        primary_metric = None\n",
    "        metric_label = 'R²'\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    cv_data = []\n",
    "    summary_stats = []\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        if is_multi_metric:\n",
    "            scores = cv_results_dict[model_name][primary_metric]\n",
    "        else:\n",
    "            scores = cv_results_dict[model_name]\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Store for dataframe\n",
    "        for fold_idx, score in enumerate(scores):\n",
    "            cv_data.append({\n",
    "                'Model': model_name, \n",
    "                'Fold': fold_idx, \n",
    "                'Score': score\n",
    "            })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores, ddof=1)  # Sample std\n",
    "        min_score = np.min(scores)\n",
    "        max_score = np.max(scores)\n",
    "        cv_coef = std_score / mean_score if mean_score != 0 else np.nan  # Coefficient of variation\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'Model': model_name,\n",
    "            'Mean': mean_score,\n",
    "            'Std': std_score,\n",
    "            'Min': min_score,\n",
    "            'Max': max_score,\n",
    "            'CV': cv_coef,\n",
    "            'Range': max_score - min_score\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Mean {metric_label}: {mean_score:.4f}\")\n",
    "        print(f\"  Std Dev:  {std_score:.4f}\")\n",
    "        print(f\"  Range:    [{min_score:.4f}, {max_score:.4f}]\")\n",
    "        print(f\"  CV (Std/Mean): {cv_coef:.4f}\")\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data)\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    \n",
    "    # LEFT PLOT: Box plot with individual points\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Box plot\n",
    "    bp = ax1.boxplot([cv_results_dict[m] if not is_multi_metric \n",
    "                       else cv_results_dict[m][primary_metric] \n",
    "                       for m in model_names],\n",
    "                      labels=model_names,\n",
    "                      patch_artist=True,\n",
    "                      widths=0.6,\n",
    "                      showmeans=True,\n",
    "                      meanprops=dict(marker='D', markerfacecolor='red', \n",
    "                                   markeredgecolor='red', markersize=8))\n",
    "    \n",
    "    # Color boxes\n",
    "    for patch, model_name in zip(bp['boxes'], model_names):\n",
    "        patch.set_facecolor(MODEL_COLORS.get(model_name, '#1f77b4'))\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    # Overlay individual points\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        if is_multi_metric:\n",
    "            scores = cv_results_dict[model_name][primary_metric]\n",
    "        else:\n",
    "            scores = cv_results_dict[model_name]\n",
    "        \n",
    "        # Add jitter to x-coordinates\n",
    "        x = np.random.normal(i + 1, 0.04, size=len(scores))\n",
    "        ax1.scatter(x, scores, alpha=0.6, color='black', s=50, zorder=3)\n",
    "    \n",
    "    ax1.set_ylabel(f'{metric_label} Score', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title(f'Cross-Validation Performance ({metric_label})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add summary statistics\n",
    "    summary_text = \"CV Summary:\\n\"\n",
    "    for _, row in summary_df.iterrows():\n",
    "        summary_text += f\"{row['Model']:15s}: {row['Mean']:.4f} ± {row['Std']:.4f}\\n\"\n",
    "    \n",
    "    ax1.text(0.02, 0.98, summary_text, transform=ax1.transAxes,\n",
    "            fontsize=9, verticalalignment='top', horizontalalignment='left',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.9),\n",
    "            family='monospace')\n",
    "    \n",
    "    # RIGHT PLOT: Stability comparison (Coefficient of Variation)\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Sort by CV for better visualization\n",
    "    summary_df_sorted = summary_df.sort_values('CV')\n",
    "    \n",
    "    bars = ax2.barh(summary_df_sorted['Model'], summary_df_sorted['CV'],\n",
    "                    color=[MODEL_COLORS.get(m, '#1f77b4') for m in summary_df_sorted['Model']],\n",
    "                    alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, row) in enumerate(summary_df_sorted.iterrows()):\n",
    "        ax2.text(row['CV'], i, f\"  {row['CV']:.4f}\", \n",
    "                va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Add reference line for \"good\" stability (CV < 0.05 = <5% variation)\n",
    "    ax2.axvline(x=0.05, color='green', linestyle='--', linewidth=2, \n",
    "                alpha=0.7, label='Good stability (CV < 0.05)')\n",
    "    \n",
    "    ax2.set_xlabel('Coefficient of Variation (Std/Mean)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Model Stability Across CV Folds\\n(Lower = More Stable)', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    ax2.legend(loc='lower right', fontsize=9)\n",
    "    ax2.invert_yaxis()  # Best at top\n",
    "    \n",
    "    # Add interpretation\n",
    "    max_cv = summary_df['CV'].max()\n",
    "    if max_cv < 0.03:\n",
    "        stability_text = \"✓ All models very stable\"\n",
    "        color = 'lightgreen'\n",
    "    elif max_cv < 0.05:\n",
    "        stability_text = \"✓ All models stable\"\n",
    "        color = 'lightgreen'\n",
    "    elif max_cv < 0.10:\n",
    "        stability_text = \"~ Some instability\"\n",
    "        color = 'lightyellow'\n",
    "    else:\n",
    "        stability_text = \"⚠ High variability\"\n",
    "        color = 'lightsalmon'\n",
    "    \n",
    "    ax2.text(0.98, 0.02, stability_text, transform=ax2.transAxes,\n",
    "            fontsize=11, verticalalignment='bottom', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.9),\n",
    "            fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"\\nFigure 6 saved to {output_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def run_cross_validation(models_dict, x, y, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Helper function to run cross-validation for multiple models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models_dict : dict\n",
    "        Dictionary of models to evaluate\n",
    "        Example: {'MLR': reg_model, 'XGBRFRegressor': xgbrf_model}\n",
    "    x : np.ndarray\n",
    "        Features\n",
    "    y : np.ndarray\n",
    "        Targets\n",
    "    n_folds : int\n",
    "        Number of CV folds\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cv_results : dict\n",
    "        Cross-validation results for each model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RUNNING {n_folds}-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cv_results = {}\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Run cross-validation\n",
    "        scores = cross_val_score(model, x, y, cv=kfold, \n",
    "                                scoring='r2', n_jobs=-1)\n",
    "        \n",
    "        cv_results[model_name] = scores\n",
    "        \n",
    "        print(f\"  R² scores: {scores}\")\n",
    "        print(f\"  Mean: {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def run_comprehensive_cv(models_dict, x, y, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Run comprehensive cross-validation with multiple metrics.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cv_results : dict\n",
    "        Multi-metric CV results for each model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RUNNING {n_folds}-FOLD CROSS-VALIDATION (MULTIPLE METRICS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cv_results = {}\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        fold_results = {\n",
    "            'r2': [],\n",
    "            'rmse': [],\n",
    "            'mae': []\n",
    "        }\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(x)):\n",
    "            x_train_fold, x_val_fold = x[train_idx], x[val_idx]\n",
    "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(x_train_fold, y_train_fold)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(x_val_fold)\n",
    "            \n",
    "            # Calculate metrics (flatten for multi-output)\n",
    "            y_val_flat = y_val_fold.ravel()\n",
    "            y_pred_flat = y_pred.ravel()\n",
    "            \n",
    "            r2 = r2_score(y_val_flat, y_pred_flat)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_flat, y_pred_flat))\n",
    "            mae = mean_absolute_error(y_val_flat, y_pred_flat)\n",
    "            \n",
    "            fold_results['r2'].append(r2)\n",
    "            fold_results['rmse'].append(rmse)\n",
    "            fold_results['mae'].append(mae)\n",
    "            \n",
    "            print(f\"  Fold {fold_idx + 1}: R²={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "        \n",
    "        cv_results[model_name] = fold_results\n",
    "        \n",
    "        print(f\"  Mean R²: {np.mean(fold_results['r2']):.4f} (±{np.std(fold_results['r2']):.4f})\")\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nTo generate Figure 6 (CV stability), you have two options:\\n\")\n",
    "    \n",
    "    print(\"OPTION 1 - Use pre-computed CV results:\")\n",
    "    print(\"cv_results = {\")\n",
    "    print(\"    'MLR': [0.84, 0.85, 0.83, 0.84, 0.85],\")\n",
    "    print(\"    'XGBRFRegressor': [0.72, 0.73, 0.71, 0.72, 0.73]\")\n",
    "    print(\"}\")\n",
    "    print(\"summary = figure_6_cv_stability(cv_results)\")\n",
    "    \n",
    "    print(\"\\nOPTION 2 - Run CV and generate plot:\")\n",
    "    print(\"models = {'MLR': reg_loaded, 'XGBRFRegressor': xgbrf_model}\")\n",
    "    print(\"cv_results = run_cross_validation(models, x_train_centered, y_train_centered, n_folds=5)\")\n",
    "    print(\"summary = figure_6_cv_stability(cv_results)\")\n",
    "    \n",
    "    print(\"\\nOPTION 3 - Comprehensive CV with multiple metrics:\")\n",
    "    print(\"cv_results = run_comprehensive_cv(models, x_train_centered, y_train_centered, n_folds=5)\")\n",
    "    print(\"summary = figure_6_cv_stability(cv_results)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
