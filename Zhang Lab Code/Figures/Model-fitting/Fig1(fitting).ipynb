{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e991bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data shapes: x_train (12748, 1197), y_train (12748, 16100)\n",
      "\n",
      "Loading MLR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christianl/miniconda3/envs/remote_training/lib/python3.12/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/christianl/miniconda3/envs/remote_training/lib/python3.12/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR predictions: (12748, 16100)\n",
      "\n",
      "Loading XGBRF models...\n",
      "XGBRF predictions: (12748, 16100)\n",
      "\n",
      "Loading RNN model...\n",
      "======================================================================\n",
      "LOADING MODEL - EXACT TRAINING SCRIPT SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "1. Loading checkpoint from: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt\n",
      "\n",
      "2. Loading network from: /home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv\n",
      "   Network shape: (1153904, 3)\n",
      "   Network columns: ['TF', 'Gene', 'Interaction']\n",
      "\n",
      "3. Formatting network...\n",
      "\n",
      "4. Using EXACT benchmark.py parameters\n",
      "   projection_amplitude_in: 1.2\n",
      "   projection_amplitude_out: 1.2\n",
      "   bionet_params: {'target_steps': 150, 'max_steps': 10, 'exp_factor': 50, 'tolerance': 1e-20, 'leak': 0.01}\n",
      "\n",
      "5. Initializing model with DataFrames...\n",
      "   Input X_in shape: (12748, 1197)\n",
      "   Input y_out shape: (12748, 16100)\n",
      "  Filtered X_in: 1197 → 1197 features\n",
      "  Filtered y_out: 16100 → 16100 features\n",
      "   ✓ Model initialized (data automatically filtered)\n",
      "\n",
      "6. Converting DataFrames to tensors...\n",
      "   ✓ Tensors created\n",
      "\n",
      "7. Applying training settings...\n",
      "   ✓ Set input_layer.weights.requires_grad = False\n",
      "   ✓ Applied prescale_weights(target_radius=0.8)\n",
      "\n",
      "8. Loading trained weights...\n",
      "   ✓ Weights loaded\n",
      "   ✓ Model set to eval mode\n",
      "\n",
      "======================================================================\n",
      "✅ MODEL LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Model ready for inference:\n",
      "  Input features: 1197\n",
      "  Output features: 16100\n",
      "  Total network nodes: 16371\n",
      "======================================================================\n",
      "LOADING MODEL - EXACT TRAINING SCRIPT SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "1. Loading checkpoint from: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt\n",
      "\n",
      "2. Loading network from: /home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv\n",
      "   Network shape: (1153904, 3)\n",
      "   Network columns: ['TF', 'Gene', 'Interaction']\n",
      "\n",
      "3. Formatting network...\n",
      "\n",
      "4. Using EXACT benchmark.py parameters\n",
      "   projection_amplitude_in: 1.2\n",
      "   projection_amplitude_out: 1.2\n",
      "   bionet_params: {'target_steps': 150, 'max_steps': 10, 'exp_factor': 50, 'tolerance': 1e-20, 'leak': 0.01}\n",
      "\n",
      "5. Initializing model with DataFrames...\n",
      "   Input X_in shape: (3187, 1197)\n",
      "   Input y_out shape: (3187, 16100)\n",
      "  Filtered X_in: 1197 → 1197 features\n",
      "  Filtered y_out: 16100 → 16100 features\n",
      "   ✓ Model initialized (data automatically filtered)\n",
      "\n",
      "6. Converting DataFrames to tensors...\n",
      "   ✓ Tensors created\n",
      "\n",
      "7. Applying training settings...\n",
      "   ✓ Set input_layer.weights.requires_grad = False\n",
      "   ✓ Applied prescale_weights(target_radius=0.8)\n",
      "\n",
      "8. Loading trained weights...\n",
      "   ✓ Weights loaded\n",
      "   ✓ Model set to eval mode\n",
      "\n",
      "======================================================================\n",
      "✅ MODEL LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Model ready for inference:\n",
      "  Input features: 1197\n",
      "  Output features: 16100\n",
      "  Total network nodes: 16371\n",
      "RNN predictions: (12748, 16100)\n",
      "\n",
      "Saving predictions to: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved predictions/model_predictions_uncentered_v1.npz\n",
      "\n",
      "✓ Predictions saved successfully!\n",
      "File size: 4979.13 MB\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_predictions.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c9530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed predictions...\n",
      "✓ Loaded predictions for 3 models\n",
      "  Training samples: 12748, Genes: 16100\n",
      "  Test samples: 3187, Genes: 16100\n",
      "\n",
      "✓ All functions loaded. Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "# Check what your y_test columns actually are:\n",
    "print(\"y_test columns type:\", type(y_train.columns))\n",
    "print(\"First 5 column names:\", y_train.columns[:5].tolist())\n",
    "\n",
    "# Also check if y_test is actually a DataFrame or numpy array:\n",
    "print(\"y_test type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlr_loaded.score: 0.9041830139739396\n"
     ]
    }
   ],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# diagnostics of MLR r2 scores for fitting to training set \n",
    "\n",
    "# checking to ensure predictions and groundtruth are comparable (they do)\n",
    "assert y_train.shape == mlr_y_pred_train.shape\n",
    "\n",
    "# compare r2 values\n",
    "# mlr_loaded.score: 0.9041830139739396 on training data (fit)\n",
    "print(\"mlr_loaded.score:\", mlr_loaded.score(x_train, y_train))\n",
    "\n",
    "# compute_metrics() is the flattened r2, where each gene's r2 is treated equally (flattened) before aggregating\n",
    "# compute_metrics r2: 0.9323357932034118\n",
    "\n",
    "# compute_metrics r2 > .score() r2 -> figured out that .score() when unspecified does uniform-average, different to compute_metrics r2 \n",
    "# which calculates the variance-weighted r2, taking into account the individual variances of each gene.\n",
    "# given the difference of 0.365 between the two, positive correlation between variance and R2 indicates that model performs better\n",
    "# on genes with higher variance (more distinct expression patterns) than lower variance ones (ie. housekeeping, \"silenced\", etc.)\n",
    "\n",
    "metrics_flat_mlr_train = compute_metrics(y_train.values, mlr_y_pred_train)\n",
    "print(\"compute global R²:\", metrics_flat_mlr_train['r2'])\n",
    "\n",
    "mlr_train_agg_R2 = metrics_flat_mlr_train['r2']\n",
    "mlr_train_agg_Pearsons = metrics_flat_mlr_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {mlr_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {mlr_train_agg_Pearsons}\")\n",
    "\n",
    "# compute_metrics_per_gene() looks at the indiviudal r2 at per-gene resolution (using DFs to maintain biological relevance of each column) \n",
    "\n",
    "#compute_metrics_per_gene r2: 0        0.861767\n",
    "#1        0.747973\n",
    "#2        0.373796\n",
    "#3        0.769920\n",
    "#4        0.859807\n",
    "#           ...   \n",
    "#16095    0.736619\n",
    "#16096    0.866326\n",
    "#16097    0.924248\n",
    "#16098    0.912513\n",
    "#16099    0.900036\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_mlr_train = compute_metrics_per_gene_test(y_train, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_pergene_R2 = metrics_flat_per_gene_mlr_train['r2']\n",
    "mlr_train_pergene_Pearsons = metrics_flat_per_gene_mlr_train['[pearson_r]']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", mlr_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", mlr_train_pergene_Pearsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# same diagnostics for XGBRF.v3 (trained on same x_train)\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == xgbrf_y_pred_train.shape\n",
    "\n",
    "# computing XGBRF metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.9136\n",
    "metrics_flat_xgbrf_train = compute_metrics(y_train.values, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_agg_R2 = metrics_flat_xgbrf_train['r2']\n",
    "xgbrf_train_agg_Pearsons = metrics_flat_xgbrf_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.798614\n",
    "#1        0.732539\n",
    "#2        0.390864\n",
    "#3        0.717345\n",
    "#4        0.819955\n",
    "#           ...   \n",
    "#16095    0.677608\n",
    "#16096    0.801420\n",
    "#16097    0.883455\n",
    "#16098    0.861673\n",
    "#16099    0.863954\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_xgbrf_train = compute_metrics_per_gene_test(y_train, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_pergene_R2 = metrics_flat_per_gene_xgbrf_train['r2']\n",
    "xgbrf_train_pergene_Pearsons = metrics_flat_per_gene_xgbrf_train['[pearson_r]']\n",
    "\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", xgbrf_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", xgbrf_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "\n",
    "# same diagnostics for RNN.v1 (used as a reference for data preprocessing of other models )\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == rnn_y_pred_train.shape\n",
    "\n",
    "# computing RNN metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.7366\n",
    "metrics_flat_rnn_train = compute_metrics(y_train.values, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_agg_R2 = metrics_flat_rnn_train['r2']\n",
    "rnn_train_agg_Pearsons = metrics_flat_rnn_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "#compute_metrics_per_gene R²: 0        0.249111\n",
    "#1       -0.058234\n",
    "#2       -0.235948\n",
    "#3        0.382344\n",
    "#4        0.671084\n",
    "#           ...   \n",
    "#16095    0.336766\n",
    "#16096    0.509802\n",
    "#16097    0.657901\n",
    "#16098    0.514623\n",
    "#16099    0.622254\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_rnn_train = compute_metrics_per_gene_test(y_train, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_pergene_R2 = metrics_flat_per_gene_rnn_train['r2']\n",
    "rnn_train_pergene_Pearsons = metrics_flat_per_gene_rnn_train['[pearson_r]']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", rnn_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", rnn_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats as scipy_stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import your existing configuration\n",
    "import sys\n",
    "sys.path.append('/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate')\n",
    "from Fig_config_utilities import (\n",
    "    MODEL_COLORS, DPI, FIGSIZE_SINGLE, FIGSIZE_WIDE,\n",
    "    set_publication_style, predictions_train, y_train\n",
    ")\n",
    "\n",
    "# Set publication style\n",
    "set_publication_style()\n",
    "\n",
    "###############################################################################\n",
    "# FIGURE 1: Aggregate Pearson's R with 95% CI\n",
    "###############################################################################\n",
    "\n",
    "def compute_aggregate_pearson_with_ci(y_true, y_pred, n_bootstrap=1000):\n",
    "    \"\"\"\n",
    "    Compute aggregate Pearson's R across all prediction tasks with 95% CI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : numpy array (n_samples, n_genes)\n",
    "        Ground truth gene expression\n",
    "    y_pred : numpy array (n_samples, n_genes)\n",
    "        Predicted gene expression\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap iterations for CI estimation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with 'pearson_r', 'ci_lower', 'ci_upper'\n",
    "    \"\"\"\n",
    "    # Flatten all predictions for aggregate correlation\n",
    "    y_true_flat = y_true.ravel()\n",
    "    y_pred_flat = y_pred.ravel()\n",
    "    \n",
    "    # Overall Pearson's R\n",
    "    pearson_r, _ = pearsonr(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    # Bootstrap for 95% CI\n",
    "    bootstrap_rs = []\n",
    "    n_total = len(y_true_flat)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Sample with replacement\n",
    "        indices = np.random.choice(n_total, size=n_total, replace=True)\n",
    "        r_boot, _ = pearsonr(y_true_flat[indices], y_pred_flat[indices])\n",
    "        bootstrap_rs.append(r_boot)\n",
    "    \n",
    "    # 95% CI\n",
    "    ci_lower = np.percentile(bootstrap_rs, 2.5)\n",
    "    ci_upper = np.percentile(bootstrap_rs, 97.5)\n",
    "    \n",
    "    return {\n",
    "        'pearson_r': pearson_r,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'ci_range': ci_upper - ci_lower\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_aggregate_pearson_comparison(predictions_dict, y_true, save_path=None):\n",
    "    \"\"\"\n",
    "    Create bar plot comparing aggregate Pearson's R across models with 95% CI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions_dict : dict\n",
    "        Dictionary with model names as keys and prediction arrays as values\n",
    "    y_true : DataFrame or numpy array\n",
    "        Ground truth values\n",
    "    save_path : str, optional\n",
    "        Path to save the figure\n",
    "    \"\"\"\n",
    "    # Convert y_true to numpy if needed\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true_array = y_true.values\n",
    "    else:\n",
    "        y_true_array = y_true\n",
    "    \n",
    "    # Compute metrics for each model\n",
    "    results = {}\n",
    "    for model_name, y_pred in predictions_dict.items():\n",
    "        results[model_name] = compute_aggregate_pearson_with_ci(y_true_array, y_pred)\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = list(results.keys())\n",
    "    pearson_rs = [results[m]['pearson_r'] for m in models]\n",
    "    ci_lowers = [results[m]['ci_lower'] for m in models]\n",
    "    ci_uppers = [results[m]['ci_upper'] for m in models]\n",
    "    errors_lower = [results[m]['pearson_r'] - results[m]['ci_lower'] for m in models]\n",
    "    errors_upper = [results[m]['ci_upper'] - results[m]['pearson_r'] for m in models]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "    \n",
    "    # Bar positions\n",
    "    x_pos = np.arange(len(models))\n",
    "    \n",
    "    # Create bars with error bars\n",
    "    bars = ax.bar(x_pos, pearson_rs, \n",
    "                  color=[MODEL_COLORS.get(m, '#888888') for m in models],\n",
    "                  alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add error bars (95% CI)\n",
    "    ax.errorbar(x_pos, pearson_rs, \n",
    "                yerr=[errors_lower, errors_upper],\n",
    "                fmt='none', color='black', capsize=8, capthick=2, \n",
    "                linewidth=2, label='95% CI')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_ylabel(\"Pearson's R (Aggregate)\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Model Architecture\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"Model Performance on Training Data\\n(Aggregate across 16,100 genes)\", \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(models, fontsize=12)\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    \n",
    "    # Add grid for readability\n",
    "    ax.yaxis.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, r_val, ci_low, ci_high) in enumerate(zip(bars, pearson_rs, ci_lowers, ci_uppers)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{r_val:.4f}\\n[{ci_low:.4f}, {ci_high:.4f}]',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    return fig, ax, results\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# FIGURE 2: Pearson's R by CV bins\n",
    "###############################################################################\n",
    "\n",
    "def compute_cv_per_gene(y_true):\n",
    "    \"\"\"\n",
    "    Compute coefficient of variation (CV) for each gene.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : numpy array (n_samples, n_genes)\n",
    "        Ground truth gene expression\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy array of CV values (one per gene)\n",
    "    \"\"\"\n",
    "    means = np.mean(y_true, axis=0)\n",
    "    stds = np.std(y_true, axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    cv = np.zeros_like(means)\n",
    "    mask = means > 1e-10\n",
    "    cv[mask] = (stds[mask] / means[mask]) * 100  # Express as percentage\n",
    "    \n",
    "    return cv\n",
    "\n",
    "\n",
    "def compute_pearson_per_gene(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Pearson's R for each gene individually.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : numpy array (n_samples, n_genes)\n",
    "    y_pred : numpy array (n_samples, n_genes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy array of Pearson's R values (one per gene)\n",
    "    \"\"\"\n",
    "    n_genes = y_true.shape[1]\n",
    "    pearson_rs = np.zeros(n_genes)\n",
    "    \n",
    "    for i in range(n_genes):\n",
    "        if np.var(y_true[:, i]) > 1e-10:\n",
    "            r, _ = pearsonr(y_true[:, i], y_pred[:, i])\n",
    "            pearson_rs[i] = r\n",
    "        else:\n",
    "            pearson_rs[i] = np.nan\n",
    "    \n",
    "    return pearson_rs\n",
    "\n",
    "\n",
    "def create_cv_bins(cv_values, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Create CV bins for grouping genes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cv_values : numpy array\n",
    "        CV values for each gene\n",
    "    bin_edges : list, optional\n",
    "        Custom bin edges. If None, creates bins from 0-5%, 5-10%, ..., 20-25%\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bin_labels, bin_assignments\n",
    "    \"\"\"\n",
    "    if bin_edges is None:\n",
    "        # Default: 0-5%, 5-10%, 10-15%, 15-20%, 20-25%\n",
    "        bin_edges = [0, 5, 10, 15, 20, 25]\n",
    "    \n",
    "    bin_labels = [f\"{bin_edges[i]}-{bin_edges[i+1]}%\" for i in range(len(bin_edges)-1)]\n",
    "    bin_assignments = np.digitize(cv_values, bin_edges) - 1\n",
    "    \n",
    "    # Handle values outside bins\n",
    "    bin_assignments = np.clip(bin_assignments, 0, len(bin_labels)-1)\n",
    "    \n",
    "    return bin_labels, bin_assignments\n",
    "\n",
    "\n",
    "def plot_pearson_by_cv_bins(predictions_dict, y_true, bin_edges=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Create grouped bar plot of Pearson's R by CV bins for each model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions_dict : dict\n",
    "        Dictionary with model names as keys and prediction arrays as values\n",
    "    y_true : DataFrame or numpy array\n",
    "        Ground truth values\n",
    "    bin_edges : list, optional\n",
    "        Custom CV bin edges\n",
    "    save_path : str, optional\n",
    "        Path to save the figure\n",
    "    \"\"\"\n",
    "    # Convert y_true to numpy if needed\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true_array = y_true.values\n",
    "    else:\n",
    "        y_true_array = y_true\n",
    "    \n",
    "    # Compute CV for each gene\n",
    "    cv_values = compute_cv_per_gene(y_true_array)\n",
    "    \n",
    "    # Create bins\n",
    "    bin_labels, bin_assignments = create_cv_bins(cv_values, bin_edges)\n",
    "    n_bins = len(bin_labels)\n",
    "    \n",
    "    # Compute per-gene Pearson's R for each model\n",
    "    model_results = {}\n",
    "    for model_name, y_pred in predictions_dict.items():\n",
    "        pearson_per_gene = compute_pearson_per_gene(y_true_array, y_pred)\n",
    "        model_results[model_name] = pearson_per_gene\n",
    "    \n",
    "    # Aggregate by CV bins\n",
    "    bin_data = {model: {bin_idx: [] for bin_idx in range(n_bins)} \n",
    "                for model in predictions_dict.keys()}\n",
    "    \n",
    "    for gene_idx in range(len(cv_values)):\n",
    "        bin_idx = bin_assignments[gene_idx]\n",
    "        for model_name, pearson_vals in model_results.items():\n",
    "            if not np.isnan(pearson_vals[gene_idx]):\n",
    "                bin_data[model_name][bin_idx].append(pearson_vals[gene_idx])\n",
    "    \n",
    "    # Calculate mean and SEM for each bin and model\n",
    "    bin_means = {model: [] for model in predictions_dict.keys()}\n",
    "    bin_sems = {model: [] for model in predictions_dict.keys()}\n",
    "    \n",
    "    for model_name in predictions_dict.keys():\n",
    "        for bin_idx in range(n_bins):\n",
    "            values = bin_data[model_name][bin_idx]\n",
    "            if len(values) > 0:\n",
    "                bin_means[model_name].append(np.mean(values))\n",
    "                bin_sems[model_name].append(scipy_stats.sem(values))\n",
    "            else:\n",
    "                bin_means[model_name].append(0)\n",
    "                bin_sems[model_name].append(0)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_WIDE)\n",
    "    \n",
    "    # Bar positions\n",
    "    x = np.arange(n_bins)\n",
    "    width = 0.25\n",
    "    models = list(predictions_dict.keys())\n",
    "    \n",
    "    # Create grouped bars\n",
    "    for i, model_name in enumerate(models):\n",
    "        offset = (i - len(models)/2 + 0.5) * width\n",
    "        bars = ax.bar(x + offset, bin_means[model_name], width,\n",
    "                      label=model_name,\n",
    "                      color=MODEL_COLORS.get(model_name, '#888888'),\n",
    "                      alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        # Add error bars (SEM)\n",
    "        ax.errorbar(x + offset, bin_means[model_name], \n",
    "                   yerr=bin_sems[model_name],\n",
    "                   fmt='none', color='black', capsize=4, \n",
    "                   linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_ylabel(\"Pearson's R (per-gene mean)\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Coefficient of Variation (CV) Bins\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"Model Performance Across Gene Expression Variability\\n(Training Data)\", \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(bin_labels, fontsize=11)\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    ax.legend(loc='upper right', fontsize=12, framealpha=0.9)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.yaxis.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Summary: Mean Pearson's R by CV Bin\")\n",
    "    print(\"=\"*70)\n",
    "    for model_name in models:\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for i, bin_label in enumerate(bin_labels):\n",
    "            n_genes_in_bin = len(bin_data[model_name][i])\n",
    "            print(f\"  {bin_label}: R={bin_means[model_name][i]:.4f} \"\n",
    "                  f\"± {bin_sems[model_name][i]:.4f} (n={n_genes_in_bin} genes)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return fig, ax, bin_data, bin_means, bin_sems\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# MAIN EXECUTION\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Creating model fitness visualizations...\")\n",
    "    print(f\"Using {len(predictions_train)} models\")\n",
    "    print(f\"Training set size: {y_train.shape}\")\n",
    "    \n",
    "    # Figure 1: Aggregate Pearson's R with 95% CI\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FIGURE 1: Aggregate Pearson's R Comparison\")\n",
    "    print(\"=\"*70)\n",
    "    fig1, ax1, results1 = plot_aggregate_pearson_comparison(\n",
    "        predictions_train, \n",
    "        y_train,\n",
    "        save_path='/mnt/user-data/outputs/Fig1_aggregate_pearson_comparison.png'\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    for model_name, metrics in results1.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Pearson's R: {metrics['pearson_r']:.6f}\")\n",
    "        print(f\"  95% CI: [{metrics['ci_lower']:.6f}, {metrics['ci_upper']:.6f}]\")\n",
    "        print(f\"  CI Range: {metrics['ci_range']:.6f}\")\n",
    "    \n",
    "    # Figure 2: Pearson's R by CV bins\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FIGURE 2: Pearson's R by CV Bins\")\n",
    "    print(\"=\"*70)\n",
    "    fig2, ax2, bin_data, bin_means, bin_sems = plot_pearson_by_cv_bins(\n",
    "        predictions_train,\n",
    "        y_train,\n",
    "        bin_edges=[0, 5, 10, 15, 20, 25],\n",
    "        save_path='/mnt/user-data/outputs/Fig2_pearson_by_cv_bins.png'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nVisualization complete! Check the output directory for figures.\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
