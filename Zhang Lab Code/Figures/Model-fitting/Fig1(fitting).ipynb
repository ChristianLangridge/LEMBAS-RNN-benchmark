{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed predictions...\n",
      "✓ Loaded predictions for 3 models\n",
      "  Training samples: 12748, Genes: 16100\n",
      "  Test samples: 3187, Genes: 16100\n",
      "\n",
      "✓ All functions loaded. Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b0edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/Model-fitting/figure1_agg_pearson_R.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "# Check what your y_test columns actually are:\n",
    "print(\"y_test columns type:\", type(y_train.columns))\n",
    "print(\"First 5 column names:\", y_train.columns[:5].tolist())\n",
    "\n",
    "# Also check if y_test is actually a DataFrame or numpy array:\n",
    "print(\"y_test type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# diagnostics of MLR r2 scores for fitting to training set \n",
    "\n",
    "# checking to ensure predictions and groundtruth are comparable (they do)\n",
    "assert y_train.shape == mlr_y_pred_train.shape\n",
    "\n",
    "# compare r2 values\n",
    "# mlr_loaded.score: 0.9041830139739396 on training data (fit)\n",
    "print(\"mlr_loaded.score:\", mlr_loaded.score(x_train, y_train))\n",
    "\n",
    "# compute_metrics() is the flattened r2, where each gene's r2 is treated equally (flattened) before aggregating\n",
    "# compute_metrics r2: 0.966425772252575\n",
    "# compute_metrics Pearson_r: 0.9830695663342065\n",
    "\n",
    "metrics_flat_mlr_train = compute_metrics(y_train.values, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_agg_R2 = metrics_flat_mlr_train['r2']\n",
    "mlr_train_agg_Pearsons = metrics_flat_mlr_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {mlr_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {mlr_train_agg_Pearsons}\")\n",
    "\n",
    "# compute_metrics_per_gene() looks at the indiviudal r2 at per-gene resolution (using DFs to maintain biological relevance of each column) \n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.920598\n",
    "#1        0.883302\n",
    "#2        0.650227\n",
    "#3        0.872502\n",
    "#4        0.953659\n",
    "#           ...   \n",
    "#16095    0.886189\n",
    "#16096    0.950355\n",
    "#16097    0.966280\n",
    "#16098    0.961176\n",
    "#16099    0.958689\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.959478\n",
    "#1        0.939842\n",
    "#2        0.806367\n",
    "#3        0.934078\n",
    "#4        0.976555\n",
    "#           ...   \n",
    "#16095    0.941376\n",
    "#16096    0.974861\n",
    "#16097    0.982995\n",
    "#16098    0.980396\n",
    "#16099    0.979127\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_mlr_train = compute_metrics_per_gene(y_train, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_pergene_R2 = metrics_flat_per_gene_mlr_train['r2']\n",
    "mlr_train_pergene_Pearsons = metrics_flat_per_gene_mlr_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", mlr_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", mlr_train_pergene_Pearsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# same diagnostics for XGBRF.v3 (trained on same x_train)\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == xgbrf_y_pred_train.shape\n",
    "\n",
    "# computing XGBRF metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_xgbrf_train = compute_metrics(y_train.values, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_agg_R2 = metrics_flat_xgbrf_train['r2']\n",
    "xgbrf_train_agg_Pearsons = metrics_flat_xgbrf_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.842478\n",
    "#1        0.858510\n",
    "#2        0.636674\n",
    "#3        0.772578\n",
    "#4        0.891585\n",
    "#           ...   \n",
    "#16095    0.773693\n",
    "#16096    0.868024\n",
    "#16097    0.910289\n",
    "#16098    0.902526\n",
    "#16099    0.915816\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.918635\n",
    "#1        0.927942\n",
    "#2        0.801955\n",
    "#3        0.881419\n",
    "#4        0.944821\n",
    "#           ...   \n",
    "#16095    0.881782\n",
    "#16096    0.932276\n",
    "#16097    0.954410\n",
    "#16098    0.950481\n",
    "#16099    0.957509\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_xgbrf_train = compute_metrics_per_gene(y_train, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_pergene_R2 = metrics_flat_per_gene_xgbrf_train['r2']\n",
    "xgbrf_train_pergene_Pearsons = metrics_flat_per_gene_xgbrf_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", xgbrf_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", xgbrf_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "\n",
    "# same diagnostics for RNN.v1 (used as a reference for data preprocessing of other models )\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == rnn_y_pred_train.shape\n",
    "\n",
    "# computing RNN metrics (aggregate and per gene)\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_rnn_train = compute_metrics(y_train.values, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_agg_R2 = metrics_flat_rnn_train['r2']\n",
    "rnn_train_agg_Pearsons = metrics_flat_rnn_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.224471\n",
    "#1       -0.057189\n",
    "#2       -0.204377\n",
    "#3        0.390087\n",
    "#4        0.662030\n",
    "#           ...   \n",
    "#16095    0.342862\n",
    "#16096    0.506315\n",
    "#16097    0.650347\n",
    "#16098    0.505688\n",
    "#16099    0.612035\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.485774\n",
    "#1       -0.149498\n",
    "#2        0.232025\n",
    "#3        0.626851\n",
    "#4        0.824306\n",
    "#           ...   \n",
    "#16095    0.586376\n",
    "#16096    0.713733\n",
    "#16097    0.809349\n",
    "#16098    0.734049\n",
    "#16099    0.783338\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_rnn_train = compute_metrics_per_gene(y_train, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_pergene_R2 = metrics_flat_per_gene_rnn_train['r2']\n",
    "rnn_train_pergene_Pearsons = metrics_flat_per_gene_rnn_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", rnn_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", rnn_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap CI for MLR (10000 iterations)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_3123736/1228113049.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fit_metrics = figure_pearson_r_comparison(\n\u001b[32m      2\u001b[39m     y_true=y_train,\n\u001b[32m      3\u001b[39m     predictions_dict=predictions_train,\n\u001b[32m      4\u001b[39m     ci_method=\u001b[33m'bootstrap'\u001b[39m,\n",
      "\u001b[32m~/Zhang-Lab/Zhang Lab Code/Figures/Model-fitting/figure1_agg_pearson_R.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(y_true, predictions_dict, ci_method, n_bootstrap, output_path)\u001b[39m\n\u001b[32m    117\u001b[39m                 y_true_boot = y_true_flat[indices]\n\u001b[32m    118\u001b[39m                 y_pred_boot = y_pred_flat[indices]\n\u001b[32m    119\u001b[39m \n\u001b[32m    120\u001b[39m                 \u001b[38;5;66;03m# Compute Pearson's R for this bootstrap sample\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m                 r_boot, _ = pearsonr(y_true_boot, y_pred_boot)\n\u001b[32m    122\u001b[39m                 bootstrap_rs.append(r_boot)\n\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m             \u001b[38;5;66;03m# 95% CI from bootstrap distribution (percentile method)\u001b[39;00m\n",
      "\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/scipy/stats/_stats_py.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, alternative, method, axis)\u001b[39m\n\u001b[32m   4754\u001b[39m     \u001b[38;5;66;03m# [-5e210, 5e210, 3e200, -3e200]\u001b[39;00m\n\u001b[32m   4755\u001b[39m     \u001b[38;5;66;03m# but not when `axis` is provided, so scale manually. scipy.linalg.norm\u001b[39;00m\n\u001b[32m   4756\u001b[39m     \u001b[38;5;66;03m# also raises an error with NaN input rather than returning NaN, so\u001b[39;00m\n\u001b[32m   4757\u001b[39m     \u001b[38;5;66;03m# use np.linalg.norm.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4758\u001b[39m     xmax = xp.max(xp.abs(xm), axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   4759\u001b[39m     ymax = xp.max(xp.abs(ym), axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   4760\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(invalid=\u001b[33m'ignore'\u001b[39m, divide=\u001b[33m'ignore'\u001b[39m):\n\u001b[32m   4761\u001b[39m         normxm = xmax * xp_vector_norm(xm/xmax, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fit_metrics = figure_pearson_r_comparison(\n",
    "    y_true=y_train,\n",
    "    predictions_dict=predictions_train, \n",
    "    ci_method='bootstrap',\n",
    "    n_bootstrap=10000, #worth lowering 55 minutes and not done at 10000 sampling runs \n",
    "    output_path='~/Zhang-Lab/Zhang Lab Data/Saved figures/pearson_r_comparison.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
