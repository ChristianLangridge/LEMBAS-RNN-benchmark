{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING DATA ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING FUNCTIONS ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/Model-fitting/figure1_agg_pearson_R.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "# Check what your y_test columns actually are:\n",
    "print(\"y_test columns type:\", type(y_train.columns))\n",
    "print(\"First 5 column names:\", y_train.columns[:5].tolist())\n",
    "\n",
    "# Also check if y_test is actually a DataFrame or numpy array:\n",
    "print(\"y_test type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# diagnostics of MLR r2 scores for fitting to training set \n",
    "\n",
    "# checking to ensure predictions and groundtruth are comparable (they do)\n",
    "assert y_train.shape == mlr_y_pred_train.shape\n",
    "\n",
    "# compare r2 values\n",
    "# mlr_loaded.score: 0.9041830139739396 on training data (fit)\n",
    "print(\"mlr_loaded.score:\", mlr_loaded.score(x_train, y_train))\n",
    "\n",
    "# compute_metrics() is the flattened r2, where each gene's r2 is treated equally (flattened) before aggregating\n",
    "# compute_metrics r2: 0.966425772252575\n",
    "# compute_metrics Pearson_r: 0.9830695663342065\n",
    "\n",
    "metrics_flat_mlr_train = compute_metrics(y_train.values, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_agg_R2 = metrics_flat_mlr_train['r2']\n",
    "mlr_train_agg_Pearsons = metrics_flat_mlr_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {mlr_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {mlr_train_agg_Pearsons}\")\n",
    "\n",
    "# compute_metrics_per_gene() looks at the indiviudal r2 at per-gene resolution (using DFs to maintain biological relevance of each column) \n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.920598\n",
    "#1        0.883302\n",
    "#2        0.650227\n",
    "#3        0.872502\n",
    "#4        0.953659\n",
    "#           ...   \n",
    "#16095    0.886189\n",
    "#16096    0.950355\n",
    "#16097    0.966280\n",
    "#16098    0.961176\n",
    "#16099    0.958689\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.959478\n",
    "#1        0.939842\n",
    "#2        0.806367\n",
    "#3        0.934078\n",
    "#4        0.976555\n",
    "#           ...   \n",
    "#16095    0.941376\n",
    "#16096    0.974861\n",
    "#16097    0.982995\n",
    "#16098    0.980396\n",
    "#16099    0.979127\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_mlr_train = compute_metrics_per_gene(y_train, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_pergene_R2 = metrics_flat_per_gene_mlr_train['r2']\n",
    "mlr_train_pergene_Pearsons = metrics_flat_per_gene_mlr_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", mlr_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", mlr_train_pergene_Pearsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# same diagnostics for XGBRF.v3 (trained on same x_train)\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == xgbrf_y_pred_train.shape\n",
    "\n",
    "# computing XGBRF metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_xgbrf_train = compute_metrics(y_train.values, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_agg_R2 = metrics_flat_xgbrf_train['r2']\n",
    "xgbrf_train_agg_Pearsons = metrics_flat_xgbrf_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.842478\n",
    "#1        0.858510\n",
    "#2        0.636674\n",
    "#3        0.772578\n",
    "#4        0.891585\n",
    "#           ...   \n",
    "#16095    0.773693\n",
    "#16096    0.868024\n",
    "#16097    0.910289\n",
    "#16098    0.902526\n",
    "#16099    0.915816\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.918635\n",
    "#1        0.927942\n",
    "#2        0.801955\n",
    "#3        0.881419\n",
    "#4        0.944821\n",
    "#           ...   \n",
    "#16095    0.881782\n",
    "#16096    0.932276\n",
    "#16097    0.954410\n",
    "#16098    0.950481\n",
    "#16099    0.957509\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_xgbrf_train = compute_metrics_per_gene(y_train, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_pergene_R2 = metrics_flat_per_gene_xgbrf_train['r2']\n",
    "xgbrf_train_pergene_Pearsons = metrics_flat_per_gene_xgbrf_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", xgbrf_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", xgbrf_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "\n",
    "# same diagnostics for RNN.v1 (used as a reference for data preprocessing of other models )\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == rnn_y_pred_train.shape\n",
    "\n",
    "# computing RNN metrics (aggregate and per gene)\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_rnn_train = compute_metrics(y_train.values, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_agg_R2 = metrics_flat_rnn_train['r2']\n",
    "rnn_train_agg_Pearsons = metrics_flat_rnn_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.224471\n",
    "#1       -0.057189\n",
    "#2       -0.204377\n",
    "#3        0.390087\n",
    "#4        0.662030\n",
    "#           ...   \n",
    "#16095    0.342862\n",
    "#16096    0.506315\n",
    "#16097    0.650347\n",
    "#16098    0.505688\n",
    "#16099    0.612035\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.485774\n",
    "#1       -0.149498\n",
    "#2        0.232025\n",
    "#3        0.626851\n",
    "#4        0.824306\n",
    "#           ...   \n",
    "#16095    0.586376\n",
    "#16096    0.713733\n",
    "#16097    0.809349\n",
    "#16098    0.734049\n",
    "#16099    0.783338\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_rnn_train = compute_metrics_per_gene(y_train, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_pergene_R2 = metrics_flat_per_gene_rnn_train['r2']\n",
    "rnn_train_pergene_Pearsons = metrics_flat_per_gene_rnn_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", rnn_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", rnn_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00d56477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING ALL BOOTSTRAP UNIT TESTS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 1: Vectorized vs Loop Equivalence (Aggregate)\n",
      "======================================================================\n",
      "\n",
      "✓ TEST PASSED: Vectorized and loop methods are equivalent\n",
      "\n",
      "======================================================================\n",
      "TEST 2: CI Coverage Properties\n",
      "======================================================================\n",
      "\n",
      "✓ TEST PASSED: Coverage rate 100.0% is within acceptable range\n",
      "\n",
      "======================================================================\n",
      "TEST 2B: CI Coverage of True Population Parameter\n",
      "======================================================================\n",
      "\n",
      "✓ TEST PASSED: True parameter coverage rate 94.0% is appropriate\n",
      "\n",
      "======================================================================\n",
      "TEST 3: Per-Gene Vectorized vs Loop Equivalence\n",
      "======================================================================\n",
      "\n",
      "✓ TEST PASSED: Per-gene vectorized method matches loop method\n",
      "\n",
      "======================================================================\n",
      "TEST 4: Bootstrap Distribution Properties\n",
      "======================================================================\n",
      "\n",
      "❌ TEST FAILED: \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Testing/test_bootstrapping.py:281\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    280\u001b[39m     tester = TestBootstrapFunctions()\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[43mtester\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Testing/test_bootstrapping.py:268\u001b[39m, in \u001b[36mTestBootstrapFunctions.run_all_tests\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m.test_ci_coverage_of_true_parameter()\n\u001b[32m    267\u001b[39m \u001b[38;5;28mself\u001b[39m.test_per_gene_vectorized_vs_loop()\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_bootstrap_distribution_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;28mself\u001b[39m.test_edge_cases()\n\u001b[32m    270\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Testing/test_bootstrapping.py:229\u001b[39m, in \u001b[36mTestBootstrapFunctions.test_bootstrap_distribution_properties\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    226\u001b[39m bootstrap_rs = cov / (std_true * std_pred)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(np.mean(bootstrap_rs) - observed_r) < \u001b[32m0.01\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0.001\u001b[39m < np.std(bootstrap_rs) < \u001b[32m0.1\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ TEST PASSED: Bootstrap distribution has expected properties\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Testing/test_bootstrapping.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "127d3a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "figure_pearson_r_comparison_fast() got an unexpected keyword argument 'chunk_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m############### PLOTTING STEP ###############\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m fit_metrics = \u001b[43mfigure_pearson_r_comparison_fast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredictions_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredictions_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mci_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpoisson_bootstrap_vectorized\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#worth lowering to 5000 55 minutes and not done at 10000 sampling runs \u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# chunking for more memory-efficient bootstrapping \u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: figure_pearson_r_comparison_fast() got an unexpected keyword argument 'chunk_size'"
     ]
    }
   ],
   "source": [
    "############### PLOTTING STEP ###############\n",
    "\n",
    "fit_metrics = figure_pearson_r_comparison_fast(\n",
    "    y_true=y_train,\n",
    "    predictions_dict=predictions_train, \n",
    "    ci_method='poisson_bootstrap_vectorized',\n",
    "    n_bootstrap=5000, #worth lowering to 5000 55 minutes and not done at 10000 sampling runs \n",
    "    chunk_size=1000, # chunking for more memory-efficient bootstrapping \n",
    "    output_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
