{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed predictions...\n"
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Figures/Model-fitting/figure1_agg_pearson_R.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "# Check what your y_test columns actually are:\n",
    "print(\"y_test columns type:\", type(y_train.columns))\n",
    "print(\"First 5 column names:\", y_train.columns[:5].tolist())\n",
    "\n",
    "# Also check if y_test is actually a DataFrame or numpy array:\n",
    "print(\"y_test type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# diagnostics of MLR r2 scores for fitting to training set \n",
    "\n",
    "# checking to ensure predictions and groundtruth are comparable (they do)\n",
    "assert y_train.shape == mlr_y_pred_train.shape\n",
    "\n",
    "# compare r2 values\n",
    "# mlr_loaded.score: 0.9041830139739396 on training data (fit)\n",
    "print(\"mlr_loaded.score:\", mlr_loaded.score(x_train, y_train))\n",
    "\n",
    "# compute_metrics() is the flattened r2, where each gene's r2 is treated equally (flattened) before aggregating\n",
    "# compute_metrics r2: 0.966425772252575\n",
    "# compute_metrics Pearson_r: 0.9830695663342065\n",
    "\n",
    "metrics_flat_mlr_train = compute_metrics(y_train.values, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_agg_R2 = metrics_flat_mlr_train['r2']\n",
    "mlr_train_agg_Pearsons = metrics_flat_mlr_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {mlr_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {mlr_train_agg_Pearsons}\")\n",
    "\n",
    "# compute_metrics_per_gene() looks at the indiviudal r2 at per-gene resolution (using DFs to maintain biological relevance of each column) \n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.920598\n",
    "#1        0.883302\n",
    "#2        0.650227\n",
    "#3        0.872502\n",
    "#4        0.953659\n",
    "#           ...   \n",
    "#16095    0.886189\n",
    "#16096    0.950355\n",
    "#16097    0.966280\n",
    "#16098    0.961176\n",
    "#16099    0.958689\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.959478\n",
    "#1        0.939842\n",
    "#2        0.806367\n",
    "#3        0.934078\n",
    "#4        0.976555\n",
    "#           ...   \n",
    "#16095    0.941376\n",
    "#16096    0.974861\n",
    "#16097    0.982995\n",
    "#16098    0.980396\n",
    "#16099    0.979127\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_mlr_train = compute_metrics_per_gene(y_train, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_pergene_R2 = metrics_flat_per_gene_mlr_train['r2']\n",
    "mlr_train_pergene_Pearsons = metrics_flat_per_gene_mlr_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", mlr_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", mlr_train_pergene_Pearsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# same diagnostics for XGBRF.v3 (trained on same x_train)\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == xgbrf_y_pred_train.shape\n",
    "\n",
    "# computing XGBRF metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_xgbrf_train = compute_metrics(y_train.values, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_agg_R2 = metrics_flat_xgbrf_train['r2']\n",
    "xgbrf_train_agg_Pearsons = metrics_flat_xgbrf_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.842478\n",
    "#1        0.858510\n",
    "#2        0.636674\n",
    "#3        0.772578\n",
    "#4        0.891585\n",
    "#           ...   \n",
    "#16095    0.773693\n",
    "#16096    0.868024\n",
    "#16097    0.910289\n",
    "#16098    0.902526\n",
    "#16099    0.915816\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.918635\n",
    "#1        0.927942\n",
    "#2        0.801955\n",
    "#3        0.881419\n",
    "#4        0.944821\n",
    "#           ...   \n",
    "#16095    0.881782\n",
    "#16096    0.932276\n",
    "#16097    0.954410\n",
    "#16098    0.950481\n",
    "#16099    0.957509\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_xgbrf_train = compute_metrics_per_gene(y_train, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_pergene_R2 = metrics_flat_per_gene_xgbrf_train['r2']\n",
    "xgbrf_train_pergene_Pearsons = metrics_flat_per_gene_xgbrf_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", xgbrf_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", xgbrf_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "\n",
    "# same diagnostics for RNN.v1 (used as a reference for data preprocessing of other models )\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == rnn_y_pred_train.shape\n",
    "\n",
    "# computing RNN metrics (aggregate and per gene)\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_rnn_train = compute_metrics(y_train.values, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_agg_R2 = metrics_flat_rnn_train['r2']\n",
    "rnn_train_agg_Pearsons = metrics_flat_rnn_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.224471\n",
    "#1       -0.057189\n",
    "#2       -0.204377\n",
    "#3        0.390087\n",
    "#4        0.662030\n",
    "#           ...   \n",
    "#16095    0.342862\n",
    "#16096    0.506315\n",
    "#16097    0.650347\n",
    "#16098    0.505688\n",
    "#16099    0.612035\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.485774\n",
    "#1       -0.149498\n",
    "#2        0.232025\n",
    "#3        0.626851\n",
    "#4        0.824306\n",
    "#           ...   \n",
    "#16095    0.586376\n",
    "#16096    0.713733\n",
    "#16097    0.809349\n",
    "#16098    0.734049\n",
    "#16099    0.783338\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_rnn_train = compute_metrics_per_gene(y_train, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_pergene_R2 = metrics_flat_per_gene_rnn_train['r2']\n",
    "rnn_train_pergene_Pearsons = metrics_flat_per_gene_rnn_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", rnn_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", rnn_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Poisson bootstrap CI for MLR (5000 iterations)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fit_metrics = \u001b[43mfigure_pearson_r_comparison\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredictions_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredictions_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mci_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpoisson_bootstrap\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#worth lowering to 5000 55 minutes and not done at 10000 sampling runs \u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Figures/Model-fitting/figure1_agg_pearson_R.py:83\u001b[39m, in \u001b[36mfigure_pearson_r_comparison\u001b[39m\u001b[34m(y_true, predictions_dict, ci_method, n_bootstrap, output_path)\u001b[39m\n\u001b[32m     80\u001b[39m w_mean_pred = (weights * y_pred_flat).sum() / w_sum\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Weighted covariance and standard deviations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m cov = \u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_flat\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_mean_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_flat\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_mean_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / w_sum\n\u001b[32m     84\u001b[39m std_true = np.sqrt((weights * (y_true_flat - w_mean_true)**\u001b[32m2\u001b[39m).sum() / w_sum)\n\u001b[32m     85\u001b[39m std_pred = np.sqrt((weights * (y_pred_flat - w_mean_pred)**\u001b[32m2\u001b[39m).sum() / w_sum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/numpy/_core/_methods.py:49\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     50\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     54\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fit_metrics = figure_pearson_r_comparison_fast(\n",
    "    y_true=y_train,\n",
    "    predictions_dict=predictions_train, \n",
    "    ci_method='poisson_bootstrap_vectorized',\n",
    "    n_bootstrap=5000, #worth lowering to 5000 55 minutes and not done at 10000 sampling runs \n",
    "    output_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
