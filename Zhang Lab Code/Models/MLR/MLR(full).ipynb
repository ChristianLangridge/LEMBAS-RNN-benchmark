{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e1b1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ALIGNMENT VERIFICATION: x_train vs RNN vs Network\n",
      "================================================================================\n",
      "\n",
      "[STEP 1] Preparing x_train with corrected preprocessing...\n",
      "âœ“ x_train prepared\n",
      "  - Shape: (12748, 1197)\n",
      "  - Features: 1197\n",
      "  - Feature names: ['ADNP', 'ADNP2', 'AEBP1', 'AEBP2', 'AHR'] ... ['ZSCAN4', 'ZSCAN5A', 'ZSCAN9', 'ZXDA', 'ZXDC']\n",
      "\n",
      "[STEP 2] Loading RNN checkpoint...\n",
      "âœ“ RNN checkpoint loaded\n",
      "  - Expected features: 1197\n",
      "  - Feature list found in checkpoint: No (will infer)\n",
      "\n",
      "[STEP 3] Analyzing network nodes...\n",
      "âœ“ Network analysis complete\n",
      "  - Network TFs (regulators): 1200\n",
      "  - Network genes (targets): 16292\n",
      "  - Total network nodes: 16371\n",
      "\n",
      "  Expression TFs in network:\n",
      "  - As regulators only: 1196\n",
      "  - As targets only: 1\n",
      "  - In network (any role): 1197\n",
      "\n",
      "================================================================================\n",
      "FEATURE COUNT COMPARISON\n",
      "================================================================================\n",
      "\n",
      "  x_train features:    1197\n",
      "  RNN expects:         1197\n",
      "  Network nodes:       1197\n",
      "\n",
      "  âœ… COUNTS MATCH PERFECTLY!\n",
      "\n",
      "================================================================================\n",
      "FEATURE LIST COMPARISON (CRITICAL)\n",
      "================================================================================\n",
      "\n",
      "[TEST 1] x_train vs Network nodes\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Features in x_train but NOT in network: 0\n",
      "  Features in network but NOT in x_train: 0\n",
      "\n",
      "  âœ… x_train and network features are IDENTICAL!\n",
      "\n",
      "[TEST 3] Feature order check\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Cannot check order (RNN feature list not in checkpoint)\n",
      "\n",
      "[TEST 4] 'TF' gene verification\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  'TF' in x_train:   True\n",
      "  'TF' in network:   True\n",
      "  'TF' in RNN:       N/A\n",
      "\n",
      "  'TF' gene in network as:\n",
      "    - Regulator (TF column): False\n",
      "    - Target (Gene column): True\n",
      "    - Number of regulators: 65\n",
      "    - Sample regulators: ['FOS', 'AHR', 'FOXM1', 'AR', 'CREB1']\n",
      "\n",
      "================================================================================\n",
      "ALIGNMENT SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Component                   â”‚ x_train    â”‚ RNN      â”‚ Network  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Feature count               â”‚ 1197       â”‚ 1197     â”‚ 1197     â”‚\n",
      "â”‚ Includes 'TF' gene          â”‚ True       â”‚ N/A      â”‚ True     â”‚\n",
      "â”‚ Features identical          â”‚ â”€          â”‚ N/A      â”‚ Yes      â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "================================================================================\n",
      "FINAL VERDICT\n",
      "================================================================================\n",
      "\n",
      "Test Results:\n",
      "  âœ… Feature count: x_train matches network\n",
      "  âœ… Feature list: x_train matches network\n",
      "  âœ… Feature count: x_train matches RNN\n",
      "  âœ… 'TF' gene: Included in both x_train and network\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ‰ ALL TESTS PASSED! ğŸ‰\n",
      "\n",
      "Your x_train features are PERFECTLY aligned with:\n",
      "âœ“ Network topology\n",
      "âœ“ RNN checkpoint expectations\n",
      "âœ“ Includes 'TF' gene correctly\n",
      "\n",
      "You can proceed with confidence:\n",
      "1. Train MLR on x_train\n",
      "2. Train XGBRF on x_train  \n",
      "3. Use existing RNN checkpoint\n",
      "4. Fair benchmarking guaranteed!\n",
      "\n",
      "All models will see IDENTICAL feature sets.\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "VERIFICATION SCRIPT: Confirm Perfect Alignment\n",
    "==============================================\n",
    "\n",
    "This script verifies that:\n",
    "1. x_train features match RNN checkpoint expectations\n",
    "2. x_train features match network nodes\n",
    "3. All three are IDENTICALLY aligned\n",
    "\n",
    "This gives you 100% confidence for fair benchmarking.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ALIGNMENT VERIFICATION: x_train vs RNN vs Network\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Prepare x_train (your current preprocessing)\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 1] Preparing x_train with corrected preprocessing...\")\n",
    "\n",
    "DATA_PATH = os.path.expanduser('/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files')\n",
    "\n",
    "# Load data\n",
    "tf_expression = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'),\n",
    "    sep='\\t',\n",
    "    header=0,\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "gene_expression = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'),\n",
    "    sep='\\t',\n",
    "    header=0,\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "net = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv'),\n",
    "    sep='\\t'\n",
    "    )\n",
    "\n",
    "# Get ALL network nodes (CORRECTED approach)\n",
    "network_tfs = set(net['TF'].unique())\n",
    "network_genes = set(net['Gene'].unique())\n",
    "network_nodes = network_tfs | network_genes\n",
    "\n",
    "# Filter to network nodes\n",
    "usable_features = [tf for tf in tf_expression.columns if tf in network_nodes]\n",
    "x = tf_expression[usable_features]\n",
    "y = gene_expression\n",
    "\n",
    "# Create train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.2,\n",
    "    random_state=888\n",
    ")\n",
    "\n",
    "print(f\"âœ“ x_train prepared\")\n",
    "print(f\"  - Shape: {x_train.shape}\")\n",
    "print(f\"  - Features: {len(usable_features)}\")\n",
    "print(f\"  - Feature names: {x_train.columns.tolist()[:5]} ... {x_train.columns.tolist()[-5:]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Load RNN checkpoint\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 2] Loading RNN checkpoint...\")\n",
    "\n",
    "try:\n",
    "    RNN_PATH = os.path.expanduser('~/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt')\n",
    "    checkpoint = torch.load(RNN_PATH, map_location='cpu', weights_only=False)\n",
    "    \n",
    "    rnn_n_features = checkpoint['state_dict']['input_layer.weights'].shape[0]\n",
    "    \n",
    "    # Try to get feature names from checkpoint\n",
    "    if 'usable_tfs' in checkpoint:\n",
    "        rnn_features = checkpoint['usable_tfs']\n",
    "        print(f\"âœ“ RNN checkpoint loaded\")\n",
    "        print(f\"  - Expected features: {rnn_n_features}\")\n",
    "        print(f\"  - Feature list found in checkpoint: Yes\")\n",
    "    else:\n",
    "        rnn_features = None\n",
    "        print(f\"âœ“ RNN checkpoint loaded\")\n",
    "        print(f\"  - Expected features: {rnn_n_features}\")\n",
    "        print(f\"  - Feature list found in checkpoint: No (will infer)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Could not load RNN checkpoint: {e}\")\n",
    "    rnn_n_features = None\n",
    "    rnn_features = None\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Get network nodes\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 3] Analyzing network nodes...\")\n",
    "\n",
    "network_tfs_list = sorted(network_tfs)\n",
    "network_genes_list = sorted(network_genes)\n",
    "network_nodes_list = sorted(network_nodes)\n",
    "\n",
    "# Count how many expression TFs are in each category\n",
    "expr_tfs_in_network_tfs = [tf for tf in tf_expression.columns if tf in network_tfs]\n",
    "expr_tfs_in_network_genes = [tf for tf in tf_expression.columns if tf in network_genes]\n",
    "expr_tfs_in_network_nodes = [tf for tf in tf_expression.columns if tf in network_nodes]\n",
    "\n",
    "print(f\"âœ“ Network analysis complete\")\n",
    "print(f\"  - Network TFs (regulators): {len(network_tfs)}\")\n",
    "print(f\"  - Network genes (targets): {len(network_genes)}\")\n",
    "print(f\"  - Total network nodes: {len(network_nodes)}\")\n",
    "print(f\"\\n  Expression TFs in network:\")\n",
    "print(f\"  - As regulators only: {len(expr_tfs_in_network_tfs)}\")\n",
    "print(f\"  - As targets only: {len([tf for tf in expr_tfs_in_network_genes if tf not in network_tfs])}\")\n",
    "print(f\"  - In network (any role): {len(expr_tfs_in_network_nodes)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Compare feature counts\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE COUNT COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n  x_train features:    {len(usable_features)}\")\n",
    "print(f\"  RNN expects:         {rnn_n_features if rnn_n_features else 'N/A'}\")\n",
    "print(f\"  Network nodes:       {len(expr_tfs_in_network_nodes)}\")\n",
    "\n",
    "counts_match = (\n",
    "    len(usable_features) == rnn_n_features == len(expr_tfs_in_network_nodes)\n",
    ")\n",
    "\n",
    "if counts_match:\n",
    "    print(f\"\\n  âœ… COUNTS MATCH PERFECTLY!\")\n",
    "else:\n",
    "    print(f\"\\n  âš ï¸  COUNTS DO NOT MATCH\")\n",
    "    if rnn_n_features:\n",
    "        print(f\"     x_train vs RNN: {len(usable_features) - rnn_n_features:+d}\")\n",
    "    print(f\"     x_train vs network: {len(usable_features) - len(expr_tfs_in_network_nodes):+d}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Compare feature lists (most critical test!)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE LIST COMPARISON (CRITICAL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert to sorted sets for comparison\n",
    "x_train_features = set(x_train.columns.tolist())\n",
    "network_features = set(expr_tfs_in_network_nodes)\n",
    "\n",
    "print(f\"\\n[TEST 1] x_train vs Network nodes\")\n",
    "print(f\"â”€\" * 80)\n",
    "\n",
    "# Features in x_train but NOT in network\n",
    "in_xtrain_not_network = x_train_features - network_features\n",
    "# Features in network but NOT in x_train\n",
    "in_network_not_xtrain = network_features - x_train_features\n",
    "\n",
    "print(f\"  Features in x_train but NOT in network: {len(in_xtrain_not_network)}\")\n",
    "if in_xtrain_not_network:\n",
    "    print(f\"    â†’ {sorted(in_xtrain_not_network)}\")\n",
    "\n",
    "print(f\"  Features in network but NOT in x_train: {len(in_network_not_xtrain)}\")\n",
    "if in_network_not_xtrain:\n",
    "    print(f\"    â†’ {sorted(in_network_not_xtrain)}\")\n",
    "\n",
    "if len(in_xtrain_not_network) == 0 and len(in_network_not_xtrain) == 0:\n",
    "    print(f\"\\n  âœ… x_train and network features are IDENTICAL!\")\n",
    "else:\n",
    "    print(f\"\\n  âš ï¸  Mismatch detected!\")\n",
    "\n",
    "# ---\n",
    "\n",
    "if rnn_features:\n",
    "    print(f\"\\n[TEST 2] x_train vs RNN checkpoint\")\n",
    "    print(f\"â”€\" * 80)\n",
    "    \n",
    "    rnn_features_set = set(rnn_features)\n",
    "    \n",
    "    # Features in x_train but NOT in RNN\n",
    "    in_xtrain_not_rnn = x_train_features - rnn_features_set\n",
    "    # Features in RNN but NOT in x_train\n",
    "    in_rnn_not_xtrain = rnn_features_set - x_train_features\n",
    "    \n",
    "    print(f\"  Features in x_train but NOT in RNN: {len(in_xtrain_not_rnn)}\")\n",
    "    if in_xtrain_not_rnn:\n",
    "        print(f\"    â†’ {sorted(in_xtrain_not_rnn)}\")\n",
    "    \n",
    "    print(f\"  Features in RNN but NOT in x_train: {len(in_rnn_not_xtrain)}\")\n",
    "    if in_rnn_not_xtrain:\n",
    "        print(f\"    â†’ {sorted(in_rnn_not_xtrain)}\")\n",
    "    \n",
    "    if len(in_xtrain_not_rnn) == 0 and len(in_rnn_not_xtrain) == 0:\n",
    "        print(f\"\\n  âœ… x_train and RNN features are IDENTICAL!\")\n",
    "    else:\n",
    "        print(f\"\\n  âš ï¸  Mismatch detected!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Check feature ORDER (important for some models)\n",
    "# ============================================================================\n",
    "print(f\"\\n[TEST 3] Feature order check\")\n",
    "print(f\"â”€\" * 80)\n",
    "\n",
    "x_train_ordered = x_train.columns.tolist()\n",
    "network_ordered = sorted(expr_tfs_in_network_nodes)\n",
    "\n",
    "if rnn_features:\n",
    "    rnn_ordered = rnn_features\n",
    "    \n",
    "    # Check if order matches\n",
    "    x_vs_rnn_order = (x_train_ordered == rnn_ordered)\n",
    "    \n",
    "    print(f\"  x_train feature order matches RNN: {x_vs_rnn_order}\")\n",
    "    \n",
    "    if not x_vs_rnn_order:\n",
    "        print(f\"\\n  Note: Order mismatch is OK if features are the same.\")\n",
    "        print(f\"  Models will still work correctly.\")\n",
    "else:\n",
    "    print(f\"  Cannot check order (RNN feature list not in checkpoint)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Check for 'TF' gene specifically\n",
    "# ============================================================================\n",
    "print(f\"\\n[TEST 4] 'TF' gene verification\")\n",
    "print(f\"â”€\" * 80)\n",
    "\n",
    "tf_in_xtrain = 'TF' in x_train_features\n",
    "tf_in_network = 'TF' in network_features\n",
    "tf_in_rnn = 'TF' in rnn_features_set if rnn_features else None\n",
    "\n",
    "print(f\"  'TF' in x_train:   {tf_in_xtrain}\")\n",
    "print(f\"  'TF' in network:   {tf_in_network}\")\n",
    "print(f\"  'TF' in RNN:       {tf_in_rnn if tf_in_rnn is not None else 'N/A'}\")\n",
    "\n",
    "if tf_in_xtrain and tf_in_network:\n",
    "    # Check how 'TF' appears in network\n",
    "    tf_as_regulator = 'TF' in network_tfs\n",
    "    tf_as_target = 'TF' in network_genes\n",
    "    \n",
    "    print(f\"\\n  'TF' gene in network as:\")\n",
    "    print(f\"    - Regulator (TF column): {tf_as_regulator}\")\n",
    "    print(f\"    - Target (Gene column): {tf_as_target}\")\n",
    "    \n",
    "    if tf_as_target:\n",
    "        tf_regulators = net[net['Gene'] == 'TF']\n",
    "        print(f\"    - Number of regulators: {len(tf_regulators)}\")\n",
    "        print(f\"    - Sample regulators: {tf_regulators['TF'].head(5).tolist()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Summary table\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALIGNMENT SUMMARY TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Component                   â”‚ x_train    â”‚ RNN      â”‚ Network  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Feature count               â”‚ {len(usable_features):<10} â”‚ {rnn_n_features if rnn_n_features else 'N/A':<8} â”‚ {len(expr_tfs_in_network_nodes):<8} â”‚\n",
    "â”‚ Includes 'TF' gene          â”‚ {str(tf_in_xtrain):<10} â”‚ {str(tf_in_rnn) if tf_in_rnn is not None else 'N/A':<8} â”‚ {str(tf_in_network):<8} â”‚\n",
    "â”‚ Features identical          â”‚ â”€          â”‚ {('Yes' if rnn_features and x_train_features == rnn_features_set else 'No' if rnn_features else 'N/A'):<8} â”‚ {('Yes' if x_train_features == network_features else 'No'):<8} â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL VERDICT\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_tests_passed = True\n",
    "test_results = []\n",
    "\n",
    "# Test 1: Feature count\n",
    "if len(usable_features) == len(expr_tfs_in_network_nodes):\n",
    "    test_results.append(\"âœ… Feature count: x_train matches network\")\n",
    "else:\n",
    "    test_results.append(\"âš ï¸  Feature count: MISMATCH\")\n",
    "    all_tests_passed = False\n",
    "\n",
    "# Test 2: Feature list\n",
    "if x_train_features == network_features:\n",
    "    test_results.append(\"âœ… Feature list: x_train matches network\")\n",
    "else:\n",
    "    test_results.append(\"âš ï¸  Feature list: MISMATCH\")\n",
    "    all_tests_passed = False\n",
    "\n",
    "# Test 3: RNN match\n",
    "if rnn_n_features:\n",
    "    if len(usable_features) == rnn_n_features:\n",
    "        test_results.append(\"âœ… Feature count: x_train matches RNN\")\n",
    "    else:\n",
    "        test_results.append(\"âš ï¸  Feature count: x_train vs RNN MISMATCH\")\n",
    "        all_tests_passed = False\n",
    "    \n",
    "    if rnn_features:\n",
    "        if x_train_features == rnn_features_set:\n",
    "            test_results.append(\"âœ… Feature list: x_train matches RNN\")\n",
    "        else:\n",
    "            test_results.append(\"âš ï¸  Feature list: x_train vs RNN MISMATCH\")\n",
    "            all_tests_passed = False\n",
    "\n",
    "# Test 4: 'TF' gene\n",
    "if tf_in_xtrain and tf_in_network:\n",
    "    test_results.append(\"âœ… 'TF' gene: Included in both x_train and network\")\n",
    "elif not tf_in_xtrain and not tf_in_network:\n",
    "    test_results.append(\"âš ï¸  'TF' gene: Missing from both (unexpected)\")\n",
    "    all_tests_passed = False\n",
    "else:\n",
    "    test_results.append(\"âš ï¸  'TF' gene: Inconsistent presence\")\n",
    "    all_tests_passed = False\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for result in test_results:\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 80)\n",
    "\n",
    "if all_tests_passed:\n",
    "    print(\"\"\"\n",
    "ğŸ‰ ALL TESTS PASSED! ğŸ‰\n",
    "\n",
    "Your x_train features are PERFECTLY aligned with:\n",
    "âœ“ Network topology\n",
    "âœ“ RNN checkpoint expectations\n",
    "âœ“ Includes 'TF' gene correctly\n",
    "\n",
    "You can proceed with confidence:\n",
    "1. Train MLR on x_train\n",
    "2. Train XGBRF on x_train  \n",
    "3. Use existing RNN checkpoint\n",
    "4. Fair benchmarking guaranteed!\n",
    "\n",
    "All models will see IDENTICAL feature sets.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "âš ï¸  ALIGNMENT ISSUES DETECTED âš ï¸\n",
    "\n",
    "Please review the mismatches above and correct your preprocessing.\n",
    "\n",
    "Common fixes:\n",
    "1. Ensure you're using: network_nodes = network_tfs | network_genes\n",
    "2. Check random seed matches (888)\n",
    "3. Verify index_col=0 in data loading\n",
    "4. Confirm network.tsv file is correct version\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VERIFICATION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87f225c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_boilerplate_remote.py:36\u001b[39m\n\u001b[32m     31\u001b[39m x_train, x_test, y_train, y_test = train_test_split(\n\u001b[32m     32\u001b[39m     x, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m888\u001b[39m) \u001b[38;5;66;03m# changed from 42 to 888 to match training seed for RNN 13/01/26\u001b[39;00m\n\u001b[32m     35\u001b[39m x_train.to_csv(\u001b[33m\"\u001b[39m\u001b[33m/home/christianl/Zhang-Lab/Zhang Lab Data/Data for Cheng RNN retraining/training/x_train(Christian).csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/christianl/Zhang-Lab/Zhang Lab Data/Data for Cheng RNN retraining/training/y_train(Christian).csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m x_test.to_csv(\u001b[33m\"\u001b[39m\u001b[33m/home/christianl/Zhang-Lab/Zhang Lab Data/Data for Cheng RNN retraining/testing/x_test(Christian).csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     39\u001b[39m y_test.to_csv(\u001b[33m\"\u001b[39m\u001b[33m/home/christianl/Zhang-Lab/Zhang Lab Data/Data for Cheng RNN retraining/testing/y_test(Christian).csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/core/generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/pandas/io/formats/csvs.py:324\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[43mlibwriters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/writers.pyx:76\u001b[39m, in \u001b[36mpandas._libs.writers.write_csv_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_boilerplate_remote.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box r2 score LinearRegression:\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "# difference of 0.12 between train and test is understandable given the high-dimensionality and noise in gene expression data\n",
    "\n",
    "# after applying the centering boilerplate (only difference between MLR v1 and v2 is column-wise centering)\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "\n",
    "# after working with uncentered, paired data from the network.tsv file (only TFs in that can be included)\n",
    "# train score:  0.908486689146908\n",
    "# test score:  0.7993502011028869\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_test = LinearRegression(\n",
    "                    n_jobs=-1,\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd61c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.908486689146908\n",
      "Score:  0.7993502011028869\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', reg_test.score(x_train, y_train))\n",
    "print('Score: ', reg_test.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeed774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0, Train set: 10038,     Test set:1116\n",
      "Fold:1, Train set: 10038,     Test set:1116\n",
      "Fold:2, Train set: 10038,     Test set:1116\n",
      "Fold:3, Train set: 10038,     Test set:1116\n",
      "Fold:4, Train set: 10039,     Test set:1115\n",
      "Fold:5, Train set: 10039,     Test set:1115\n",
      "Fold:6, Train set: 10039,     Test set:1115\n",
      "Fold:7, Train set: 10039,     Test set:1115\n",
      "Fold:8, Train set: 10039,     Test set:1115\n",
      "Fold:9, Train set: 10039,     Test set:1115\n"
     ]
    }
   ],
   "source": [
    "# conducting a k-fold validation to check for overfitting\n",
    "# splitting training set into 10-folds\n",
    "# train sets: ~10038 targets\n",
    "# test sets: ~1116 targets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cnt = 0\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=888) # changed from 42 to 888 to match training seed for RNN 13/01/26\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, \\\n",
    "    Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa70df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MLR model cross validation ------\n",
      "Scores: [0.79306553 0.79355143 0.80595273 0.77689887 0.78254468 0.78294832\n",
      " 0.79897946 0.77465899 0.75861371 0.78061954]\n",
      "Mean: 0.7847833249078063\n",
      "StandardDeviation: 0.012924317642343348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the 10-fold validation \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773 -> similar to the holdout training run\n",
    "#StandardDeviation: 0.009341412328795035 -> very consistent between folds\n",
    "\n",
    "# unlikely that MLR is overfitting based on these results -> good sanity check for reference\n",
    "\n",
    "# redid same analysis with column-wise centered data and got the exact same results \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773\n",
    "#StandardDeviation: 0.00934141232879502\n",
    "\n",
    "# redid same analysis once again, with uncentered data like the first run, but set random seed to 888\n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.79322189 0.79384094 0.80615516 0.77715731 0.78278073 0.78325776\n",
    "# 0.79921787 0.77486414 0.75888273 0.7807757 ]\n",
    "#Mean: 0.7850154223167911\n",
    "#StandardDeviation: 0.01291359135998445\n",
    "\n",
    "\n",
    "# same as before but used index_col=0 and removed 'TF' which was a junk filler column 15/01/26\n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.79306553 0.79355143 0.80595273 0.77689887 0.78254468 0.78294832\n",
    "# 0.79897946 0.77465899 0.75861371 0.78061954]\n",
    "#Mean: 0.7847833249078063\n",
    "#StandardDeviation: 0.012924317642343348\n",
    "\n",
    "\n",
    "def cross_validation(reg_model, training_set, training_target, cv):\n",
    "    scores = cross_val_score(\n",
    "      reg_model, training_set,\n",
    "      training_target,\n",
    "      scoring=\"r2\", cv=cv)\n",
    "    r2_scores = scores\n",
    "    print(\"Scores:\", r2_scores)\n",
    "    print(\"Mean:\", r2_scores.mean())\n",
    "    print(\"StandardDeviation:\", r2_scores.std())\n",
    "\n",
    "print(\"----- MLR model cross validation ------\")\n",
    "lin_reg = LinearRegression()\n",
    "cross_validation(lin_reg, x_train, y_train, kf)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779c71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# saving model + metadata\n",
    "\n",
    "metadata = {\n",
    "    'sklearn_version': '1.7.2',\n",
    "    'model_type': 'LinearRegression',\n",
    "    'n_features': reg_test.n_features_in_,\n",
    "    'coef_shape': reg_test.coef_.shape,\n",
    "    'intercept_shape': reg_test.intercept_.shape,\n",
    "}\n",
    "\n",
    "joblib.dump(reg_test, \"/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/MLR_model_v4(uncentered[FINAL]).joblib\")\n",
    "with open(\"/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/model_metadata_uncentered[FINAL].json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
