{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5354eebc",
   "metadata": {},
   "source": [
    "MLR SCRIPT ON FULL DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2008b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226b7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in gene/TF expression full data\n",
    "\n",
    "gene_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd11b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e3f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box r2 score LinearRegression:\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "# difference of 0.12 between train and test is understandable given the high-dimensionality and noise in gene expression data\n",
    "\n",
    "reg_test = LinearRegression(\n",
    "                    n_jobs=-1,\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.7934193600256717\n",
      "Score:  0.90870454039286\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', reg_test.score(x_train, y_train))\n",
    "print('Score: ', reg_test.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeed774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0, Train set: 10038,     Test set:1116\n",
      "Fold:1, Train set: 10038,     Test set:1116\n",
      "Fold:2, Train set: 10038,     Test set:1116\n",
      "Fold:3, Train set: 10038,     Test set:1116\n",
      "Fold:4, Train set: 10039,     Test set:1115\n",
      "Fold:5, Train set: 10039,     Test set:1115\n",
      "Fold:6, Train set: 10039,     Test set:1115\n",
      "Fold:7, Train set: 10039,     Test set:1115\n",
      "Fold:8, Train set: 10039,     Test set:1115\n",
      "Fold:9, Train set: 10039,     Test set:1115\n"
     ]
    }
   ],
   "source": [
    "# conducting a k-fold validation to check for overfitting\n",
    "# splitting training set into 10-folds\n",
    "# train sets: ~10038 targets\n",
    "# test sets: ~1116 targets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cnt = 0\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, \\\n",
    "    Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MLR model cross validation ------\n",
      "Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
      " 0.77717178 0.7840341  0.79817987 0.76680642]\n",
      "Mean: 0.7834287993694773\n",
      "StandardDeviation: 0.009341412328795035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the 10-fold validation \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773 -> similar to the holdout training run\n",
    "#StandardDeviation: 0.009341412328795035 -> very consistent between folds\n",
    "\n",
    "# Unlikely that MLR is overfitting based on these results -> good sanity check for reference\n",
    "\n",
    "def cross_validation(reg_model, training_set, training_target, cv):\n",
    "    scores = cross_val_score(\n",
    "      reg_model, training_set,\n",
    "      training_target,\n",
    "      scoring=\"r2\", cv=cv)\n",
    "    r2_scores = scores\n",
    "    print(\"Scores:\", r2_scores)\n",
    "    print(\"Mean:\", r2_scores.mean())\n",
    "    print(\"StandardDeviation:\", r2_scores.std())\n",
    "\n",
    "print(\"----- MLR model cross validation ------\")\n",
    "lin_reg = LinearRegression()\n",
    "cross_validation(lin_reg, x_train, y_train, kf)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779c71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# saving model + metadata\n",
    "\n",
    "metadata = {\n",
    "    'sklearn_version': '1.7.2',\n",
    "    'model_type': 'LinearRegression',\n",
    "    'n_features': reg_test.n_features_in_,\n",
    "    'coef_shape': reg_test.coef_.shape,\n",
    "    'intercept_shape': reg_test.intercept_.shape,\n",
    "}\n",
    "\n",
    "joblib.dump(reg_test, \"/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_model.joblib\")\n",
    "with open(\"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e891a2",
   "metadata": {},
   "source": [
    "ELASTICNET ON FULL DATASETS + TUNING  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score  0.00432651511965587\n"
     ]
    }
   ],
   "source": [
    "# out-of-the-box r2 score with ElasticNet: 0.00432651511965587\n",
    "# no tuning at all so not surprised by uncompetitive results vs. MLR\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elas_reg = ElasticNet().fit(x_train,y_train)\n",
    "print('Score ', elas_reg.score(x_test,y_test))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41135c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning performance of ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(x_train)\n",
    "X_test_std  = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46089c54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiTaskElasticNetCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# L1/L2 penalty tuning with ElasticNetCV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m elas = \u001b[43mMultiTaskElasticNetCV\u001b[49m(\n\u001b[32m      4\u001b[39m     alphas=np.logspace(-\u001b[32m4\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m),\n\u001b[32m      5\u001b[39m     l1_ratio=[\u001b[32m0.1\u001b[39m, \u001b[32m0.3\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.7\u001b[39m, \u001b[32m0.9\u001b[39m],\n\u001b[32m      6\u001b[39m     cv=\u001b[32m5\u001b[39m,\n\u001b[32m      7\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m,\n\u001b[32m      8\u001b[39m     max_iter=\u001b[32m10000\u001b[39m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m elas.fit(X_train_std, y_train)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest R2:\u001b[39m\u001b[33m\"\u001b[39m, elas.score(X_test_std, y_test))\n",
      "\u001b[31mNameError\u001b[39m: name 'MultiTaskElasticNetCV' is not defined"
     ]
    }
   ],
   "source": [
    "# L1/L2 penalty tuning with ElasticNetCV\n",
    "\n",
    "elas = MultiTaskElasticNetCV(\n",
    "    alphas=np.logspace(-4, 1, 50),\n",
    "    l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    max_iter=10000,\n",
    ")\n",
    "elas.fit(X_train_std, y_train)\n",
    "print(\"Test R2:\", elas.score(X_test_std, y_test))\n",
    "print(\"alpha_:\", elas.alpha_, \"l1_ratio_:\", elas.l1_ratio_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
