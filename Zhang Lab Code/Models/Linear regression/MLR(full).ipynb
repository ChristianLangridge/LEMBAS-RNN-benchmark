{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87f225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Code/Boilerplate/MLR_boiler_plate_local.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e3f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box r2 score LinearRegression:\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "# difference of 0.12 between train and test is understandable given the high-dimensionality and noise in gene expression data\n",
    "\n",
    "# after applying the centering boilerplate (only difference between MLR v1 and v2 is column-wise centering)\n",
    "# train score: 0.90870454039286\n",
    "# test score:  0.7934193600256717 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_test = LinearRegression(\n",
    "                    n_jobs=-1,\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd61c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.90870454039286\n",
      "Score:  0.7934193600256717\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', reg_test.score(x_train, y_train))\n",
    "print('Score: ', reg_test.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdeed774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0, Train set: 10038,     Test set:1116\n",
      "Fold:1, Train set: 10038,     Test set:1116\n",
      "Fold:2, Train set: 10038,     Test set:1116\n",
      "Fold:3, Train set: 10038,     Test set:1116\n",
      "Fold:4, Train set: 10039,     Test set:1115\n",
      "Fold:5, Train set: 10039,     Test set:1115\n",
      "Fold:6, Train set: 10039,     Test set:1115\n",
      "Fold:7, Train set: 10039,     Test set:1115\n",
      "Fold:8, Train set: 10039,     Test set:1115\n",
      "Fold:9, Train set: 10039,     Test set:1115\n"
     ]
    }
   ],
   "source": [
    "# conducting a k-fold validation to check for overfitting\n",
    "# splitting training set into 10-folds\n",
    "# train sets: ~10038 targets\n",
    "# test sets: ~1116 targets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cnt = 0\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, \\\n",
    "    Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MLR model cross validation ------\n",
      "Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
      " 0.77717178 0.7840341  0.79817987 0.76680642]\n",
      "Mean: 0.7834287993694773\n",
      "StandardDeviation: 0.00934141232879502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the 10-fold validation \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773 -> similar to the holdout training run\n",
    "#StandardDeviation: 0.009341412328795035 -> very consistent between folds\n",
    "\n",
    "# unlikely that MLR is overfitting based on these results -> good sanity check for reference\n",
    "\n",
    "# redid same analysis with column-wise centered data and got the exact same results \n",
    "#----- MLR model cross validation ------\n",
    "#Scores: [0.78811923 0.79602325 0.7830914  0.78294147 0.78665107 0.7712694\n",
    "# 0.77717178 0.7840341  0.79817987 0.76680642]\n",
    "#Mean: 0.7834287993694773\n",
    "#StandardDeviation: 0.00934141232879502\n",
    "\n",
    "def cross_validation(reg_model, training_set, training_target, cv):\n",
    "    scores = cross_val_score(\n",
    "      reg_model, training_set,\n",
    "      training_target,\n",
    "      scoring=\"r2\", cv=cv)\n",
    "    r2_scores = scores\n",
    "    print(\"Scores:\", r2_scores)\n",
    "    print(\"Mean:\", r2_scores.mean())\n",
    "    print(\"StandardDeviation:\", r2_scores.std())\n",
    "\n",
    "print(\"----- MLR model cross validation ------\")\n",
    "lin_reg = LinearRegression()\n",
    "cross_validation(lin_reg, x_train, y_train, kf)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779c71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# saving model + metadata\n",
    "\n",
    "metadata = {\n",
    "    'sklearn_version': '1.7.2',\n",
    "    'model_type': 'LinearRegression',\n",
    "    'n_features': reg_test.n_features_in_,\n",
    "    'coef_shape': reg_test.coef_.shape,\n",
    "    'intercept_shape': reg_test.intercept_.shape,\n",
    "}\n",
    "\n",
    "joblib.dump(reg_test, \"/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_model_v2.joblib\")\n",
    "with open(\"model_metadata2.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
