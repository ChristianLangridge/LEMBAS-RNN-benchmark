{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ba369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in gene/TF expression full data\n",
    "\n",
    "gene_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box r2 score with ElasticNet: 0.00432651511965587\n",
    "# no tuning at all so not surprised by uncompetitive results vs. MLR\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elas_reg = ElasticNet().fit(x_train,y_train)\n",
    "print('Score ', elas_reg.score(x_test,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning performance of ElasticNet\n",
    "# scaling input features \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(x_train)\n",
    "X_test_std  = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1/L2 penalty tuning with ElasticNetCV\n",
    "\n",
    "elas = MultiTaskElasticNetCV(\n",
    "    alphas=np.logspace(-4, 1, 50),\n",
    "    l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    max_iter=10000,\n",
    ")\n",
    "elas.fit(X_train_std, y_train)\n",
    "print(\"Test R2:\", elas.score(X_test_std, y_test))\n",
    "print(\"alpha_:\", elas.alpha_, \"l1_ratio_:\", elas.l1_ratio_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
