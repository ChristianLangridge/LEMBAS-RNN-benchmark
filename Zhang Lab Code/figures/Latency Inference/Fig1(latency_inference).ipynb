{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630a06aa",
   "metadata": {},
   "source": [
    "**This script contains the figure generating functions for Fig 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76a2526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed predictions...\n",
      "âœ“ Loaded predictions for 3 models\n",
      "  Training samples: 12748, Genes: 16100\n",
      "  Test samples: 3187, Genes: 16100\n",
      "  Val samples: 262, Genes: 16100\n",
      "\n",
      "âœ“ All functions loaded. Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "############### LOADING DATA ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_load.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e198841",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING LATENCY INFERENCE FUNCTIONS ###############\n",
    "\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b5253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ model_load.py data detected\n",
      "\n",
      "Preparing validation inputs...\n",
      "  x_validation: (262, 1197)\n",
      "  y_validation: (262, 16100)\n",
      "\n",
      "Loading models...\n",
      "======================================================================\n",
      "LOADING MODEL - EXACT TRAINING SCRIPT SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "1. Loading checkpoint from: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt\n",
      "\n",
      "2. Loading network from: /home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv\n",
      "   Network shape: (1153904, 3)\n",
      "   Network columns: ['TF', 'Gene', 'Interaction']\n",
      "\n",
      "3. Formatting network...\n",
      "\n",
      "4. Using EXACT benchmark.py parameters\n",
      "   projection_amplitude_in: 1.2\n",
      "   projection_amplitude_out: 1.2\n",
      "   bionet_params: {'target_steps': 150, 'max_steps': 10, 'exp_factor': 50, 'tolerance': 1e-20, 'leak': 0.01}\n",
      "\n",
      "5. Initializing model with DataFrames...\n",
      "   Input X_in shape: (262, 1197)\n",
      "   Input y_out shape: (262, 16100)\n",
      "  Filtered X_in: 1197 â†’ 1197 features\n",
      "  Filtered y_out: 16100 â†’ 16100 features\n",
      "   âœ“ Model initialized (data automatically filtered)\n",
      "\n",
      "6. Converting DataFrames to tensors...\n",
      "   âœ“ Tensors created\n",
      "\n",
      "7. Applying training settings...\n",
      "   âœ“ Set input_layer.weights.requires_grad = False\n",
      "   âœ“ Applied prescale_weights(target_radius=0.8)\n",
      "\n",
      "8. Loading trained weights...\n",
      "   âœ“ Weights loaded\n",
      "   âœ“ Model set to eval mode\n",
      "\n",
      "======================================================================\n",
      "âœ… MODEL LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Model ready for inference:\n",
      "  Input features: 1197\n",
      "  Output features: 16100\n",
      "  Total network nodes: 16371\n",
      "âœ“ All models loaded\n"
     ]
    }
   ],
   "source": [
    "############### LOADING IN DATA AND MODELS ###############\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/')\n",
    "from model_latency_inference import run_benchmarks\n",
    "\n",
    "# ============================================================================\n",
    "# Validate prerequisites\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    _ = y_validation, predictions_validation\n",
    "    print(\"âœ“ model_load.py data detected\")\n",
    "except NameError:\n",
    "    raise SystemExit(\n",
    "        \"\\nERROR: Please run model_load.py first!\\n\"\n",
    "        \"Usage:\\n\"\n",
    "        \"  %run model_load.py\\n\"\n",
    "        \"  %run benchmark_latency.py\\n\"\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# Build x_validation (TF features) from external data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nPreparing validation inputs...\")\n",
    "\n",
    "# Load external validation data\n",
    "validation_dataset = pd.read_csv(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/Liver_bulk_external.tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Load network and TF reference\n",
    "net = pd.read_csv(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "    sep='\\t'\n",
    ")\n",
    "tf_expression = pd.read_csv(\n",
    "    '~/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Determine features\n",
    "network_nodes = set(net['TF'].unique()) | set(net['Gene'].unique())\n",
    "usable_features = [tf for tf in tf_expression.columns if tf in network_nodes]\n",
    "\n",
    "# Build x_validation with zero-filling for missing features\n",
    "x_validation = pd.DataFrame(0, index=validation_dataset.index, columns=usable_features)\n",
    "present_features = [f for f in usable_features if f in validation_dataset.columns]\n",
    "x_validation[present_features] = validation_dataset[present_features]\n",
    "\n",
    "print(f\"  x_validation: {x_validation.shape}\")\n",
    "print(f\"  y_validation: {y_validation.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nLoading models...\")\n",
    "\n",
    "sys.path.append('/home/christianl/Zhang-Lab/Zhang Lab Code/Tuning/uncentered_RNN_tuning')\n",
    "from RNN_reconstructor import load_model_from_checkpoint\n",
    "\n",
    "# MLR\n",
    "mlr_loaded = joblib.load(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/MLR/MLR_v3/MLR_model_v4(uncentered[FINAL]).joblib'\n",
    ")\n",
    "\n",
    "# XGBRF\n",
    "xgbrf_loaded = joblib.load(\n",
    "    '/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/XGBRF/XGBRF_v5/all_models_batch_XGBRF[uncentered_REALFINAL].joblib'\n",
    ")\n",
    "\n",
    "# RNN\n",
    "RNN_val = load_model_from_checkpoint(\n",
    "    checkpoint_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt',\n",
    "    net_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "    X_in_df=x_validation,\n",
    "    y_out_df=y_validation,\n",
    "    device='cpu',\n",
    "    use_exact_training_params=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ All models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1149017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " ðŸš€ STARTING DUAL-MODE BENCHMARK\n",
      "================================================================================\n",
      "\n",
      "[Mode A] TRUE LATENCY (Input shape: (1, 1197))\n",
      "------------------------------------------------------------\n",
      "  Testing MLR...\n",
      "  Testing XGBRFRegressor (17 sub-models)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m############### PLOTTING STEP ###############\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results = \u001b[43mrun_benchmarks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmlr_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlr_loaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgbrf_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxgbrf_loaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRNN_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/christianl/Zhang-Lab/Zhang Lab Figures/inference_latency_corrected.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py:162\u001b[39m, in \u001b[36mrun_benchmarks\u001b[39m\u001b[34m(mlr_model, xgbrf_models, rnn_model, X_full, n_runs, save_path)\u001b[39m\n\u001b[32m    159\u001b[39m results_latency[\u001b[33m'\u001b[39m\u001b[33mMLR\u001b[39m\u001b[33m'\u001b[39m] = benchmark_mlr_inference(mlr_model, X_np_single, n_runs)\n\u001b[32m    161\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Testing XGBRFRegressor (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(xgbrf_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sub-models)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m results_latency[\u001b[33m'\u001b[39m\u001b[33mXGBRFRegressor\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mbenchmark_xgbrf_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgbrf_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_np_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Testing RNN...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Try/Except block in case RNN is strictly graph-based and rejects single nodes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zhang-Lab/Zhang Lab Code/Boilerplate_datahandling/Remote boilerplate/model_latency_inference.py:66\u001b[39m, in \u001b[36mbenchmark_xgbrf_inference\u001b[39m\u001b[34m(models_list, X_input, n_runs, warmup_runs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Warmup\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(warmup_runs):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     _ = [\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_list]\n\u001b[32m     68\u001b[39m latencies = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/sklearn/multioutput.py:310\u001b[39m, in \u001b[36m_MultiOutputEstimator.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe base estimator should implement a predict method\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m y = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(y).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/xgboost/sklearn.py:1446\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1455\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/xgboost/core.py:2851\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2847\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n\u001b[32m   2849\u001b[39m     data, _ = _ensure_np_dtype(data, data.dtype)\n\u001b[32m   2850\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterPredictFromDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m            \u001b[49m\u001b[43mp_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2858\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2859\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2860\u001b[39m     )\n\u001b[32m   2861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (ArrowTransformed, PandasTransformed)):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "############### PLOTTING STEP ###############\n",
    "\n",
    "results = run_benchmarks(\n",
    "    mlr_model=mlr_loaded,\n",
    "    xgbrf_models=xgbrf_loaded,\n",
    "    rnn_model=RNN_val,\n",
    "    X_full=x_validation,\n",
    "    save_path='/home/christianl/Zhang-Lab/Zhang Lab Figures/inference_latency_corrected.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
