{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa30a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing uncentered-trained RNN \n",
    "# importing pytorch\n",
    "import torch\n",
    "import pandas as pd\n",
    "from RNN_reconstructor import load_model_from_checkpoint\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running data config file\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Remote boilerplate/uncentered_RNN_remote.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING MODEL - EXACT TRAINING SCRIPT SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "1. Loading checkpoint from: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt\n",
      "\n",
      "2. Loading network from: /home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv\n",
      "   Network shape: (1153904, 3)\n",
      "   Network columns: ['TF', 'Gene', 'Interaction']\n",
      "\n",
      "3. Formatting network...\n",
      "\n",
      "4. Using EXACT benchmark.py parameters\n",
      "   projection_amplitude_in: 1.2\n",
      "   projection_amplitude_out: 1.2\n",
      "   bionet_params: {'target_steps': 150, 'max_steps': 10, 'exp_factor': 50, 'tolerance': 1e-20, 'leak': 0.01}\n",
      "\n",
      "5. Initializing model with DataFrames...\n",
      "   Input X_in shape: (3187, 1198)\n",
      "   Input y_out shape: (3187, 16101)\n",
      "  Filtered X_in: 1198 → 1197 features\n",
      "  Filtered y_out: 16101 → 16100 features\n",
      "   ✓ Model initialized (data automatically filtered)\n",
      "\n",
      "6. Converting DataFrames to tensors...\n",
      "   ✓ Tensors created\n",
      "\n",
      "7. Applying training settings...\n",
      "   ✓ Set input_layer.weights.requires_grad = False\n",
      "   ✓ Applied prescale_weights(target_radius=0.8)\n",
      "\n",
      "8. Loading trained weights...\n",
      "   ✓ Weights loaded\n",
      "   ✓ Model set to eval mode\n",
      "\n",
      "======================================================================\n",
      "✅ MODEL LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Model ready for inference:\n",
      "  Input features: 1197\n",
      "  Output features: 16100\n",
      "  Total network nodes: 16371\n"
     ]
    }
   ],
   "source": [
    "# reconstructing trained RNN from checkpoint file with learned weights, \n",
    "# the fixed network.tsv and the reconstructor script with the class initalisations \n",
    "loaded_RNN = load_model_from_checkpoint(\n",
    "                checkpoint_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt',\n",
    "                net_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "                X_in_df=x_test_df,  # passing as df not tensors\n",
    "                y_out_df=y_test_df,  # passing as df not tensors\n",
    "                device='cpu',\n",
    "                use_exact_training_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9764bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions shape: torch.Size([3187, 16100])\n",
      "Hidden states shape: torch.Size([3187, 16371])\n"
     ]
    }
   ],
   "source": [
    "# looking across test dataset to see what the RNN's predictive ability is on my data\n",
    "# y_hat -> predictions made only across the 16,100 target genes we are looking at in our final output (returned)\n",
    "# y_full -> predictions across all 16,371 network nodes in the .tsv file, including hidden states (intermediary calculations, returned)\n",
    "# torch.no_grad() -> command to look across but not change the RNN's learned weights\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_hat, Y_full = loaded_RNN(loaded_RNN.X_in)\n",
    "    \n",
    "print(f\"\\nPredictions shape: {Y_hat.shape}\")\n",
    "print(f\"Hidden states shape: {Y_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658b83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "Pearson correlation coefficient: 0.8587\n"
     ]
    }
   ],
   "source": [
    "# calculating Pearson correlation to check how well model is predicting results vs. a groundtruth\n",
    "# Y_hat -> the cleaned predictions only including the target genes synched with the .tsv file\n",
    "# loaded_RNN.y_out -> the test set 'y_test_df' with exact same dimensions, used here as a baseline to compare performance \n",
    "# data is run through detach().cpu().numpy() to convert from Pytorch tensors to Numpy arrays\n",
    "# flatten() compresses multidimensional data into a 1D array\n",
    "# Agg Pearson correlation coefficient of 0.8587 between y_test and y_hat predictions \n",
    "\n",
    "pr, _ = pearsonr(\n",
    "    loaded_RNN.y_out.detach().flatten().cpu().numpy(),\n",
    "    Y_hat.detach().flatten().cpu().numpy())\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Pearson correlation coefficient: {pr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5045d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions saved to: /home/christianl/Zhang-Lab/Zhang Lab Data/uncenteredRNN_on_uncentereddata_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "# saving predictions in an output file\n",
    "output_file = \"/home/christianl/Zhang-Lab/Zhang Lab Data/uncenteredRNN_on_uncentereddata_predictions.tsv\"\n",
    "pd.DataFrame(Y_hat.detach().cpu().numpy()).to_csv(\n",
    "    output_file, sep=\"\\t\", index=False, header=False\n",
    ")\n",
    "print(f\"\\nPredictions saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b812322",
   "metadata": {},
   "source": [
    "#### Retrying the code but with mean-centered data to check differences in Agg PCC ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f5070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Remote boilerplate/centered_RNN_remote.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a08490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING MODEL - EXACT TRAINING SCRIPT SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "1. Loading checkpoint from: /home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt\n",
      "\n",
      "2. Loading network from: /home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv\n",
      "   Network shape: (1153904, 3)\n",
      "   Network columns: ['TF', 'Gene', 'Interaction']\n",
      "\n",
      "3. Formatting network...\n",
      "\n",
      "4. Using EXACT benchmark.py parameters\n",
      "   projection_amplitude_in: 1.2\n",
      "   projection_amplitude_out: 1.2\n",
      "   bionet_params: {'target_steps': 150, 'max_steps': 10, 'exp_factor': 50, 'tolerance': 1e-20, 'leak': 0.01}\n",
      "\n",
      "5. Initializing model with DataFrames...\n",
      "   Input X_in shape: (3187, 1198)\n",
      "   Input y_out shape: (3187, 16101)\n",
      "  Filtered X_in: 1198 → 1197 features\n",
      "  Filtered y_out: 16101 → 16100 features\n",
      "   ✓ Model initialized (data automatically filtered)\n",
      "\n",
      "6. Converting DataFrames to tensors...\n",
      "   ✓ Tensors created\n",
      "\n",
      "7. Applying training settings...\n",
      "   ✓ Set input_layer.weights.requires_grad = False\n",
      "   ✓ Applied prescale_weights(target_radius=0.8)\n",
      "\n",
      "8. Loading trained weights...\n",
      "   ✓ Weights loaded\n",
      "   ✓ Model set to eval mode\n",
      "\n",
      "======================================================================\n",
      "✅ MODEL LOADED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Model ready for inference:\n",
      "  Input features: 1197\n",
      "  Output features: 16100\n",
      "  Total network nodes: 16371\n"
     ]
    }
   ],
   "source": [
    "centered_loaded_RNN = load_model_from_checkpoint(\n",
    "                checkpoint_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt',\n",
    "                net_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv',\n",
    "                X_in_df=x_test_centered_df,  # passing as df not tensors (centered)\n",
    "                y_out_df=y_test_centered_df,  # passing as df not tensors (centered)\n",
    "                device='cpu',\n",
    "                use_exact_training_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec30319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions shape: torch.Size([3187, 16100])\n",
      "Hidden states shape: torch.Size([3187, 16371])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    Y_hat_centered, Y_full_centered = centered_loaded_RNN(loaded_RNN.X_in)\n",
    "    \n",
    "print(f\"\\nPredictions shape: {Y_hat_centered.shape}\")\n",
    "print(f\"Hidden states shape: {Y_full_centered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e87a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "Pearson correlation coefficient on mean-centered data (uncentered-data training) : 0.3320\n"
     ]
    }
   ],
   "source": [
    "# As expected, performance drop significantly with PCC dropping to 0.3320 when comparing \n",
    "# a model trained on uncentered data with data that has been mean-centered\n",
    "# This illustrates how important a unified data preprocessing step is for benchmarking \n",
    "\n",
    "pr, _ = pearsonr(\n",
    "    centered_loaded_RNN.y_out.detach().flatten().cpu().numpy(),\n",
    "    Y_hat_centered.detach().flatten().cpu().numpy())\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Pearson correlation coefficient on mean-centered data (uncentered-data training) : {pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15765141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions saved to: /home/christianl/Zhang-Lab/Zhang Lab Data/uncenteredRNN_on_centereddata_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "# saving predictions in an output file\n",
    "output_file_1 = \"/home/christianl/Zhang-Lab/Zhang Lab Data/uncenteredRNN_on_centereddata_predictions.tsv\"\n",
    "pd.DataFrame(Y_hat_centered.detach().cpu().numpy()).to_csv(\n",
    "    output_file_1, sep=\"\\t\", index=False, header=False\n",
    ")\n",
    "print(f\"\\nPredictions saved to: {output_file_1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
