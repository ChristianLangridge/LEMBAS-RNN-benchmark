{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing uncentered-trained RNN \n",
    "# importing pytorch\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running data config file\n",
    "%run '/home/christianl/Zhang-Lab/Zhang Lab Code/Boilerplate/model_boilerplate_remote.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying testing data\n",
    "net = pd.read_csv('/home/christianl/Zhang-Lab/Zhang Lab Data/Full data files/network(full).tsv', sep = '\\t')\n",
    "x_in = x_test\n",
    "y_out = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38c67a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bionetwork.py'; 'bionetwork' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Update this path to your LEMBAS directory\u001b[39;00m\n\u001b[32m     14\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m/home/christian/Zhang-Lab/RNN\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbionetwork\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SignalingModel\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(checkpoint_path, node_names=\u001b[38;5;28;01mNone\u001b[39;00m, net=\u001b[38;5;28;01mNone\u001b[39;00m, X_in=\u001b[38;5;28;01mNone\u001b[39;00m, y_out=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    Load your model in one line!\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m    >>> predictions, _ = model(model.X_in[:5])\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bionetwork.py'; 'bionetwork' is not a package"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SUPER SIMPLE LOADER - One Function Does Everything\n",
    "===================================================\n",
    "\n",
    "Just call load_model() and you're done!\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Update this path to your LEMBAS directory\n",
    "sys.path.append('/home/christian/Zhang-Lab/RNN')\n",
    "from bionetwork.py import SignalingModel\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path, node_names=None, net=None, X_in=None, y_out=None):\n",
    "    \"\"\"\n",
    "    Load your model in one line!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    checkpoint_path : str\n",
    "        Path to your .pt checkpoint file\n",
    "    node_names : list, optional\n",
    "        List of node names. If None, uses generic names.\n",
    "    net : pd.DataFrame, optional\n",
    "        Network topology. If None, reconstructs from checkpoint.\n",
    "    X_in : pd.DataFrame, optional\n",
    "        Input data. If None, creates dummy data.\n",
    "    y_out : pd.DataFrame, optional\n",
    "        Output data. If None, creates dummy data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : SignalingModel\n",
    "        Your loaded model, ready to use!\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> model = load_model('signaling_model.v1.pt')\n",
    "    >>> # That's it! Now use it:\n",
    "    >>> model.eval()\n",
    "    >>> predictions, _ = model(model.X_in[:5])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    config = {\n",
    "        'seed': checkpoint.get('seed', 888),\n",
    "        'bionet_params': checkpoint.get('bionet_params'),\n",
    "        'projection_amplitude_in': checkpoint.get('projection_amplitude_in', 1.0),\n",
    "        'projection_amplitude_out': checkpoint.get('projection_amplitude_out', 1.0)\n",
    "    }\n",
    "    \n",
    "    # Get dimensions from state_dict\n",
    "    network_key = [k for k in state_dict.keys() if 'network' in k.lower() and 'weight' in k.lower() and len(state_dict[k].shape) == 2][0]\n",
    "    adj_matrix = state_dict[network_key].cpu().numpy()\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    \n",
    "    input_key = [k for k in state_dict.keys() if 'input' in k.lower() and 'weight' in k.lower()][0]\n",
    "    n_ligands = state_dict[input_key].shape[0]\n",
    "    \n",
    "    output_key = [k for k in state_dict.keys() if 'output' in k.lower() and 'weight' in k.lower()][0]\n",
    "    n_tfs = state_dict[output_key].shape[0]\n",
    "    \n",
    "    # Create node names if not provided\n",
    "    if node_names is None:\n",
    "        node_names = [f'node_{i}' for i in range(n_nodes)]\n",
    "    \n",
    "    # Reconstruct network if not provided\n",
    "    if net is None:\n",
    "        sources, targets, weights = [], [], []\n",
    "        for i in range(n_nodes):\n",
    "            for j in range(n_nodes):\n",
    "                if adj_matrix[i, j] != 0:\n",
    "                    targets.append(node_names[i])\n",
    "                    sources.append(node_names[j])\n",
    "                    weights.append(adj_matrix[i, j])\n",
    "        \n",
    "        net = pd.DataFrame({\n",
    "            'source': sources,\n",
    "            'target': targets,\n",
    "            'mode_of_action': [1 if w > 0 else -1 for w in weights]\n",
    "        })\n",
    "    \n",
    "    # Create dummy data if not provided\n",
    "    if X_in is None:\n",
    "        X_in = pd.DataFrame(\n",
    "            np.random.rand(100, n_ligands) * 0.1,\n",
    "            columns=[node_names[i] for i in range(n_ligands)]\n",
    "        )\n",
    "    \n",
    "    if y_out is None:\n",
    "        y_out = pd.DataFrame(\n",
    "            np.random.rand(100, n_tfs) * 0.1,\n",
    "            columns=[node_names[i] for i in range(n_tfs)]\n",
    "        )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SignalingModel(\n",
    "        net=net,\n",
    "        X_in=X_in,\n",
    "        y_out=y_out,\n",
    "        projection_amplitude_in=config['projection_amplitude_in'],\n",
    "        projection_amplitude_out=config['projection_amplitude_out'],\n",
    "        bionet_params=config['bionet_params'],\n",
    "        activation_function='MML',\n",
    "        dtype=torch.float32,\n",
    "        device='cpu',\n",
    "        seed=config['seed']\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "    print(f\"   Nodes: {n_nodes}, Ligands: {n_ligands}, TFs: {n_tfs}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Example 1: Load with everything automatic (dummy data)\n",
    "    print(\"Example 1: Automatic loading with dummy data\")\n",
    "    model = load_model('/home/christian/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt')\n",
    "    \n",
    "    # Test it\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred, _ = model(model.X_in[:3])\n",
    "        print(f\"Prediction shape: {y_pred.shape}\")\n",
    "        print(f\"Sample value: {y_pred[0, 0].item():.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Example 2: Load with your own node names\n",
    "    print(\"\\nExample 2: With node names\")\n",
    "    # node_names = ['EGF', 'TGFA', 'FGF1', ...]  # Your names here\n",
    "    # model = load_model('signaling_model.v1.pt', node_names=node_names)\n",
    "    \n",
    "    # Example 3: Load with your own network and data\n",
    "    print(\"\\nExample 3: With real data\")\n",
    "    # net = pd.read_csv('your_network.csv')\n",
    "    # X_in = pd.read_csv('your_X_in.csv', index_col=0)\n",
    "    # y_out = pd.read_csv('your_y_out.csv', index_col=0)\n",
    "    # model = load_model('signaling_model.v1.pt', net=net, X_in=X_in, y_out=y_out)\n",
    "    \n",
    "    print(\"\\n✅ Done! Your model is ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092ef8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STATE_DICT ANALYSIS\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2640175/2818158888.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location='cpu')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_layer.weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43manalyze_what_you_have\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36manalyze_what_you_have\u001b[39m\u001b[34m(state_dict_path)\u001b[39m\n\u001b[32m     29\u001b[39m state_dict = torch.load(state_dict_path, map_location=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Extract dimensions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m n_ligands = \u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_layer.weights\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     33\u001b[39m n_nodes = state_dict[\u001b[33m'\u001b[39m\u001b[33msignaling_network.weights\u001b[39m\u001b[33m'\u001b[39m].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m n_tfs = state_dict[\u001b[33m'\u001b[39m\u001b[33moutput_layer.weights\u001b[39m\u001b[33m'\u001b[39m].shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'input_layer.weights'"
     ]
    }
   ],
   "source": [
    "analyze_what_you_have('/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization parameters\n",
    "projection_amplitude_in = 1  # default of 1 \n",
    "projection_amplitude_out = ???  # equal to the number of nodes in the final fixed network \n",
    "activation_function = 'MML'\n",
    "bionet_params = {\n",
    "    'target_steps': 100,\n",
    "    'max_steps': 300,      # RNN iterations\n",
    "    'exp_factor': 20,\n",
    "    'leak': 0.01,          # for activation function\n",
    "    'tolerance': 1e-5,     # convergence threshold\n",
    "    'spectral_target': 1e-7\n",
    "}\n",
    "ban_list = None\n",
    "\n",
    "dtype = torch.dtype=torch.float32\n",
    "device = 'cpu' # was trained on gpu \n",
    "seed = 888 # default of 888 by Kejun's self.setseeds function unless specifcied\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ee2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in uncentered data trained model learned weighted\n",
    "uncentered_data_RNN_weights = torch.load('/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/RNN/signaling_model.v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Model Parameters ===\")\n",
    "print(f\"Input shape: {trained_model.X_in.shape}\")\n",
    "print(f\"Output shape: {trained_model.y_out.shape}\")\n",
    "print(f\"Number of nodes: {len(trained_model.node_idx_map)}\")\n",
    "print(f\"Projection amplitude in: {trained_model.input_layer.projection_amplitude}\")\n",
    "print(f\"Projection amplitude out: {trained_model.projection_amplitude_out}\")\n",
    "print(f\"Device: {trained_model.device}\")\n",
    "print(f\"Seed: {trained_model.seed}\")\n",
    "print(f\"\\nBioNet params: {trained_model.signaling_network.training_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ece1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predicted values y_pred from test set \n",
    "rnn_y_pred = loaded_model.predict(x_test) \n",
    "print(type(rnn_y_pred), rnn_y_pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
