{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b79aa92",
   "metadata": {},
   "source": [
    "**This script contains the figure generating functions for Fig 1.A and 1.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ea9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# 1. Find the Repo Root dynamically\n",
    "# Walks up folders until it finds the README.md file\n",
    "_root = next(p for p in Path.cwd().parents if (p / \"README.md\").exists())\n",
    "REPO_ROOT = str(_root)\n",
    "\n",
    "# 2. Add to sys.path so standard 'import' statements work\n",
    "import sys\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Load the Data Root from the JSON file\n",
    "with open(Path(REPO_ROOT) / \"data_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    DATA_ROOT = config[\"DATA_ROOT\"]\n",
    "\n",
    "print(f\"Data is being pulled from: {DATA_ROOT}\")\n",
    "print(f\"Repo root identified as: {REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING DATA ###############\n",
    "\n",
    "%run \"$REPO_ROOT/config/predictions/model_load.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING FUNCTIONS ###############\n",
    "\n",
    "%run \"$REPO_ROOT/config/figures/figure1_agg_pearson_R.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### UNIT TEST ###############\n",
    "\n",
    "# Check what your y_test columns actually are:\n",
    "print(\"y_test columns type:\", type(y_train.columns))\n",
    "print(\"First 5 column names:\", y_train.columns[:5].tolist())\n",
    "\n",
    "# Also check if y_test is actually a DataFrame or numpy array:\n",
    "print(\"y_test type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# diagnostics of MLR r2 scores for fitting to training set \n",
    "\n",
    "# checking to ensure predictions and groundtruth are comparable (they do)\n",
    "assert y_train.shape == mlr_y_pred_train.shape\n",
    "\n",
    "# compare r2 values\n",
    "# mlr_loaded.score: 0.9041830139739396 on training data (fit)\n",
    "print(\"mlr_loaded.score:\", mlr_loaded.score(x_train, y_train))\n",
    "\n",
    "# compute_metrics() is the flattened r2, where each gene's r2 is treated equally (flattened) before aggregating\n",
    "# compute_metrics r2: 0.966425772252575\n",
    "# compute_metrics Pearson_r: 0.9830695663342065\n",
    "\n",
    "metrics_flat_mlr_train = compute_metrics(y_train.values, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_agg_R2 = metrics_flat_mlr_train['r2']\n",
    "mlr_train_agg_Pearsons = metrics_flat_mlr_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {mlr_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {mlr_train_agg_Pearsons}\")\n",
    "\n",
    "# compute_metrics_per_gene() looks at the indiviudal r2 at per-gene resolution (using DFs to maintain biological relevance of each column) \n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.920598\n",
    "#1        0.883302\n",
    "#2        0.650227\n",
    "#3        0.872502\n",
    "#4        0.953659\n",
    "#           ...   \n",
    "#16095    0.886189\n",
    "#16096    0.950355\n",
    "#16097    0.966280\n",
    "#16098    0.961176\n",
    "#16099    0.958689\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.959478\n",
    "#1        0.939842\n",
    "#2        0.806367\n",
    "#3        0.934078\n",
    "#4        0.976555\n",
    "#           ...   \n",
    "#16095    0.941376\n",
    "#16096    0.974861\n",
    "#16097    0.982995\n",
    "#16098    0.980396\n",
    "#16099    0.979127\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_mlr_train = compute_metrics_per_gene(y_train, mlr_y_pred_train)\n",
    "\n",
    "mlr_train_pergene_R2 = metrics_flat_per_gene_mlr_train['r2']\n",
    "mlr_train_pergene_Pearsons = metrics_flat_per_gene_mlr_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", mlr_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", mlr_train_pergene_Pearsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "# same diagnostics for XGBRF.v3 (trained on same x_train)\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == xgbrf_y_pred_train.shape\n",
    "\n",
    "# computing XGBRF metrics (aggregate and per gene (per model is this case))\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_xgbrf_train = compute_metrics(y_train.values, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_agg_R2 = metrics_flat_xgbrf_train['r2']\n",
    "xgbrf_train_agg_Pearsons = metrics_flat_xgbrf_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.842478\n",
    "#1        0.858510\n",
    "#2        0.636674\n",
    "#3        0.772578\n",
    "#4        0.891585\n",
    "#           ...   \n",
    "#16095    0.773693\n",
    "#16096    0.868024\n",
    "#16097    0.910289\n",
    "#16098    0.902526\n",
    "#16099    0.915816\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.918635\n",
    "#1        0.927942\n",
    "#2        0.801955\n",
    "#3        0.881419\n",
    "#4        0.944821\n",
    "#           ...   \n",
    "#16095    0.881782\n",
    "#16096    0.932276\n",
    "#16097    0.954410\n",
    "#16098    0.950481\n",
    "#16099    0.957509\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_xgbrf_train = compute_metrics_per_gene(y_train, xgbrf_y_pred_train)\n",
    "\n",
    "xgbrf_train_pergene_R2 = metrics_flat_per_gene_xgbrf_train['r2']\n",
    "xgbrf_train_pergene_Pearsons = metrics_flat_per_gene_xgbrf_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", xgbrf_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", xgbrf_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DIAGNOSTICS ###############\n",
    "\n",
    "\n",
    "# same diagnostics for RNN.v1 (used as a reference for data preprocessing of other models )\n",
    "# checking to ensure predictions and groundtruth are comparable\n",
    "assert y_train.shape == rnn_y_pred_train.shape\n",
    "\n",
    "# computing RNN metrics (aggregate and per gene)\n",
    "# compute global R²: 0.9347856649287827\n",
    "# compute global Pearson's R: 0.9669668218291075\n",
    "metrics_flat_rnn_train = compute_metrics(y_train.values, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_agg_R2 = metrics_flat_rnn_train['r2']\n",
    "rnn_train_agg_Pearsons = metrics_flat_rnn_train['pearson_r']\n",
    "\n",
    "print(f\"compute global R²: {xgbrf_train_agg_R2}\")\n",
    "print(f\"compute global Pearson's R: {xgbrf_train_agg_Pearsons}\")\n",
    "\n",
    "#compute_metrics_per_gene R²: 0        0.224471\n",
    "#1       -0.057189\n",
    "#2       -0.204377\n",
    "#3        0.390087\n",
    "#4        0.662030\n",
    "#           ...   \n",
    "#16095    0.342862\n",
    "#16096    0.506315\n",
    "#16097    0.650347\n",
    "#16098    0.505688\n",
    "#16099    0.612035\n",
    "#Name: r2, Length: 16100, dtype: float64\n",
    "\n",
    "#computer_metrics_per_gene Pearson's R 0        0.485774\n",
    "#1       -0.149498\n",
    "#2        0.232025\n",
    "#3        0.626851\n",
    "#4        0.824306\n",
    "#           ...   \n",
    "#16095    0.586376\n",
    "#16096    0.713733\n",
    "#16097    0.809349\n",
    "#16098    0.734049\n",
    "#16099    0.783338\n",
    "#Name: pearson_r, Length: 16100, dtype: float64\n",
    "\n",
    "metrics_flat_per_gene_rnn_train = compute_metrics_per_gene(y_train, rnn_y_pred_train)\n",
    "\n",
    "rnn_train_pergene_R2 = metrics_flat_per_gene_rnn_train['r2']\n",
    "rnn_train_pergene_Pearsons = metrics_flat_per_gene_rnn_train['pearson_r']\n",
    "\n",
    "print(\"compute_metrics_per_gene R²:\", rnn_train_pergene_R2)\n",
    "print(\"computer_metrics_per_gene Pearson's R\", rnn_train_pergene_Pearsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86240d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### f"{DATA_ROOT}/
    "\n",
    "agg_metrics = figure_dual_correlation_comparison(\n",
    "    y_true=y_train,\n",
    "    predictions_dict=predictions_train,\n",
    "    compute_spearman=True,\n",
    "    spearman_subsample=500000,\n",
    "    output_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)/aggregate_correlation.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### f"{DATA_ROOT}/,
    "\n",
    "per_gene_df, per_gene_summary = figure_per_gene_dual_correlation_distribution(\n",
    "    y_true_df=y_train,\n",
    "    predictions_dict=predictions_train,\n",
    "    compute_spearman=True,\n",
    "    ci_method='analytical',\n",
    "    output_path='/home/christianl/Zhang-Lab/Zhang Lab Data/Saved figures/Production_model_figures(x_train)/per_gene_correlation.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
