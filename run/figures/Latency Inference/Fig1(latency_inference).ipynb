{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630a06aa",
   "metadata": {},
   "source": [
    "**This script contains the figure generating functions for Fig 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# 1. Find the Repo Root dynamically\n",
    "# Walks up folders until it finds the README.md file\n",
    "_root = next(p for p in Path.cwd().parents if (p / \"README.md\").exists())\n",
    "REPO_ROOT = str(_root)\n",
    "\n",
    "# 2. Add to sys.path so standard 'import' statements work\n",
    "import sys\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "    \n",
    "# Load the Data Root from the JSON file\n",
    "with open(Path(REPO_ROOT) / \"data_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    DATA_ROOT = config[\"DATA_ROOT\"]\n",
    "\n",
    "print(f\"Data is being pulled from: {DATA_ROOT}\")\n",
    "print(f\"Repo root identified as: {REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING DATA ###############\n",
    "\n",
    "%run \"$REPO_ROOT/config/predictions/model_load.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e198841",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING LATENCY INFERENCE FUNCTIONS ###############\n",
    "\n",
    "%run \"$REPO_ROOT/config/latency/model_latency_inference.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOADING IN DATA AND MODELS ###############\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "#sys.path.append(f\"{REPO_ROOT}/config/latency/\")\n",
    "#from model_latency_inference import run_benchmarks\n",
    "\n",
    "# ============================================================================\n",
    "# Validate prerequisites\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    _ = y_validation, predictions_validation\n",
    "    print(\"✓ model_load.py data detected\")\n",
    "except NameError:\n",
    "    raise SystemExit(\n",
    "        \"\\nERROR: Please run model_load.py first!\\n\"\n",
    "        \"Usage:\\n\"\n",
    "        \"  %run model_load.py\\n\"\n",
    "        \"  %run benchmark_latency.py\\n\"\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# Build x_validation (TF features) from external data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nPreparing validation inputs...\")\n",
    "\n",
    "# Load external validation data\n",
    "validation_dataset = pd.read_csv(\n",
    "    f\"{DATA_ROOT}/Full data files/Liver_bulk_external.tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Load network and TF reference\n",
    "net = pd.read_csv(\n",
    "    f\"{DATA_ROOT}/Full data files/network(full).tsv',\n",
    "    sep='\\t'\n",
    ")\n",
    "tf_expression = pd.read_csv(\n",
    "    '~/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv',\n",
    "    sep='\\t', header=0, index_col=0\n",
    ")\n",
    "\n",
    "# Determine features\n",
    "network_nodes = set(net['TF'].unique()) | set(net['Gene'].unique())\n",
    "usable_features = [tf for tf in tf_expression.columns if tf in network_nodes]\n",
    "\n",
    "# Build x_validation with zero-filling for missing features\n",
    "x_validation = pd.DataFrame(0, index=validation_dataset.index, columns=usable_features)\n",
    "present_features = [f for f in usable_features if f in validation_dataset.columns]\n",
    "x_validation[present_features] = validation_dataset[present_features]\n",
    "\n",
    "print(f\"  x_validation: {x_validation.shape}\")\n",
    "print(f\"  y_validation: {y_validation.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nLoading models...\")\n",
    "\n",
    "sys.path.append(f\"{REPO_ROOT}run/model scripts/LEMBAS-RNN/\")\n",
    "from RNN_reconstructor import load_model_from_checkpoint\n",
    "\n",
    "# MLR\n",
    "mlr_loaded = joblib.load(\n",
    "    f\"{DATA_ROOT}/Saved models/MLR/MLR_v3/MLR_model_v4(uncentered[FINAL]).joblib'\n",
    ")\n",
    "\n",
    "# XGBRF\n",
    "xgbrf_loaded = joblib.load(\n",
    "    f\"{DATA_ROOT}/Saved models/XGBRF/XGBRF_v5/all_models_batch_XGBRF[uncentered_REALFINAL].joblib'\n",
    ")\n",
    "\n",
    "# RNN\n",
    "RNN_val = load_model_from_checkpoint(\n",
    "    checkpoint_path=f\"{DATA_ROOT}/Saved models/RNN/uncentered_data_RNN/signaling_model.v1.pt',\n",
    "    net_path=f\"{DATA_ROOT}/Full data files/network(full).tsv',\n",
    "    X_in_df=x_validation,\n",
    "    y_out_df=y_validation,\n",
    "    device='cpu',\n",
    "    use_exact_training_params=True\n",
    ")\n",
    "\n",
    "print(\"✓ All models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1149017",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PLOTTING STEP ###############\n",
    "\n",
    "results = run_benchmarks(\n",
    "    mlr_model=mlr_loaded,\n",
    "    xgbrf_models=xgbrf_loaded,\n",
    "    rnn_model=RNN_val,\n",
    "    X_full=x_validation,\n",
    "    save_path='/home/christianl/Zhang-Lab/Zhang Lab Figures/inference_latency_corrected.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
